#!/usr/bin/python
# -*- coding: utf-8 -*-

# Author: Axel Angel, copyright 2015, license GPLv3.

import os
import sys
import caffe
import numpy as np
import lmdb
import argparse
from collections import defaultdict

def flat_shape(x):
    "Returns x without singleton dimension, eg: (1,28,28) -> (28,28)"
    return x.reshape(filter(lambda s: s > 1, x.shape))

def lmdb_reader(fpath):
    import lmdb
    lmdb_env = lmdb.open(fpath)
    lmdb_txn = lmdb_env.begin()
    lmdb_cursor = lmdb_txn.cursor()

    for key, value in lmdb_cursor:
        datum = caffe.proto.caffe_pb2.Datum()
        datum.ParseFromString(value)
        label = int(datum.label)
        image = caffe.io.datum_to_array(datum).astype(np.uint8)
        yield (key, flat_shape(image), label)

def leveldb_reader(fpath):
    import leveldb
    db = leveldb.LevelDB(fpath)

    for key, value in db.RangeIter():
        datum = caffe.proto.caffe_pb2.Datum()
        datum.ParseFromString(value)
        label = int(datum.label)
        image = caffe.io.datum_to_array(datum).astype(np.uint8)
        yield (key, flat_shape(image), label)

def npz_reader(fpath):
    npz = np.load(fpath)

    xs = npz['arr_0']
    ls = npz['arr_1']

    for i, (x, l) in enumerate(np.array([ xs, ls ]).T):
        yield (i, x, l)

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--proto', type=str, required=True)
    parser.add_argument('--model', type=str, required=True)
    # group = parser.add_mutually_exclusive_group(required=True)
    # group.add_argument('--lmdb', type=str, default=None)
    # group.add_argument('--leveldb', type=str, default=None)
    # group.add_argument('--npz', type=str, default=None)
    args = parser.parse_args()

    count = 0
    correct = 0
    matrix = defaultdict(int) # (real,pred) -> int
    labels_set = set()

    net = caffe.Net(args.proto, args.model, caffe.TEST)
    net.blobs['data'].reshape(1,        # batch size
                          3,         # 3-channel (BGR) images
                          227, 227)  # image size is 227x227
    # caffe.set_mode_cpu()
    caffe.set_mode_gpu()
    caffe.set_device(0)

    print "args", vars(args)
    # if args.lmdb != None:
    #     reader = lmdb_reader(args.lmdb)
    # if args.leveldb != None:
    #     reader = leveldb_reader(args.leveldb)
    # if args.npz != None:
    #     reader = npz_reader(args.npz)

    mu = np.load('/home/users/wxie/visual_recognition/ilsvrc_2012_mean.npy')
    mu = mu.mean(1).mean(1)  # average over pixels to obtain the mean (BGR) pixel values
    print 'mean-subtracted values:', zip('BGR', mu)

    # create transformer for the input called 'data'
    transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})

    transformer.set_transpose('data', (2,0,1))  # move image channels to outermost dimension
    transformer.set_mean('data', mu)            # subtract the dataset-mean value in each channel
    transformer.set_raw_scale('data', 255)      # rescale from [0, 1] to [0, 255]
    transformer.set_channel_swap('data', (2,1,0))  # swap channels from RGB to BGR


    set_name = "test"
    root_dir = "/home/users/wxie/visual_recognition/data/"
    set_dir = root_dir + set_name + "/"

    # Get a list of the sub-class dir
    class_list = os.listdir(set_dir)

    for cur_class in class_list:
        class_dir = set_dir + cur_class + "/"
        # Get image names for each class
        filename_list = os.listdir(class_dir)
        for filename in filename_list:
            print(class_dir + filename)
            image = caffe.io.load_image(class_dir + filename)
            transformed_image = transformer.preprocess('data', image)
            net.blobs['data'].data[...] = transformed_image
            output = net.forward()
            output_prob = output['prob'][0]  # the output probability vector for the first image in the batch
            print(cur_class)
            print(output_prob)
            print(output_prob.argmax())
            raw_input("Press Enter to continue...")


    # for i, image, label in reader:
    #     out = net.forward_all(data=np.asarray([ image ]))
    #     plabel = int(out['prob'][0].argmax(axis=0))

    #     count += 1
    #     iscorrect = label == plabel
    #     correct += (1 if iscorrect else 0)
    #     matrix[(label, plabel)] += 1
    #     labels_set.update([label, plabel])

    #     if not iscorrect:
    #         print("\rError: i=%s, expected %i but predicted %i" \
    #                 % (i, label, plabel))

    #     sys.stdout.write("\rAccuracy: %.1f%%" % (100.*correct/count))
    #     sys.stdout.flush()

    # print(", %i/%i corrects" % (correct, count))

    # print ""
    # print "Confusion matrix:"
    # print "(r , p) | count"
    # for l in labels_set:
    #     for pl in labels_set:
    #         print "(%i , %i) | %i" % (l, pl, matrix[(l,pl)])
