I0309 12:31:37.312578 55597 caffe.cpp:185] Using GPUs 0
I0309 12:31:37.440682 55597 caffe.cpp:190] GPU 0: Tesla K40m
I0309 12:31:38.325922 55597 solver.cpp:48] Initializing solver from parameters: 
test_iter: 25
test_interval: 300
base_lr: 0.0001
display: 50
max_iter: 100000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 10000
snapshot: 500
snapshot_prefix: "/work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb"
device_id: 0
net: "/work/04018/wxie/maverick/visual_recognition/finetune/train_val_lmdb.prototxt"
I0309 12:31:38.329192 55597 solver.cpp:91] Creating training net from net file: /work/04018/wxie/maverick/visual_recognition/finetune/train_val_lmdb.prototxt
I0309 12:31:38.352363 55597 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0309 12:31:38.352432 55597 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0309 12:31:38.352638 55597 net.cpp:49] Initializing net from parameters: 
name: "FlickrStyleCaffeNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/work/01932/dineshj/CS381V/caffe_install_scripts/caffe/data/ilsvrc12/imagenet_mean.binaryproto"
  }
  data_param {
    source: "/work/04018/wxie/maverick/visual_recognition/data/train-lmdb"
    batch_size: 128
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_subset"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8_subset"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  inner_product_param {
    num_output: 25
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_subset"
  bottom: "label"
  top: "loss"
}
I0309 12:31:38.352936 55597 layer_factory.hpp:77] Creating layer data
I0309 12:31:38.353714 55597 net.cpp:106] Creating Layer data
I0309 12:31:38.353778 55597 net.cpp:411] data -> data
I0309 12:31:38.353890 55597 net.cpp:411] data -> label
I0309 12:31:38.353972 55597 data_transformer.cpp:25] Loading mean file from: /work/01932/dineshj/CS381V/caffe_install_scripts/caffe/data/ilsvrc12/imagenet_mean.binaryproto
I0309 12:31:38.369343 55599 db_lmdb.cpp:38] Opened lmdb /work/04018/wxie/maverick/visual_recognition/data/train-lmdb
I0309 12:31:38.486054 55597 data_layer.cpp:41] output data size: 128,3,227,227
I0309 12:31:38.638173 55597 net.cpp:150] Setting up data
I0309 12:31:38.638303 55597 net.cpp:157] Top shape: 128 3 227 227 (19787136)
I0309 12:31:38.638331 55597 net.cpp:157] Top shape: 128 (128)
I0309 12:31:38.638353 55597 net.cpp:165] Memory required for data: 79149056
I0309 12:31:38.638394 55597 layer_factory.hpp:77] Creating layer conv1
I0309 12:31:38.638478 55597 net.cpp:106] Creating Layer conv1
I0309 12:31:38.638507 55597 net.cpp:454] conv1 <- data
I0309 12:31:38.638561 55597 net.cpp:411] conv1 -> conv1
I0309 12:31:38.648403 55597 net.cpp:150] Setting up conv1
I0309 12:31:38.648447 55597 net.cpp:157] Top shape: 128 96 55 55 (37171200)
I0309 12:31:38.648475 55597 net.cpp:165] Memory required for data: 227833856
I0309 12:31:38.648538 55597 layer_factory.hpp:77] Creating layer relu1
I0309 12:31:38.648578 55597 net.cpp:106] Creating Layer relu1
I0309 12:31:38.648608 55597 net.cpp:454] relu1 <- conv1
I0309 12:31:38.648638 55597 net.cpp:397] relu1 -> conv1 (in-place)
I0309 12:31:38.648672 55597 net.cpp:150] Setting up relu1
I0309 12:31:38.648700 55597 net.cpp:157] Top shape: 128 96 55 55 (37171200)
I0309 12:31:38.648722 55597 net.cpp:165] Memory required for data: 376518656
I0309 12:31:38.648743 55597 layer_factory.hpp:77] Creating layer pool1
I0309 12:31:38.648775 55597 net.cpp:106] Creating Layer pool1
I0309 12:31:38.648803 55597 net.cpp:454] pool1 <- conv1
I0309 12:31:38.648833 55597 net.cpp:411] pool1 -> pool1
I0309 12:31:38.648995 55597 net.cpp:150] Setting up pool1
I0309 12:31:38.649031 55597 net.cpp:157] Top shape: 128 96 27 27 (8957952)
I0309 12:31:38.649116 55597 net.cpp:165] Memory required for data: 412350464
I0309 12:31:38.649145 55597 layer_factory.hpp:77] Creating layer norm1
I0309 12:31:38.649178 55597 net.cpp:106] Creating Layer norm1
I0309 12:31:38.649206 55597 net.cpp:454] norm1 <- pool1
I0309 12:31:38.649238 55597 net.cpp:411] norm1 -> norm1
I0309 12:31:38.649350 55597 net.cpp:150] Setting up norm1
I0309 12:31:38.649390 55597 net.cpp:157] Top shape: 128 96 27 27 (8957952)
I0309 12:31:38.649418 55597 net.cpp:165] Memory required for data: 448182272
I0309 12:31:38.649448 55597 layer_factory.hpp:77] Creating layer conv2
I0309 12:31:38.649482 55597 net.cpp:106] Creating Layer conv2
I0309 12:31:38.649512 55597 net.cpp:454] conv2 <- norm1
I0309 12:31:38.649541 55597 net.cpp:411] conv2 -> conv2
I0309 12:31:38.662063 55597 net.cpp:150] Setting up conv2
I0309 12:31:38.662102 55597 net.cpp:157] Top shape: 128 256 27 27 (23887872)
I0309 12:31:38.662127 55597 net.cpp:165] Memory required for data: 543733760
I0309 12:31:38.662153 55597 layer_factory.hpp:77] Creating layer relu2
I0309 12:31:38.662194 55597 net.cpp:106] Creating Layer relu2
I0309 12:31:38.662217 55597 net.cpp:454] relu2 <- conv2
I0309 12:31:38.662253 55597 net.cpp:397] relu2 -> conv2 (in-place)
I0309 12:31:38.662286 55597 net.cpp:150] Setting up relu2
I0309 12:31:38.662325 55597 net.cpp:157] Top shape: 128 256 27 27 (23887872)
I0309 12:31:38.662348 55597 net.cpp:165] Memory required for data: 639285248
I0309 12:31:38.662371 55597 layer_factory.hpp:77] Creating layer pool2
I0309 12:31:38.662400 55597 net.cpp:106] Creating Layer pool2
I0309 12:31:38.662425 55597 net.cpp:454] pool2 <- conv2
I0309 12:31:38.662451 55597 net.cpp:411] pool2 -> pool2
I0309 12:31:38.662509 55597 net.cpp:150] Setting up pool2
I0309 12:31:38.662555 55597 net.cpp:157] Top shape: 128 256 13 13 (5537792)
I0309 12:31:38.662580 55597 net.cpp:165] Memory required for data: 661436416
I0309 12:31:38.662603 55597 layer_factory.hpp:77] Creating layer norm2
I0309 12:31:38.662631 55597 net.cpp:106] Creating Layer norm2
I0309 12:31:38.662657 55597 net.cpp:454] norm2 <- pool2
I0309 12:31:38.662684 55597 net.cpp:411] norm2 -> norm2
I0309 12:31:38.662741 55597 net.cpp:150] Setting up norm2
I0309 12:31:38.662787 55597 net.cpp:157] Top shape: 128 256 13 13 (5537792)
I0309 12:31:38.662823 55597 net.cpp:165] Memory required for data: 683587584
I0309 12:31:38.662845 55597 layer_factory.hpp:77] Creating layer conv3
I0309 12:31:38.662889 55597 net.cpp:106] Creating Layer conv3
I0309 12:31:38.662914 55597 net.cpp:454] conv3 <- norm2
I0309 12:31:38.662946 55597 net.cpp:411] conv3 -> conv3
I0309 12:31:38.696972 55597 net.cpp:150] Setting up conv3
I0309 12:31:38.697031 55597 net.cpp:157] Top shape: 128 384 13 13 (8306688)
I0309 12:31:38.697054 55597 net.cpp:165] Memory required for data: 716814336
I0309 12:31:38.697095 55597 layer_factory.hpp:77] Creating layer relu3
I0309 12:31:38.697123 55597 net.cpp:106] Creating Layer relu3
I0309 12:31:38.697160 55597 net.cpp:454] relu3 <- conv3
I0309 12:31:38.697188 55597 net.cpp:397] relu3 -> conv3 (in-place)
I0309 12:31:38.697217 55597 net.cpp:150] Setting up relu3
I0309 12:31:38.697245 55597 net.cpp:157] Top shape: 128 384 13 13 (8306688)
I0309 12:31:38.697268 55597 net.cpp:165] Memory required for data: 750041088
I0309 12:31:38.697299 55597 layer_factory.hpp:77] Creating layer conv4
I0309 12:31:38.697330 55597 net.cpp:106] Creating Layer conv4
I0309 12:31:38.697370 55597 net.cpp:454] conv4 <- conv3
I0309 12:31:38.697398 55597 net.cpp:411] conv4 -> conv4
I0309 12:31:38.730607 55597 net.cpp:150] Setting up conv4
I0309 12:31:38.730654 55597 net.cpp:157] Top shape: 128 384 13 13 (8306688)
I0309 12:31:38.730680 55597 net.cpp:165] Memory required for data: 783267840
I0309 12:31:38.730711 55597 layer_factory.hpp:77] Creating layer relu4
I0309 12:31:38.730742 55597 net.cpp:106] Creating Layer relu4
I0309 12:31:38.730768 55597 net.cpp:454] relu4 <- conv4
I0309 12:31:38.730801 55597 net.cpp:397] relu4 -> conv4 (in-place)
I0309 12:31:38.730835 55597 net.cpp:150] Setting up relu4
I0309 12:31:38.730877 55597 net.cpp:157] Top shape: 128 384 13 13 (8306688)
I0309 12:31:38.730916 55597 net.cpp:165] Memory required for data: 816494592
I0309 12:31:38.730938 55597 layer_factory.hpp:77] Creating layer conv5
I0309 12:31:38.730970 55597 net.cpp:106] Creating Layer conv5
I0309 12:31:38.730998 55597 net.cpp:454] conv5 <- conv4
I0309 12:31:38.731030 55597 net.cpp:411] conv5 -> conv5
I0309 12:31:38.748620 55597 net.cpp:150] Setting up conv5
I0309 12:31:38.748667 55597 net.cpp:157] Top shape: 128 256 13 13 (5537792)
I0309 12:31:38.748689 55597 net.cpp:165] Memory required for data: 838645760
I0309 12:31:38.748731 55597 layer_factory.hpp:77] Creating layer relu5
I0309 12:31:38.748760 55597 net.cpp:106] Creating Layer relu5
I0309 12:31:38.748783 55597 net.cpp:454] relu5 <- conv5
I0309 12:31:38.748808 55597 net.cpp:397] relu5 -> conv5 (in-place)
I0309 12:31:38.748836 55597 net.cpp:150] Setting up relu5
I0309 12:31:38.748860 55597 net.cpp:157] Top shape: 128 256 13 13 (5537792)
I0309 12:31:38.748881 55597 net.cpp:165] Memory required for data: 860796928
I0309 12:31:38.748903 55597 layer_factory.hpp:77] Creating layer pool5
I0309 12:31:38.748930 55597 net.cpp:106] Creating Layer pool5
I0309 12:31:38.748955 55597 net.cpp:454] pool5 <- conv5
I0309 12:31:38.748980 55597 net.cpp:411] pool5 -> pool5
I0309 12:31:38.749053 55597 net.cpp:150] Setting up pool5
I0309 12:31:38.749083 55597 net.cpp:157] Top shape: 128 256 6 6 (1179648)
I0309 12:31:38.749104 55597 net.cpp:165] Memory required for data: 865515520
I0309 12:31:38.749125 55597 layer_factory.hpp:77] Creating layer fc6
I0309 12:31:38.749173 55597 net.cpp:106] Creating Layer fc6
I0309 12:31:38.749199 55597 net.cpp:454] fc6 <- pool5
I0309 12:31:38.749227 55597 net.cpp:411] fc6 -> fc6
I0309 12:31:38.895184 55600 blocking_queue.cpp:50] Waiting for data
I0309 12:31:40.163590 55597 net.cpp:150] Setting up fc6
I0309 12:31:40.163719 55597 net.cpp:157] Top shape: 128 4096 (524288)
I0309 12:31:40.163743 55597 net.cpp:165] Memory required for data: 867612672
I0309 12:31:40.163776 55597 layer_factory.hpp:77] Creating layer relu6
I0309 12:31:40.163811 55597 net.cpp:106] Creating Layer relu6
I0309 12:31:40.163836 55597 net.cpp:454] relu6 <- fc6
I0309 12:31:40.163866 55597 net.cpp:397] relu6 -> fc6 (in-place)
I0309 12:31:40.163904 55597 net.cpp:150] Setting up relu6
I0309 12:31:40.163929 55597 net.cpp:157] Top shape: 128 4096 (524288)
I0309 12:31:40.163950 55597 net.cpp:165] Memory required for data: 869709824
I0309 12:31:40.163971 55597 layer_factory.hpp:77] Creating layer drop6
I0309 12:31:40.163997 55597 net.cpp:106] Creating Layer drop6
I0309 12:31:40.164019 55597 net.cpp:454] drop6 <- fc6
I0309 12:31:40.164044 55597 net.cpp:397] drop6 -> fc6 (in-place)
I0309 12:31:40.164135 55597 net.cpp:150] Setting up drop6
I0309 12:31:40.164165 55597 net.cpp:157] Top shape: 128 4096 (524288)
I0309 12:31:40.164187 55597 net.cpp:165] Memory required for data: 871806976
I0309 12:31:40.164208 55597 layer_factory.hpp:77] Creating layer fc7
I0309 12:31:40.164237 55597 net.cpp:106] Creating Layer fc7
I0309 12:31:40.164258 55597 net.cpp:454] fc7 <- fc6
I0309 12:31:40.164289 55597 net.cpp:411] fc7 -> fc7
I0309 12:31:40.776743 55597 net.cpp:150] Setting up fc7
I0309 12:31:40.776876 55597 net.cpp:157] Top shape: 128 4096 (524288)
I0309 12:31:40.776901 55597 net.cpp:165] Memory required for data: 873904128
I0309 12:31:40.776932 55597 layer_factory.hpp:77] Creating layer relu7
I0309 12:31:40.776968 55597 net.cpp:106] Creating Layer relu7
I0309 12:31:40.776991 55597 net.cpp:454] relu7 <- fc7
I0309 12:31:40.777021 55597 net.cpp:397] relu7 -> fc7 (in-place)
I0309 12:31:40.777057 55597 net.cpp:150] Setting up relu7
I0309 12:31:40.777082 55597 net.cpp:157] Top shape: 128 4096 (524288)
I0309 12:31:40.777103 55597 net.cpp:165] Memory required for data: 876001280
I0309 12:31:40.777124 55597 layer_factory.hpp:77] Creating layer drop7
I0309 12:31:40.777151 55597 net.cpp:106] Creating Layer drop7
I0309 12:31:40.777173 55597 net.cpp:454] drop7 <- fc7
I0309 12:31:40.777196 55597 net.cpp:397] drop7 -> fc7 (in-place)
I0309 12:31:40.777267 55597 net.cpp:150] Setting up drop7
I0309 12:31:40.777338 55597 net.cpp:157] Top shape: 128 4096 (524288)
I0309 12:31:40.777359 55597 net.cpp:165] Memory required for data: 878098432
I0309 12:31:40.777381 55597 layer_factory.hpp:77] Creating layer fc8_subset
I0309 12:31:40.777413 55597 net.cpp:106] Creating Layer fc8_subset
I0309 12:31:40.777436 55597 net.cpp:454] fc8_subset <- fc7
I0309 12:31:40.777462 55597 net.cpp:411] fc8_subset -> fc8_subset
I0309 12:31:40.781739 55597 net.cpp:150] Setting up fc8_subset
I0309 12:31:40.781777 55597 net.cpp:157] Top shape: 128 25 (3200)
I0309 12:31:40.781800 55597 net.cpp:165] Memory required for data: 878111232
I0309 12:31:40.781824 55597 layer_factory.hpp:77] Creating layer loss
I0309 12:31:40.781853 55597 net.cpp:106] Creating Layer loss
I0309 12:31:40.781877 55597 net.cpp:454] loss <- fc8_subset
I0309 12:31:40.781899 55597 net.cpp:454] loss <- label
I0309 12:31:40.781927 55597 net.cpp:411] loss -> loss
I0309 12:31:40.781997 55597 layer_factory.hpp:77] Creating layer loss
I0309 12:31:40.782130 55597 net.cpp:150] Setting up loss
I0309 12:31:40.782160 55597 net.cpp:157] Top shape: (1)
I0309 12:31:40.782181 55597 net.cpp:160]     with loss weight 1
I0309 12:31:40.782244 55597 net.cpp:165] Memory required for data: 878111236
I0309 12:31:40.782266 55597 net.cpp:226] loss needs backward computation.
I0309 12:31:40.782294 55597 net.cpp:226] fc8_subset needs backward computation.
I0309 12:31:40.782315 55597 net.cpp:226] drop7 needs backward computation.
I0309 12:31:40.782335 55597 net.cpp:226] relu7 needs backward computation.
I0309 12:31:40.782356 55597 net.cpp:226] fc7 needs backward computation.
I0309 12:31:40.782377 55597 net.cpp:226] drop6 needs backward computation.
I0309 12:31:40.782397 55597 net.cpp:226] relu6 needs backward computation.
I0309 12:31:40.782416 55597 net.cpp:226] fc6 needs backward computation.
I0309 12:31:40.782436 55597 net.cpp:226] pool5 needs backward computation.
I0309 12:31:40.782456 55597 net.cpp:226] relu5 needs backward computation.
I0309 12:31:40.782476 55597 net.cpp:226] conv5 needs backward computation.
I0309 12:31:40.782497 55597 net.cpp:226] relu4 needs backward computation.
I0309 12:31:40.782517 55597 net.cpp:226] conv4 needs backward computation.
I0309 12:31:40.782537 55597 net.cpp:226] relu3 needs backward computation.
I0309 12:31:40.782557 55597 net.cpp:226] conv3 needs backward computation.
I0309 12:31:40.782583 55597 net.cpp:226] norm2 needs backward computation.
I0309 12:31:40.782605 55597 net.cpp:226] pool2 needs backward computation.
I0309 12:31:40.782625 55597 net.cpp:226] relu2 needs backward computation.
I0309 12:31:40.782645 55597 net.cpp:226] conv2 needs backward computation.
I0309 12:31:40.782665 55597 net.cpp:226] norm1 needs backward computation.
I0309 12:31:40.782686 55597 net.cpp:226] pool1 needs backward computation.
I0309 12:31:40.782709 55597 net.cpp:226] relu1 needs backward computation.
I0309 12:31:40.782732 55597 net.cpp:226] conv1 needs backward computation.
I0309 12:31:40.782752 55597 net.cpp:228] data does not need backward computation.
I0309 12:31:40.782773 55597 net.cpp:270] This network produces output loss
I0309 12:31:40.782810 55597 net.cpp:283] Network initialization done.
I0309 12:31:40.784296 55597 solver.cpp:181] Creating test net (#0) specified by net file: /work/04018/wxie/maverick/visual_recognition/finetune/train_val_lmdb.prototxt
I0309 12:31:40.784381 55597 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0309 12:31:40.784611 55597 net.cpp:49] Initializing net from parameters: 
name: "FlickrStyleCaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_file: "/work/01932/dineshj/CS381V/caffe_install_scripts/caffe/data/ilsvrc12/imagenet_mean.binaryproto"
  }
  data_param {
    source: "/work/04018/wxie/maverick/visual_recognition/data/test-lmdb"
    batch_size: 20
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_subset"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8_subset"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  inner_product_param {
    num_output: 25
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_subset"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8_subset"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0309 12:31:40.784791 55597 layer_factory.hpp:77] Creating layer data
I0309 12:31:40.784955 55597 net.cpp:106] Creating Layer data
I0309 12:31:40.784991 55597 net.cpp:411] data -> data
I0309 12:31:40.785032 55597 net.cpp:411] data -> label
I0309 12:31:40.785064 55597 data_transformer.cpp:25] Loading mean file from: /work/01932/dineshj/CS381V/caffe_install_scripts/caffe/data/ilsvrc12/imagenet_mean.binaryproto
I0309 12:31:40.802580 55601 db_lmdb.cpp:38] Opened lmdb /work/04018/wxie/maverick/visual_recognition/data/test-lmdb
I0309 12:31:40.804255 55597 data_layer.cpp:41] output data size: 20,3,227,227
I0309 12:31:40.827661 55597 net.cpp:150] Setting up data
I0309 12:31:40.827749 55597 net.cpp:157] Top shape: 20 3 227 227 (3091740)
I0309 12:31:40.827790 55597 net.cpp:157] Top shape: 20 (20)
I0309 12:31:40.827836 55597 net.cpp:165] Memory required for data: 12367040
I0309 12:31:40.827865 55597 layer_factory.hpp:77] Creating layer label_data_1_split
I0309 12:31:40.827894 55597 net.cpp:106] Creating Layer label_data_1_split
I0309 12:31:40.827919 55597 net.cpp:454] label_data_1_split <- label
I0309 12:31:40.827946 55597 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0309 12:31:40.827982 55597 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0309 12:31:40.828074 55597 net.cpp:150] Setting up label_data_1_split
I0309 12:31:40.828110 55597 net.cpp:157] Top shape: 20 (20)
I0309 12:31:40.828138 55597 net.cpp:157] Top shape: 20 (20)
I0309 12:31:40.828164 55597 net.cpp:165] Memory required for data: 12367200
I0309 12:31:40.828191 55597 layer_factory.hpp:77] Creating layer conv1
I0309 12:31:40.828227 55597 net.cpp:106] Creating Layer conv1
I0309 12:31:40.828255 55597 net.cpp:454] conv1 <- data
I0309 12:31:40.828289 55597 net.cpp:411] conv1 -> conv1
I0309 12:31:40.829864 55597 net.cpp:150] Setting up conv1
I0309 12:31:40.829910 55597 net.cpp:157] Top shape: 20 96 55 55 (5808000)
I0309 12:31:40.829939 55597 net.cpp:165] Memory required for data: 35599200
I0309 12:31:40.829974 55597 layer_factory.hpp:77] Creating layer relu1
I0309 12:31:40.830005 55597 net.cpp:106] Creating Layer relu1
I0309 12:31:40.830032 55597 net.cpp:454] relu1 <- conv1
I0309 12:31:40.830062 55597 net.cpp:397] relu1 -> conv1 (in-place)
I0309 12:31:40.830091 55597 net.cpp:150] Setting up relu1
I0309 12:31:40.830117 55597 net.cpp:157] Top shape: 20 96 55 55 (5808000)
I0309 12:31:40.830138 55597 net.cpp:165] Memory required for data: 58831200
I0309 12:31:40.830163 55597 layer_factory.hpp:77] Creating layer pool1
I0309 12:31:40.830193 55597 net.cpp:106] Creating Layer pool1
I0309 12:31:40.830221 55597 net.cpp:454] pool1 <- conv1
I0309 12:31:40.830252 55597 net.cpp:411] pool1 -> pool1
I0309 12:31:40.830317 55597 net.cpp:150] Setting up pool1
I0309 12:31:40.830354 55597 net.cpp:157] Top shape: 20 96 27 27 (1399680)
I0309 12:31:40.830384 55597 net.cpp:165] Memory required for data: 64429920
I0309 12:31:40.830409 55597 layer_factory.hpp:77] Creating layer norm1
I0309 12:31:40.830438 55597 net.cpp:106] Creating Layer norm1
I0309 12:31:40.830466 55597 net.cpp:454] norm1 <- pool1
I0309 12:31:40.830495 55597 net.cpp:411] norm1 -> norm1
I0309 12:31:40.830554 55597 net.cpp:150] Setting up norm1
I0309 12:31:40.830587 55597 net.cpp:157] Top shape: 20 96 27 27 (1399680)
I0309 12:31:40.830613 55597 net.cpp:165] Memory required for data: 70028640
I0309 12:31:40.830639 55597 layer_factory.hpp:77] Creating layer conv2
I0309 12:31:40.830672 55597 net.cpp:106] Creating Layer conv2
I0309 12:31:40.830720 55597 net.cpp:454] conv2 <- norm1
I0309 12:31:40.830778 55597 net.cpp:411] conv2 -> conv2
I0309 12:31:40.843400 55597 net.cpp:150] Setting up conv2
I0309 12:31:40.843462 55597 net.cpp:157] Top shape: 20 256 27 27 (3732480)
I0309 12:31:40.843488 55597 net.cpp:165] Memory required for data: 84958560
I0309 12:31:40.843524 55597 layer_factory.hpp:77] Creating layer relu2
I0309 12:31:40.843554 55597 net.cpp:106] Creating Layer relu2
I0309 12:31:40.843580 55597 net.cpp:454] relu2 <- conv2
I0309 12:31:40.843618 55597 net.cpp:397] relu2 -> conv2 (in-place)
I0309 12:31:40.843647 55597 net.cpp:150] Setting up relu2
I0309 12:31:40.843674 55597 net.cpp:157] Top shape: 20 256 27 27 (3732480)
I0309 12:31:40.843696 55597 net.cpp:165] Memory required for data: 99888480
I0309 12:31:40.843719 55597 layer_factory.hpp:77] Creating layer pool2
I0309 12:31:40.843746 55597 net.cpp:106] Creating Layer pool2
I0309 12:31:40.843780 55597 net.cpp:454] pool2 <- conv2
I0309 12:31:40.843806 55597 net.cpp:411] pool2 -> pool2
I0309 12:31:40.843873 55597 net.cpp:150] Setting up pool2
I0309 12:31:40.843904 55597 net.cpp:157] Top shape: 20 256 13 13 (865280)
I0309 12:31:40.843926 55597 net.cpp:165] Memory required for data: 103349600
I0309 12:31:40.843947 55597 layer_factory.hpp:77] Creating layer norm2
I0309 12:31:40.843974 55597 net.cpp:106] Creating Layer norm2
I0309 12:31:40.843998 55597 net.cpp:454] norm2 <- pool2
I0309 12:31:40.844023 55597 net.cpp:411] norm2 -> norm2
I0309 12:31:40.844079 55597 net.cpp:150] Setting up norm2
I0309 12:31:40.844108 55597 net.cpp:157] Top shape: 20 256 13 13 (865280)
I0309 12:31:40.844130 55597 net.cpp:165] Memory required for data: 106810720
I0309 12:31:40.844151 55597 layer_factory.hpp:77] Creating layer conv3
I0309 12:31:40.844180 55597 net.cpp:106] Creating Layer conv3
I0309 12:31:40.844204 55597 net.cpp:454] conv3 <- norm2
I0309 12:31:40.844233 55597 net.cpp:411] conv3 -> conv3
I0309 12:31:40.879578 55597 net.cpp:150] Setting up conv3
I0309 12:31:40.879678 55597 net.cpp:157] Top shape: 20 384 13 13 (1297920)
I0309 12:31:40.879706 55597 net.cpp:165] Memory required for data: 112002400
I0309 12:31:40.879745 55597 layer_factory.hpp:77] Creating layer relu3
I0309 12:31:40.879783 55597 net.cpp:106] Creating Layer relu3
I0309 12:31:40.879814 55597 net.cpp:454] relu3 <- conv3
I0309 12:31:40.879847 55597 net.cpp:397] relu3 -> conv3 (in-place)
I0309 12:31:40.879880 55597 net.cpp:150] Setting up relu3
I0309 12:31:40.879917 55597 net.cpp:157] Top shape: 20 384 13 13 (1297920)
I0309 12:31:40.879940 55597 net.cpp:165] Memory required for data: 117194080
I0309 12:31:40.879963 55597 layer_factory.hpp:77] Creating layer conv4
I0309 12:31:40.880005 55597 net.cpp:106] Creating Layer conv4
I0309 12:31:40.880043 55597 net.cpp:454] conv4 <- conv3
I0309 12:31:40.880070 55597 net.cpp:411] conv4 -> conv4
I0309 12:31:40.906409 55597 net.cpp:150] Setting up conv4
I0309 12:31:40.906457 55597 net.cpp:157] Top shape: 20 384 13 13 (1297920)
I0309 12:31:40.906486 55597 net.cpp:165] Memory required for data: 122385760
I0309 12:31:40.906515 55597 layer_factory.hpp:77] Creating layer relu4
I0309 12:31:40.906546 55597 net.cpp:106] Creating Layer relu4
I0309 12:31:40.906574 55597 net.cpp:454] relu4 <- conv4
I0309 12:31:40.906616 55597 net.cpp:397] relu4 -> conv4 (in-place)
I0309 12:31:40.906648 55597 net.cpp:150] Setting up relu4
I0309 12:31:40.906677 55597 net.cpp:157] Top shape: 20 384 13 13 (1297920)
I0309 12:31:40.906702 55597 net.cpp:165] Memory required for data: 127577440
I0309 12:31:40.906728 55597 layer_factory.hpp:77] Creating layer conv5
I0309 12:31:40.906761 55597 net.cpp:106] Creating Layer conv5
I0309 12:31:40.906790 55597 net.cpp:454] conv5 <- conv4
I0309 12:31:40.906823 55597 net.cpp:411] conv5 -> conv5
I0309 12:31:40.924190 55597 net.cpp:150] Setting up conv5
I0309 12:31:40.924233 55597 net.cpp:157] Top shape: 20 256 13 13 (865280)
I0309 12:31:40.924259 55597 net.cpp:165] Memory required for data: 131038560
I0309 12:31:40.924298 55597 layer_factory.hpp:77] Creating layer relu5
I0309 12:31:40.924326 55597 net.cpp:106] Creating Layer relu5
I0309 12:31:40.924407 55597 net.cpp:454] relu5 <- conv5
I0309 12:31:40.924438 55597 net.cpp:397] relu5 -> conv5 (in-place)
I0309 12:31:40.924470 55597 net.cpp:150] Setting up relu5
I0309 12:31:40.924500 55597 net.cpp:157] Top shape: 20 256 13 13 (865280)
I0309 12:31:40.924525 55597 net.cpp:165] Memory required for data: 134499680
I0309 12:31:40.924551 55597 layer_factory.hpp:77] Creating layer pool5
I0309 12:31:40.924582 55597 net.cpp:106] Creating Layer pool5
I0309 12:31:40.924609 55597 net.cpp:454] pool5 <- conv5
I0309 12:31:40.924641 55597 net.cpp:411] pool5 -> pool5
I0309 12:31:40.924705 55597 net.cpp:150] Setting up pool5
I0309 12:31:40.924741 55597 net.cpp:157] Top shape: 20 256 6 6 (184320)
I0309 12:31:40.924767 55597 net.cpp:165] Memory required for data: 135236960
I0309 12:31:40.924793 55597 layer_factory.hpp:77] Creating layer fc6
I0309 12:31:40.924828 55597 net.cpp:106] Creating Layer fc6
I0309 12:31:40.924854 55597 net.cpp:454] fc6 <- pool5
I0309 12:31:40.924885 55597 net.cpp:411] fc6 -> fc6
I0309 12:31:42.304183 55597 net.cpp:150] Setting up fc6
I0309 12:31:42.304322 55597 net.cpp:157] Top shape: 20 4096 (81920)
I0309 12:31:42.304347 55597 net.cpp:165] Memory required for data: 135564640
I0309 12:31:42.304380 55597 layer_factory.hpp:77] Creating layer relu6
I0309 12:31:42.304414 55597 net.cpp:106] Creating Layer relu6
I0309 12:31:42.304437 55597 net.cpp:454] relu6 <- fc6
I0309 12:31:42.304467 55597 net.cpp:397] relu6 -> fc6 (in-place)
I0309 12:31:42.304507 55597 net.cpp:150] Setting up relu6
I0309 12:31:42.304530 55597 net.cpp:157] Top shape: 20 4096 (81920)
I0309 12:31:42.304550 55597 net.cpp:165] Memory required for data: 135892320
I0309 12:31:42.304571 55597 layer_factory.hpp:77] Creating layer drop6
I0309 12:31:42.304599 55597 net.cpp:106] Creating Layer drop6
I0309 12:31:42.304620 55597 net.cpp:454] drop6 <- fc6
I0309 12:31:42.304642 55597 net.cpp:397] drop6 -> fc6 (in-place)
I0309 12:31:42.304695 55597 net.cpp:150] Setting up drop6
I0309 12:31:42.304724 55597 net.cpp:157] Top shape: 20 4096 (81920)
I0309 12:31:42.304745 55597 net.cpp:165] Memory required for data: 136220000
I0309 12:31:42.304766 55597 layer_factory.hpp:77] Creating layer fc7
I0309 12:31:42.304797 55597 net.cpp:106] Creating Layer fc7
I0309 12:31:42.304821 55597 net.cpp:454] fc7 <- fc6
I0309 12:31:42.304844 55597 net.cpp:411] fc7 -> fc7
I0309 12:31:42.917593 55597 net.cpp:150] Setting up fc7
I0309 12:31:42.917722 55597 net.cpp:157] Top shape: 20 4096 (81920)
I0309 12:31:42.917747 55597 net.cpp:165] Memory required for data: 136547680
I0309 12:31:42.917778 55597 layer_factory.hpp:77] Creating layer relu7
I0309 12:31:42.917815 55597 net.cpp:106] Creating Layer relu7
I0309 12:31:42.917840 55597 net.cpp:454] relu7 <- fc7
I0309 12:31:42.917870 55597 net.cpp:397] relu7 -> fc7 (in-place)
I0309 12:31:42.917906 55597 net.cpp:150] Setting up relu7
I0309 12:31:42.917930 55597 net.cpp:157] Top shape: 20 4096 (81920)
I0309 12:31:42.917951 55597 net.cpp:165] Memory required for data: 136875360
I0309 12:31:42.917973 55597 layer_factory.hpp:77] Creating layer drop7
I0309 12:31:42.917999 55597 net.cpp:106] Creating Layer drop7
I0309 12:31:42.918021 55597 net.cpp:454] drop7 <- fc7
I0309 12:31:42.918047 55597 net.cpp:397] drop7 -> fc7 (in-place)
I0309 12:31:42.918097 55597 net.cpp:150] Setting up drop7
I0309 12:31:42.918128 55597 net.cpp:157] Top shape: 20 4096 (81920)
I0309 12:31:42.918148 55597 net.cpp:165] Memory required for data: 137203040
I0309 12:31:42.918169 55597 layer_factory.hpp:77] Creating layer fc8_subset
I0309 12:31:42.918200 55597 net.cpp:106] Creating Layer fc8_subset
I0309 12:31:42.918223 55597 net.cpp:454] fc8_subset <- fc7
I0309 12:31:42.918248 55597 net.cpp:411] fc8_subset -> fc8_subset
I0309 12:31:42.921931 55597 net.cpp:150] Setting up fc8_subset
I0309 12:31:42.921965 55597 net.cpp:157] Top shape: 20 25 (500)
I0309 12:31:42.921988 55597 net.cpp:165] Memory required for data: 137205040
I0309 12:31:42.922011 55597 layer_factory.hpp:77] Creating layer fc8_subset_fc8_subset_0_split
I0309 12:31:42.922070 55597 net.cpp:106] Creating Layer fc8_subset_fc8_subset_0_split
I0309 12:31:42.922149 55597 net.cpp:454] fc8_subset_fc8_subset_0_split <- fc8_subset
I0309 12:31:42.922175 55597 net.cpp:411] fc8_subset_fc8_subset_0_split -> fc8_subset_fc8_subset_0_split_0
I0309 12:31:42.922204 55597 net.cpp:411] fc8_subset_fc8_subset_0_split -> fc8_subset_fc8_subset_0_split_1
I0309 12:31:42.922261 55597 net.cpp:150] Setting up fc8_subset_fc8_subset_0_split
I0309 12:31:42.922297 55597 net.cpp:157] Top shape: 20 25 (500)
I0309 12:31:42.922322 55597 net.cpp:157] Top shape: 20 25 (500)
I0309 12:31:42.922343 55597 net.cpp:165] Memory required for data: 137209040
I0309 12:31:42.922363 55597 layer_factory.hpp:77] Creating layer loss
I0309 12:31:42.922389 55597 net.cpp:106] Creating Layer loss
I0309 12:31:42.922410 55597 net.cpp:454] loss <- fc8_subset_fc8_subset_0_split_0
I0309 12:31:42.922433 55597 net.cpp:454] loss <- label_data_1_split_0
I0309 12:31:42.922461 55597 net.cpp:411] loss -> loss
I0309 12:31:42.922492 55597 layer_factory.hpp:77] Creating layer loss
I0309 12:31:42.922590 55597 net.cpp:150] Setting up loss
I0309 12:31:42.922621 55597 net.cpp:157] Top shape: (1)
I0309 12:31:42.922642 55597 net.cpp:160]     with loss weight 1
I0309 12:31:42.922674 55597 net.cpp:165] Memory required for data: 137209044
I0309 12:31:42.922696 55597 layer_factory.hpp:77] Creating layer accuracy
I0309 12:31:42.922724 55597 net.cpp:106] Creating Layer accuracy
I0309 12:31:42.922747 55597 net.cpp:454] accuracy <- fc8_subset_fc8_subset_0_split_1
I0309 12:31:42.922770 55597 net.cpp:454] accuracy <- label_data_1_split_1
I0309 12:31:42.922793 55597 net.cpp:411] accuracy -> accuracy
I0309 12:31:42.922875 55597 net.cpp:150] Setting up accuracy
I0309 12:31:42.922902 55597 net.cpp:157] Top shape: (1)
I0309 12:31:42.922924 55597 net.cpp:165] Memory required for data: 137209048
I0309 12:31:42.922946 55597 net.cpp:228] accuracy does not need backward computation.
I0309 12:31:42.922968 55597 net.cpp:226] loss needs backward computation.
I0309 12:31:42.922991 55597 net.cpp:226] fc8_subset_fc8_subset_0_split needs backward computation.
I0309 12:31:42.923012 55597 net.cpp:226] fc8_subset needs backward computation.
I0309 12:31:42.923032 55597 net.cpp:226] drop7 needs backward computation.
I0309 12:31:42.923053 55597 net.cpp:226] relu7 needs backward computation.
I0309 12:31:42.923074 55597 net.cpp:226] fc7 needs backward computation.
I0309 12:31:42.923094 55597 net.cpp:226] drop6 needs backward computation.
I0309 12:31:42.923115 55597 net.cpp:226] relu6 needs backward computation.
I0309 12:31:42.923135 55597 net.cpp:226] fc6 needs backward computation.
I0309 12:31:42.923156 55597 net.cpp:226] pool5 needs backward computation.
I0309 12:31:42.923177 55597 net.cpp:226] relu5 needs backward computation.
I0309 12:31:42.923198 55597 net.cpp:226] conv5 needs backward computation.
I0309 12:31:42.923218 55597 net.cpp:226] relu4 needs backward computation.
I0309 12:31:42.923239 55597 net.cpp:226] conv4 needs backward computation.
I0309 12:31:42.923260 55597 net.cpp:226] relu3 needs backward computation.
I0309 12:31:42.923285 55597 net.cpp:226] conv3 needs backward computation.
I0309 12:31:42.923308 55597 net.cpp:226] norm2 needs backward computation.
I0309 12:31:42.923329 55597 net.cpp:226] pool2 needs backward computation.
I0309 12:31:42.923351 55597 net.cpp:226] relu2 needs backward computation.
I0309 12:31:42.923372 55597 net.cpp:226] conv2 needs backward computation.
I0309 12:31:42.923393 55597 net.cpp:226] norm1 needs backward computation.
I0309 12:31:42.923413 55597 net.cpp:226] pool1 needs backward computation.
I0309 12:31:42.923434 55597 net.cpp:226] relu1 needs backward computation.
I0309 12:31:42.923454 55597 net.cpp:226] conv1 needs backward computation.
I0309 12:31:42.923476 55597 net.cpp:228] label_data_1_split does not need backward computation.
I0309 12:31:42.923498 55597 net.cpp:228] data does not need backward computation.
I0309 12:31:42.923518 55597 net.cpp:270] This network produces output accuracy
I0309 12:31:42.923539 55597 net.cpp:270] This network produces output loss
I0309 12:31:42.923590 55597 net.cpp:283] Network initialization done.
I0309 12:31:42.958611 55597 solver.cpp:60] Solver scaffolding done.
I0309 12:31:42.959131 55597 caffe.cpp:129] Finetuning from /work/01932/dineshj/CS381V/caffe_install_scripts/caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I0309 12:31:43.973465 55597 upgrade_proto.cpp:42] Attempting to upgrade input file specified using deprecated transformation parameters: /work/01932/dineshj/CS381V/caffe_install_scripts/caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I0309 12:31:43.973536 55597 upgrade_proto.cpp:45] Successfully upgraded file specified using deprecated data transformation parameters.
W0309 12:31:43.973563 55597 upgrade_proto.cpp:47] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0309 12:31:43.973752 55597 upgrade_proto.cpp:51] Attempting to upgrade input file specified using deprecated V1LayerParameter: /work/01932/dineshj/CS381V/caffe_install_scripts/caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I0309 12:31:44.244092 55597 upgrade_proto.cpp:59] Successfully upgraded file specified using deprecated V1LayerParameter
I0309 12:31:44.285758 55597 net.cpp:816] Ignoring source layer fc8
I0309 12:31:45.030678 55597 upgrade_proto.cpp:42] Attempting to upgrade input file specified using deprecated transformation parameters: /work/01932/dineshj/CS381V/caffe_install_scripts/caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I0309 12:31:45.030768 55597 upgrade_proto.cpp:45] Successfully upgraded file specified using deprecated data transformation parameters.
W0309 12:31:45.030794 55597 upgrade_proto.cpp:47] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0309 12:31:45.030839 55597 upgrade_proto.cpp:51] Attempting to upgrade input file specified using deprecated V1LayerParameter: /work/01932/dineshj/CS381V/caffe_install_scripts/caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I0309 12:31:45.300890 55597 upgrade_proto.cpp:59] Successfully upgraded file specified using deprecated V1LayerParameter
I0309 12:31:45.342705 55597 net.cpp:816] Ignoring source layer fc8
I0309 12:31:45.344472 55597 caffe.cpp:219] Starting Optimization
I0309 12:31:45.344509 55597 solver.cpp:280] Solving FlickrStyleCaffeNet
I0309 12:31:45.344532 55597 solver.cpp:281] Learning Rate Policy: step
I0309 12:31:45.346200 55597 solver.cpp:338] Iteration 0, Testing net (#0)
I0309 12:31:46.531780 55597 solver.cpp:406]     Test net output #0: accuracy = 0.028
I0309 12:31:46.531926 55597 solver.cpp:406]     Test net output #1: loss = 3.5498 (* 1 = 3.5498 loss)
I0309 12:31:47.145826 55597 solver.cpp:229] Iteration 0, loss = 4.01133
I0309 12:31:47.145880 55597 solver.cpp:245]     Train net output #0: loss = 4.01133 (* 1 = 4.01133 loss)
I0309 12:31:47.145946 55597 sgd_solver.cpp:106] Iteration 0, lr = 0.0001
I0309 12:32:25.932085 55597 solver.cpp:229] Iteration 50, loss = 0.487873
I0309 12:32:25.932404 55597 solver.cpp:245]     Train net output #0: loss = 0.487873 (* 1 = 0.487873 loss)
I0309 12:32:25.932438 55597 sgd_solver.cpp:106] Iteration 50, lr = 0.0001
I0309 12:33:04.753556 55597 solver.cpp:229] Iteration 100, loss = 0.390788
I0309 12:33:04.753834 55597 solver.cpp:245]     Train net output #0: loss = 0.390788 (* 1 = 0.390788 loss)
I0309 12:33:04.753868 55597 sgd_solver.cpp:106] Iteration 100, lr = 0.0001
I0309 12:33:43.595021 55597 solver.cpp:229] Iteration 150, loss = 0.482603
I0309 12:33:43.595284 55597 solver.cpp:245]     Train net output #0: loss = 0.482603 (* 1 = 0.482603 loss)
I0309 12:33:43.595319 55597 sgd_solver.cpp:106] Iteration 150, lr = 0.0001
I0309 12:34:22.442960 55597 solver.cpp:229] Iteration 200, loss = 0.327372
I0309 12:34:22.443230 55597 solver.cpp:245]     Train net output #0: loss = 0.327372 (* 1 = 0.327372 loss)
I0309 12:34:22.443264 55597 sgd_solver.cpp:106] Iteration 200, lr = 0.0001
I0309 12:35:01.295042 55597 solver.cpp:229] Iteration 250, loss = 0.347959
I0309 12:35:01.295317 55597 solver.cpp:245]     Train net output #0: loss = 0.347959 (* 1 = 0.347959 loss)
I0309 12:35:01.295351 55597 sgd_solver.cpp:106] Iteration 250, lr = 0.0001
I0309 12:35:39.371093 55597 solver.cpp:338] Iteration 300, Testing net (#0)
I0309 12:35:40.678110 55597 solver.cpp:406]     Test net output #0: accuracy = 0.95
I0309 12:35:40.678320 55597 solver.cpp:406]     Test net output #1: loss = 0.183687 (* 1 = 0.183687 loss)
I0309 12:35:41.279873 55597 solver.cpp:229] Iteration 300, loss = 0.20833
I0309 12:35:41.280055 55597 solver.cpp:245]     Train net output #0: loss = 0.20833 (* 1 = 0.20833 loss)
I0309 12:35:41.280084 55597 sgd_solver.cpp:106] Iteration 300, lr = 0.0001
I0309 12:36:20.132269 55597 solver.cpp:229] Iteration 350, loss = 0.322515
I0309 12:36:20.132536 55597 solver.cpp:245]     Train net output #0: loss = 0.322515 (* 1 = 0.322515 loss)
I0309 12:36:20.132570 55597 sgd_solver.cpp:106] Iteration 350, lr = 0.0001
I0309 12:36:58.988391 55597 solver.cpp:229] Iteration 400, loss = 0.255487
I0309 12:36:58.988591 55597 solver.cpp:245]     Train net output #0: loss = 0.255487 (* 1 = 0.255487 loss)
I0309 12:36:58.988626 55597 sgd_solver.cpp:106] Iteration 400, lr = 0.0001
I0309 12:37:37.840773 55597 solver.cpp:229] Iteration 450, loss = 0.130419
I0309 12:37:37.840967 55597 solver.cpp:245]     Train net output #0: loss = 0.130419 (* 1 = 0.130419 loss)
I0309 12:37:37.841001 55597 sgd_solver.cpp:106] Iteration 450, lr = 0.0001
I0309 12:38:15.908792 55597 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_500.caffemodel
I0309 12:38:17.623757 55597 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_500.solverstate
I0309 12:38:19.147325 55597 solver.cpp:229] Iteration 500, loss = 0.179349
I0309 12:38:19.147413 55597 solver.cpp:245]     Train net output #0: loss = 0.179349 (* 1 = 0.179349 loss)
I0309 12:38:19.147444 55597 sgd_solver.cpp:106] Iteration 500, lr = 0.0001
I0309 12:38:57.998680 55597 solver.cpp:229] Iteration 550, loss = 0.180358
I0309 12:38:57.998898 55597 solver.cpp:245]     Train net output #0: loss = 0.180358 (* 1 = 0.180358 loss)
I0309 12:38:57.998932 55597 sgd_solver.cpp:106] Iteration 550, lr = 0.0001
I0309 12:39:36.084183 55597 solver.cpp:338] Iteration 600, Testing net (#0)
I0309 12:39:37.391811 55597 solver.cpp:406]     Test net output #0: accuracy = 0.95
I0309 12:39:37.392019 55597 solver.cpp:406]     Test net output #1: loss = 0.159139 (* 1 = 0.159139 loss)
I0309 12:39:37.991614 55597 solver.cpp:229] Iteration 600, loss = 0.258056
I0309 12:39:37.991760 55597 solver.cpp:245]     Train net output #0: loss = 0.258056 (* 1 = 0.258056 loss)
I0309 12:39:37.991791 55597 sgd_solver.cpp:106] Iteration 600, lr = 0.0001
I0309 12:40:16.853655 55597 solver.cpp:229] Iteration 650, loss = 0.202831
I0309 12:40:16.853875 55597 solver.cpp:245]     Train net output #0: loss = 0.202831 (* 1 = 0.202831 loss)
I0309 12:40:16.853909 55597 sgd_solver.cpp:106] Iteration 650, lr = 0.0001
I0309 12:40:55.703985 55597 solver.cpp:229] Iteration 700, loss = 0.217862
I0309 12:40:55.704187 55597 solver.cpp:245]     Train net output #0: loss = 0.217862 (* 1 = 0.217862 loss)
I0309 12:40:55.704226 55597 sgd_solver.cpp:106] Iteration 700, lr = 0.0001
I0309 12:41:34.559026 55597 solver.cpp:229] Iteration 750, loss = 0.311334
I0309 12:41:34.559223 55597 solver.cpp:245]     Train net output #0: loss = 0.311334 (* 1 = 0.311334 loss)
I0309 12:41:34.559258 55597 sgd_solver.cpp:106] Iteration 750, lr = 0.0001
I0309 12:42:13.416879 55597 solver.cpp:229] Iteration 800, loss = 0.224978
I0309 12:42:13.417067 55597 solver.cpp:245]     Train net output #0: loss = 0.224978 (* 1 = 0.224978 loss)
I0309 12:42:13.417099 55597 sgd_solver.cpp:106] Iteration 800, lr = 0.0001
I0309 12:42:52.270428 55597 solver.cpp:229] Iteration 850, loss = 0.245462
I0309 12:42:52.270653 55597 solver.cpp:245]     Train net output #0: loss = 0.245462 (* 1 = 0.245462 loss)
I0309 12:42:52.270701 55597 sgd_solver.cpp:106] Iteration 850, lr = 0.0001
I0309 12:43:30.361054 55597 solver.cpp:338] Iteration 900, Testing net (#0)
I0309 12:43:31.667377 55597 solver.cpp:406]     Test net output #0: accuracy = 0.958
I0309 12:43:31.667573 55597 solver.cpp:406]     Test net output #1: loss = 0.151615 (* 1 = 0.151615 loss)
I0309 12:43:32.267767 55597 solver.cpp:229] Iteration 900, loss = 0.317143
I0309 12:43:32.267910 55597 solver.cpp:245]     Train net output #0: loss = 0.317143 (* 1 = 0.317143 loss)
I0309 12:43:32.267941 55597 sgd_solver.cpp:106] Iteration 900, lr = 0.0001
I0309 12:44:11.121662 55597 solver.cpp:229] Iteration 950, loss = 0.219694
I0309 12:44:11.121894 55597 solver.cpp:245]     Train net output #0: loss = 0.219694 (* 1 = 0.219694 loss)
I0309 12:44:11.121929 55597 sgd_solver.cpp:106] Iteration 950, lr = 0.0001
I0309 12:44:49.203833 55597 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_1000.caffemodel
I0309 12:44:50.840579 55597 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_1000.solverstate
I0309 12:44:52.380631 55597 solver.cpp:229] Iteration 1000, loss = 0.196445
I0309 12:44:52.380717 55597 solver.cpp:245]     Train net output #0: loss = 0.196445 (* 1 = 0.196445 loss)
I0309 12:44:52.380746 55597 sgd_solver.cpp:106] Iteration 1000, lr = 0.0001
I0309 12:45:31.241686 55597 solver.cpp:229] Iteration 1050, loss = 0.246405
I0309 12:45:31.241967 55597 solver.cpp:245]     Train net output #0: loss = 0.246405 (* 1 = 0.246405 loss)
I0309 12:45:31.242002 55597 sgd_solver.cpp:106] Iteration 1050, lr = 0.0001
I0309 12:46:10.087461 55597 solver.cpp:229] Iteration 1100, loss = 0.140296
I0309 12:46:10.087661 55597 solver.cpp:245]     Train net output #0: loss = 0.140296 (* 1 = 0.140296 loss)
I0309 12:46:10.087694 55597 sgd_solver.cpp:106] Iteration 1100, lr = 0.0001
I0309 12:46:48.949133 55597 solver.cpp:229] Iteration 1150, loss = 0.28931
I0309 12:46:48.949331 55597 solver.cpp:245]     Train net output #0: loss = 0.28931 (* 1 = 0.28931 loss)
I0309 12:46:48.949364 55597 sgd_solver.cpp:106] Iteration 1150, lr = 0.0001
I0309 12:47:27.034925 55597 solver.cpp:338] Iteration 1200, Testing net (#0)
I0309 12:47:28.342367 55597 solver.cpp:406]     Test net output #0: accuracy = 0.962
I0309 12:47:28.342500 55597 solver.cpp:406]     Test net output #1: loss = 0.13728 (* 1 = 0.13728 loss)
I0309 12:47:28.943311 55597 solver.cpp:229] Iteration 1200, loss = 0.269987
I0309 12:47:28.943356 55597 solver.cpp:245]     Train net output #0: loss = 0.269987 (* 1 = 0.269987 loss)
I0309 12:47:28.943384 55597 sgd_solver.cpp:106] Iteration 1200, lr = 0.0001
I0309 12:48:07.805563 55597 solver.cpp:229] Iteration 1250, loss = 0.166116
I0309 12:48:07.805775 55597 solver.cpp:245]     Train net output #0: loss = 0.166116 (* 1 = 0.166116 loss)
I0309 12:48:07.805809 55597 sgd_solver.cpp:106] Iteration 1250, lr = 0.0001
I0309 12:48:46.663094 55597 solver.cpp:229] Iteration 1300, loss = 0.21349
I0309 12:48:46.663300 55597 solver.cpp:245]     Train net output #0: loss = 0.21349 (* 1 = 0.21349 loss)
I0309 12:48:46.663333 55597 sgd_solver.cpp:106] Iteration 1300, lr = 0.0001
I0309 12:49:25.508919 55597 solver.cpp:229] Iteration 1350, loss = 0.120389
I0309 12:49:25.509109 55597 solver.cpp:245]     Train net output #0: loss = 0.120389 (* 1 = 0.120389 loss)
I0309 12:49:25.509141 55597 sgd_solver.cpp:106] Iteration 1350, lr = 0.0001
I0309 12:50:04.364209 55597 solver.cpp:229] Iteration 1400, loss = 0.121077
I0309 12:50:04.364406 55597 solver.cpp:245]     Train net output #0: loss = 0.121077 (* 1 = 0.121077 loss)
I0309 12:50:04.364439 55597 sgd_solver.cpp:106] Iteration 1400, lr = 0.0001
I0309 12:50:43.209383 55597 solver.cpp:229] Iteration 1450, loss = 0.121682
I0309 12:50:43.209586 55597 solver.cpp:245]     Train net output #0: loss = 0.121682 (* 1 = 0.121682 loss)
I0309 12:50:43.209619 55597 sgd_solver.cpp:106] Iteration 1450, lr = 0.0001
I0309 12:51:21.292533 55597 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_1500.caffemodel
I0309 12:51:22.925712 55597 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_1500.solverstate
I0309 12:51:23.864960 55597 solver.cpp:338] Iteration 1500, Testing net (#0)
I0309 12:51:25.001804 55597 solver.cpp:406]     Test net output #0: accuracy = 0.966
I0309 12:51:25.001943 55597 solver.cpp:406]     Test net output #1: loss = 0.13578 (* 1 = 0.13578 loss)
I0309 12:51:25.602046 55597 solver.cpp:229] Iteration 1500, loss = 0.16121
I0309 12:51:25.602090 55597 solver.cpp:245]     Train net output #0: loss = 0.16121 (* 1 = 0.16121 loss)
I0309 12:51:25.602118 55597 sgd_solver.cpp:106] Iteration 1500, lr = 0.0001
I0309 12:52:04.447612 55597 solver.cpp:229] Iteration 1550, loss = 0.198016
I0309 12:52:04.447841 55597 solver.cpp:245]     Train net output #0: loss = 0.198016 (* 1 = 0.198016 loss)
I0309 12:52:04.447875 55597 sgd_solver.cpp:106] Iteration 1550, lr = 0.0001
I0309 12:52:43.305826 55597 solver.cpp:229] Iteration 1600, loss = 0.233868
I0309 12:52:43.306012 55597 solver.cpp:245]     Train net output #0: loss = 0.233868 (* 1 = 0.233868 loss)
I0309 12:52:43.306046 55597 sgd_solver.cpp:106] Iteration 1600, lr = 0.0001
I0309 12:53:22.158370 55597 solver.cpp:229] Iteration 1650, loss = 0.241903
I0309 12:53:22.158571 55597 solver.cpp:245]     Train net output #0: loss = 0.241903 (* 1 = 0.241903 loss)
I0309 12:53:22.158604 55597 sgd_solver.cpp:106] Iteration 1650, lr = 0.0001
I0309 12:54:01.013166 55597 solver.cpp:229] Iteration 1700, loss = 0.158187
I0309 12:54:01.013356 55597 solver.cpp:245]     Train net output #0: loss = 0.158187 (* 1 = 0.158187 loss)
I0309 12:54:01.013389 55597 sgd_solver.cpp:106] Iteration 1700, lr = 0.0001
I0309 12:54:39.861750 55597 solver.cpp:229] Iteration 1750, loss = 0.121753
I0309 12:54:39.861945 55597 solver.cpp:245]     Train net output #0: loss = 0.121753 (* 1 = 0.121753 loss)
I0309 12:54:39.861979 55597 sgd_solver.cpp:106] Iteration 1750, lr = 0.0001
I0309 12:55:17.945235 55597 solver.cpp:338] Iteration 1800, Testing net (#0)
I0309 12:55:19.251809 55597 solver.cpp:406]     Test net output #0: accuracy = 0.958
I0309 12:55:19.251942 55597 solver.cpp:406]     Test net output #1: loss = 0.136496 (* 1 = 0.136496 loss)
I0309 12:55:19.851848 55597 solver.cpp:229] Iteration 1800, loss = 0.165412
I0309 12:55:19.851891 55597 solver.cpp:245]     Train net output #0: loss = 0.165412 (* 1 = 0.165412 loss)
I0309 12:55:19.851919 55597 sgd_solver.cpp:106] Iteration 1800, lr = 0.0001
I0309 12:55:58.704809 55597 solver.cpp:229] Iteration 1850, loss = 0.250484
I0309 12:55:58.705011 55597 solver.cpp:245]     Train net output #0: loss = 0.250484 (* 1 = 0.250484 loss)
I0309 12:55:58.705044 55597 sgd_solver.cpp:106] Iteration 1850, lr = 0.0001
I0309 12:56:37.555945 55597 solver.cpp:229] Iteration 1900, loss = 0.137871
I0309 12:56:37.556148 55597 solver.cpp:245]     Train net output #0: loss = 0.137872 (* 1 = 0.137872 loss)
I0309 12:56:37.556180 55597 sgd_solver.cpp:106] Iteration 1900, lr = 0.0001
I0309 12:57:16.409972 55597 solver.cpp:229] Iteration 1950, loss = 0.118415
I0309 12:57:16.410162 55597 solver.cpp:245]     Train net output #0: loss = 0.118415 (* 1 = 0.118415 loss)
I0309 12:57:16.410194 55597 sgd_solver.cpp:106] Iteration 1950, lr = 0.0001
I0309 12:57:54.486281 55597 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_2000.caffemodel
I0309 12:57:57.217030 55597 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_2000.solverstate
I0309 12:57:58.753967 55597 solver.cpp:229] Iteration 2000, loss = 0.0896927
I0309 12:57:58.754052 55597 solver.cpp:245]     Train net output #0: loss = 0.0896927 (* 1 = 0.0896927 loss)
I0309 12:57:58.754081 55597 sgd_solver.cpp:106] Iteration 2000, lr = 0.0001
I0309 12:58:37.611464 55597 solver.cpp:229] Iteration 2050, loss = 0.189198
I0309 12:58:37.611693 55597 solver.cpp:245]     Train net output #0: loss = 0.189198 (* 1 = 0.189198 loss)
I0309 12:58:37.611726 55597 sgd_solver.cpp:106] Iteration 2050, lr = 0.0001
I0309 12:59:15.695751 55597 solver.cpp:338] Iteration 2100, Testing net (#0)
I0309 12:59:17.002387 55597 solver.cpp:406]     Test net output #0: accuracy = 0.962
I0309 12:59:17.002531 55597 solver.cpp:406]     Test net output #1: loss = 0.128161 (* 1 = 0.128161 loss)
I0309 12:59:17.602900 55597 solver.cpp:229] Iteration 2100, loss = 0.123177
I0309 12:59:17.602944 55597 solver.cpp:245]     Train net output #0: loss = 0.123177 (* 1 = 0.123177 loss)
I0309 12:59:17.602973 55597 sgd_solver.cpp:106] Iteration 2100, lr = 0.0001
I0309 12:59:56.458195 55597 solver.cpp:229] Iteration 2150, loss = 0.108906
I0309 12:59:56.458420 55597 solver.cpp:245]     Train net output #0: loss = 0.108906 (* 1 = 0.108906 loss)
I0309 12:59:56.458452 55597 sgd_solver.cpp:106] Iteration 2150, lr = 0.0001
I0309 13:00:35.349722 55597 solver.cpp:229] Iteration 2200, loss = 0.154035
I0309 13:00:35.350100 55597 solver.cpp:245]     Train net output #0: loss = 0.154035 (* 1 = 0.154035 loss)
I0309 13:00:35.350134 55597 sgd_solver.cpp:106] Iteration 2200, lr = 0.0001
I0309 13:01:14.232491 55597 solver.cpp:229] Iteration 2250, loss = 0.184003
I0309 13:01:14.232709 55597 solver.cpp:245]     Train net output #0: loss = 0.184003 (* 1 = 0.184003 loss)
I0309 13:01:14.232743 55597 sgd_solver.cpp:106] Iteration 2250, lr = 0.0001
I0309 13:01:53.118333 55597 solver.cpp:229] Iteration 2300, loss = 0.0823217
I0309 13:01:53.118549 55597 solver.cpp:245]     Train net output #0: loss = 0.0823217 (* 1 = 0.0823217 loss)
I0309 13:01:53.118582 55597 sgd_solver.cpp:106] Iteration 2300, lr = 0.0001
I0309 13:02:31.997771 55597 solver.cpp:229] Iteration 2350, loss = 0.0720582
I0309 13:02:31.997982 55597 solver.cpp:245]     Train net output #0: loss = 0.0720582 (* 1 = 0.0720582 loss)
I0309 13:02:31.998014 55597 sgd_solver.cpp:106] Iteration 2350, lr = 0.0001
I0309 13:03:10.113590 55597 solver.cpp:338] Iteration 2400, Testing net (#0)
I0309 13:03:11.421290 55597 solver.cpp:406]     Test net output #0: accuracy = 0.966
I0309 13:03:11.421479 55597 solver.cpp:406]     Test net output #1: loss = 0.13075 (* 1 = 0.13075 loss)
I0309 13:03:12.023214 55597 solver.cpp:229] Iteration 2400, loss = 0.132433
I0309 13:03:12.023258 55597 solver.cpp:245]     Train net output #0: loss = 0.132433 (* 1 = 0.132433 loss)
I0309 13:03:12.023288 55597 sgd_solver.cpp:106] Iteration 2400, lr = 0.0001
I0309 13:03:50.897016 55597 solver.cpp:229] Iteration 2450, loss = 0.224463
I0309 13:03:50.897244 55597 solver.cpp:245]     Train net output #0: loss = 0.224463 (* 1 = 0.224463 loss)
I0309 13:03:50.897277 55597 sgd_solver.cpp:106] Iteration 2450, lr = 0.0001
I0309 13:04:29.008201 55597 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_2500.caffemodel
I0309 13:04:30.659260 55597 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_2500.solverstate
I0309 13:04:32.182441 55597 solver.cpp:229] Iteration 2500, loss = 0.161029
I0309 13:04:32.182520 55597 solver.cpp:245]     Train net output #0: loss = 0.161029 (* 1 = 0.161029 loss)
I0309 13:04:32.182549 55597 sgd_solver.cpp:106] Iteration 2500, lr = 0.0001
I0309 13:05:11.070436 55597 solver.cpp:229] Iteration 2550, loss = 0.0987959
I0309 13:05:11.070679 55597 solver.cpp:245]     Train net output #0: loss = 0.0987959 (* 1 = 0.0987959 loss)
I0309 13:05:11.070713 55597 sgd_solver.cpp:106] Iteration 2550, lr = 0.0001
I0309 13:05:49.964979 55597 solver.cpp:229] Iteration 2600, loss = 0.0559586
I0309 13:05:49.965196 55597 solver.cpp:245]     Train net output #0: loss = 0.0559586 (* 1 = 0.0559586 loss)
I0309 13:05:49.965229 55597 sgd_solver.cpp:106] Iteration 2600, lr = 0.0001
I0309 13:06:28.853364 55597 solver.cpp:229] Iteration 2650, loss = 0.0667748
I0309 13:06:28.853603 55597 solver.cpp:245]     Train net output #0: loss = 0.0667748 (* 1 = 0.0667748 loss)
I0309 13:06:28.853636 55597 sgd_solver.cpp:106] Iteration 2650, lr = 0.0001
I0309 13:07:06.971312 55597 solver.cpp:338] Iteration 2700, Testing net (#0)
I0309 13:07:08.279773 55597 solver.cpp:406]     Test net output #0: accuracy = 0.958
I0309 13:07:08.279956 55597 solver.cpp:406]     Test net output #1: loss = 0.125762 (* 1 = 0.125762 loss)
I0309 13:07:08.881937 55597 solver.cpp:229] Iteration 2700, loss = 0.168805
I0309 13:07:08.881979 55597 solver.cpp:245]     Train net output #0: loss = 0.168805 (* 1 = 0.168805 loss)
I0309 13:07:08.882007 55597 sgd_solver.cpp:106] Iteration 2700, lr = 0.0001
I0309 13:07:47.765388 55597 solver.cpp:229] Iteration 2750, loss = 0.15402
I0309 13:07:47.765621 55597 solver.cpp:245]     Train net output #0: loss = 0.15402 (* 1 = 0.15402 loss)
I0309 13:07:47.765655 55597 sgd_solver.cpp:106] Iteration 2750, lr = 0.0001
I0309 13:08:26.654093 55597 solver.cpp:229] Iteration 2800, loss = 0.0811937
I0309 13:08:26.654312 55597 solver.cpp:245]     Train net output #0: loss = 0.0811937 (* 1 = 0.0811937 loss)
I0309 13:08:26.654345 55597 sgd_solver.cpp:106] Iteration 2800, lr = 0.0001
I0309 13:09:05.531258 55597 solver.cpp:229] Iteration 2850, loss = 0.152339
I0309 13:09:05.531471 55597 solver.cpp:245]     Train net output #0: loss = 0.152339 (* 1 = 0.152339 loss)
I0309 13:09:05.531502 55597 sgd_solver.cpp:106] Iteration 2850, lr = 0.0001
I0309 13:09:44.414563 55597 solver.cpp:229] Iteration 2900, loss = 0.176249
I0309 13:09:44.414752 55597 solver.cpp:245]     Train net output #0: loss = 0.176249 (* 1 = 0.176249 loss)
I0309 13:09:44.414785 55597 sgd_solver.cpp:106] Iteration 2900, lr = 0.0001
I0309 13:10:23.297410 55597 solver.cpp:229] Iteration 2950, loss = 0.0977705
I0309 13:10:23.297621 55597 solver.cpp:245]     Train net output #0: loss = 0.0977706 (* 1 = 0.0977706 loss)
I0309 13:10:23.297653 55597 sgd_solver.cpp:106] Iteration 2950, lr = 0.0001
I0309 13:11:01.410996 55597 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_3000.caffemodel
I0309 13:11:03.053583 55597 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_3000.solverstate
I0309 13:11:03.980542 55597 solver.cpp:338] Iteration 3000, Testing net (#0)
I0309 13:11:05.119056 55597 solver.cpp:406]     Test net output #0: accuracy = 0.962
I0309 13:11:05.119235 55597 solver.cpp:406]     Test net output #1: loss = 0.12378 (* 1 = 0.12378 loss)
I0309 13:11:05.721382 55597 solver.cpp:229] Iteration 3000, loss = 0.180351
I0309 13:11:05.721426 55597 solver.cpp:245]     Train net output #0: loss = 0.180351 (* 1 = 0.180351 loss)
I0309 13:11:05.721456 55597 sgd_solver.cpp:106] Iteration 3000, lr = 0.0001
I0309 13:11:44.602576 55597 solver.cpp:229] Iteration 3050, loss = 0.176067
I0309 13:11:44.602826 55597 solver.cpp:245]     Train net output #0: loss = 0.176067 (* 1 = 0.176067 loss)
I0309 13:11:44.602859 55597 sgd_solver.cpp:106] Iteration 3050, lr = 0.0001
I0309 13:12:23.486908 55597 solver.cpp:229] Iteration 3100, loss = 0.0749522
I0309 13:12:23.487118 55597 solver.cpp:245]     Train net output #0: loss = 0.0749523 (* 1 = 0.0749523 loss)
I0309 13:12:23.487149 55597 sgd_solver.cpp:106] Iteration 3100, lr = 0.0001
I0309 13:13:02.371471 55597 solver.cpp:229] Iteration 3150, loss = 0.132566
I0309 13:13:02.371681 55597 solver.cpp:245]     Train net output #0: loss = 0.132566 (* 1 = 0.132566 loss)
I0309 13:13:02.371714 55597 sgd_solver.cpp:106] Iteration 3150, lr = 0.0001
I0309 13:13:41.252687 55597 solver.cpp:229] Iteration 3200, loss = 0.0833049
I0309 13:13:41.252897 55597 solver.cpp:245]     Train net output #0: loss = 0.0833049 (* 1 = 0.0833049 loss)
I0309 13:13:41.252928 55597 sgd_solver.cpp:106] Iteration 3200, lr = 0.0001
I0309 13:14:20.134166 55597 solver.cpp:229] Iteration 3250, loss = 0.241689
I0309 13:14:20.134392 55597 solver.cpp:245]     Train net output #0: loss = 0.241689 (* 1 = 0.241689 loss)
I0309 13:14:20.134439 55597 sgd_solver.cpp:106] Iteration 3250, lr = 0.0001
I0309 13:14:58.243993 55597 solver.cpp:338] Iteration 3300, Testing net (#0)
I0309 13:14:59.550596 55597 solver.cpp:406]     Test net output #0: accuracy = 0.96
I0309 13:14:59.550786 55597 solver.cpp:406]     Test net output #1: loss = 0.123803 (* 1 = 0.123803 loss)
I0309 13:15:00.150985 55597 solver.cpp:229] Iteration 3300, loss = 0.106657
I0309 13:15:00.151029 55597 solver.cpp:245]     Train net output #0: loss = 0.106657 (* 1 = 0.106657 loss)
I0309 13:15:00.151058 55597 sgd_solver.cpp:106] Iteration 3300, lr = 0.0001
I0309 13:15:39.038287 55597 solver.cpp:229] Iteration 3350, loss = 0.164233
I0309 13:15:39.038529 55597 solver.cpp:245]     Train net output #0: loss = 0.164233 (* 1 = 0.164233 loss)
I0309 13:15:39.038563 55597 sgd_solver.cpp:106] Iteration 3350, lr = 0.0001
I0309 13:16:17.932929 55597 solver.cpp:229] Iteration 3400, loss = 0.110687
I0309 13:16:17.933137 55597 solver.cpp:245]     Train net output #0: loss = 0.110687 (* 1 = 0.110687 loss)
I0309 13:16:17.933169 55597 sgd_solver.cpp:106] Iteration 3400, lr = 0.0001
I0309 13:16:56.818616 55597 solver.cpp:229] Iteration 3450, loss = 0.1056
I0309 13:16:56.818799 55597 solver.cpp:245]     Train net output #0: loss = 0.1056 (* 1 = 0.1056 loss)
I0309 13:16:56.818832 55597 sgd_solver.cpp:106] Iteration 3450, lr = 0.0001
I0309 13:17:34.933504 55597 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_3500.caffemodel
I0309 13:17:36.579423 55597 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_3500.solverstate
I0309 13:17:38.104800 55597 solver.cpp:229] Iteration 3500, loss = 0.0733043
I0309 13:17:38.104881 55597 solver.cpp:245]     Train net output #0: loss = 0.0733043 (* 1 = 0.0733043 loss)
I0309 13:17:38.104909 55597 sgd_solver.cpp:106] Iteration 3500, lr = 0.0001
I0309 13:18:16.990360 55597 solver.cpp:229] Iteration 3550, loss = 0.067057
I0309 13:18:16.990602 55597 solver.cpp:245]     Train net output #0: loss = 0.067057 (* 1 = 0.067057 loss)
I0309 13:18:16.990635 55597 sgd_solver.cpp:106] Iteration 3550, lr = 0.0001
I0309 13:18:55.113276 55597 solver.cpp:338] Iteration 3600, Testing net (#0)
I0309 13:18:56.420977 55597 solver.cpp:406]     Test net output #0: accuracy = 0.968
I0309 13:18:56.421161 55597 solver.cpp:406]     Test net output #1: loss = 0.127771 (* 1 = 0.127771 loss)
I0309 13:18:57.022173 55597 solver.cpp:229] Iteration 3600, loss = 0.207685
I0309 13:18:57.022229 55597 solver.cpp:245]     Train net output #0: loss = 0.207685 (* 1 = 0.207685 loss)
I0309 13:18:57.022259 55597 sgd_solver.cpp:106] Iteration 3600, lr = 0.0001
I0309 13:19:35.906517 55597 solver.cpp:229] Iteration 3650, loss = 0.116003
I0309 13:19:35.906733 55597 solver.cpp:245]     Train net output #0: loss = 0.116003 (* 1 = 0.116003 loss)
I0309 13:19:35.906765 55597 sgd_solver.cpp:106] Iteration 3650, lr = 0.0001
I0309 13:20:14.794464 55597 solver.cpp:229] Iteration 3700, loss = 0.06319
I0309 13:20:14.794677 55597 solver.cpp:245]     Train net output #0: loss = 0.0631901 (* 1 = 0.0631901 loss)
I0309 13:20:14.794710 55597 sgd_solver.cpp:106] Iteration 3700, lr = 0.0001
I0309 13:20:53.689383 55597 solver.cpp:229] Iteration 3750, loss = 0.113961
I0309 13:20:53.689563 55597 solver.cpp:245]     Train net output #0: loss = 0.113961 (* 1 = 0.113961 loss)
I0309 13:20:53.689596 55597 sgd_solver.cpp:106] Iteration 3750, lr = 0.0001
I0309 13:21:32.579089 55597 solver.cpp:229] Iteration 3800, loss = 0.178902
I0309 13:21:32.579303 55597 solver.cpp:245]     Train net output #0: loss = 0.178903 (* 1 = 0.178903 loss)
I0309 13:21:32.579335 55597 sgd_solver.cpp:106] Iteration 3800, lr = 0.0001
I0309 13:22:11.458729 55597 solver.cpp:229] Iteration 3850, loss = 0.152178
I0309 13:22:11.469995 55597 solver.cpp:245]     Train net output #0: loss = 0.152178 (* 1 = 0.152178 loss)
I0309 13:22:11.470028 55597 sgd_solver.cpp:106] Iteration 3850, lr = 0.0001
I0309 13:22:49.565984 55597 solver.cpp:338] Iteration 3900, Testing net (#0)
I0309 13:22:50.872736 55597 solver.cpp:406]     Test net output #0: accuracy = 0.962
I0309 13:22:50.872921 55597 solver.cpp:406]     Test net output #1: loss = 0.118614 (* 1 = 0.118614 loss)
I0309 13:22:51.474166 55597 solver.cpp:229] Iteration 3900, loss = 0.152417
I0309 13:22:51.474210 55597 solver.cpp:245]     Train net output #0: loss = 0.152417 (* 1 = 0.152417 loss)
I0309 13:22:51.474239 55597 sgd_solver.cpp:106] Iteration 3900, lr = 0.0001
I0309 13:23:30.355106 55597 solver.cpp:229] Iteration 3950, loss = 0.0537009
I0309 13:23:30.355357 55597 solver.cpp:245]     Train net output #0: loss = 0.053701 (* 1 = 0.053701 loss)
I0309 13:23:30.355391 55597 sgd_solver.cpp:106] Iteration 3950, lr = 0.0001
I0309 13:24:08.463049 55597 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_4000.caffemodel
I0309 13:24:10.115685 55597 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_4000.solverstate
I0309 13:24:11.637627 55597 solver.cpp:229] Iteration 4000, loss = 0.150595
I0309 13:24:11.637712 55597 solver.cpp:245]     Train net output #0: loss = 0.150595 (* 1 = 0.150595 loss)
I0309 13:24:11.637742 55597 sgd_solver.cpp:106] Iteration 4000, lr = 0.0001
I0309 13:24:50.523450 55597 solver.cpp:229] Iteration 4050, loss = 0.091188
I0309 13:24:50.523658 55597 solver.cpp:245]     Train net output #0: loss = 0.0911881 (* 1 = 0.0911881 loss)
I0309 13:24:50.523690 55597 sgd_solver.cpp:106] Iteration 4050, lr = 0.0001
I0309 13:25:29.403127 55597 solver.cpp:229] Iteration 4100, loss = 0.125976
I0309 13:25:29.403336 55597 solver.cpp:245]     Train net output #0: loss = 0.125976 (* 1 = 0.125976 loss)
I0309 13:25:29.403368 55597 sgd_solver.cpp:106] Iteration 4100, lr = 0.0001
I0309 13:26:08.295583 55597 solver.cpp:229] Iteration 4150, loss = 0.121194
I0309 13:26:08.295791 55597 solver.cpp:245]     Train net output #0: loss = 0.121194 (* 1 = 0.121194 loss)
I0309 13:26:08.295825 55597 sgd_solver.cpp:106] Iteration 4150, lr = 0.0001
I0309 13:26:46.405318 55597 solver.cpp:338] Iteration 4200, Testing net (#0)
I0309 13:26:47.713541 55597 solver.cpp:406]     Test net output #0: accuracy = 0.97
I0309 13:26:47.713729 55597 solver.cpp:406]     Test net output #1: loss = 0.118615 (* 1 = 0.118615 loss)
I0309 13:26:48.314910 55597 solver.cpp:229] Iteration 4200, loss = 0.0574318
I0309 13:26:48.314963 55597 solver.cpp:245]     Train net output #0: loss = 0.0574318 (* 1 = 0.0574318 loss)
I0309 13:26:48.314996 55597 sgd_solver.cpp:106] Iteration 4200, lr = 0.0001
I0309 13:27:27.199281 55597 solver.cpp:229] Iteration 4250, loss = 0.0731156
I0309 13:27:27.199512 55597 solver.cpp:245]     Train net output #0: loss = 0.0731156 (* 1 = 0.0731156 loss)
I0309 13:27:27.199545 55597 sgd_solver.cpp:106] Iteration 4250, lr = 0.0001
I0309 13:28:06.084388 55597 solver.cpp:229] Iteration 4300, loss = 0.124819
I0309 13:28:06.084573 55597 solver.cpp:245]     Train net output #0: loss = 0.124819 (* 1 = 0.124819 loss)
I0309 13:28:06.084605 55597 sgd_solver.cpp:106] Iteration 4300, lr = 0.0001
I0309 13:28:44.973214 55597 solver.cpp:229] Iteration 4350, loss = 0.0955169
I0309 13:28:44.973398 55597 solver.cpp:245]     Train net output #0: loss = 0.095517 (* 1 = 0.095517 loss)
I0309 13:28:44.973431 55597 sgd_solver.cpp:106] Iteration 4350, lr = 0.0001
I0309 13:29:23.859421 55597 solver.cpp:229] Iteration 4400, loss = 0.0989967
I0309 13:29:23.859633 55597 solver.cpp:245]     Train net output #0: loss = 0.0989967 (* 1 = 0.0989967 loss)
I0309 13:29:23.859665 55597 sgd_solver.cpp:106] Iteration 4400, lr = 0.0001
I0309 13:30:02.744402 55597 solver.cpp:229] Iteration 4450, loss = 0.180074
I0309 13:30:02.744609 55597 solver.cpp:245]     Train net output #0: loss = 0.180074 (* 1 = 0.180074 loss)
I0309 13:30:02.744642 55597 sgd_solver.cpp:106] Iteration 4450, lr = 0.0001
I0309 13:30:40.853497 55597 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_4500.caffemodel
I0309 13:30:42.502557 55597 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_4500.solverstate
I0309 13:30:43.430121 55597 solver.cpp:338] Iteration 4500, Testing net (#0)
I0309 13:30:44.567890 55597 solver.cpp:406]     Test net output #0: accuracy = 0.966
I0309 13:30:44.568078 55597 solver.cpp:406]     Test net output #1: loss = 0.124143 (* 1 = 0.124143 loss)
I0309 13:30:45.168781 55597 solver.cpp:229] Iteration 4500, loss = 0.0591187
I0309 13:30:45.168825 55597 solver.cpp:245]     Train net output #0: loss = 0.0591188 (* 1 = 0.0591188 loss)
I0309 13:30:45.168854 55597 sgd_solver.cpp:106] Iteration 4500, lr = 0.0001
I0309 13:31:24.049432 55597 solver.cpp:229] Iteration 4550, loss = 0.214951
I0309 13:31:24.049682 55597 solver.cpp:245]     Train net output #0: loss = 0.214951 (* 1 = 0.214951 loss)
I0309 13:31:24.049715 55597 sgd_solver.cpp:106] Iteration 4550, lr = 0.0001
I0309 13:32:02.924891 55597 solver.cpp:229] Iteration 4600, loss = 0.113721
I0309 13:32:02.925101 55597 solver.cpp:245]     Train net output #0: loss = 0.113721 (* 1 = 0.113721 loss)
I0309 13:32:02.925133 55597 sgd_solver.cpp:106] Iteration 4600, lr = 0.0001
I0309 13:32:41.808637 55597 solver.cpp:229] Iteration 4650, loss = 0.137193
I0309 13:32:41.808845 55597 solver.cpp:245]     Train net output #0: loss = 0.137193 (* 1 = 0.137193 loss)
I0309 13:32:41.808877 55597 sgd_solver.cpp:106] Iteration 4650, lr = 0.0001
I0309 13:33:20.687067 55597 solver.cpp:229] Iteration 4700, loss = 0.0830458
I0309 13:33:20.687247 55597 solver.cpp:245]     Train net output #0: loss = 0.0830458 (* 1 = 0.0830458 loss)
I0309 13:33:20.687280 55597 sgd_solver.cpp:106] Iteration 4700, lr = 0.0001
I0309 13:33:59.573992 55597 solver.cpp:229] Iteration 4750, loss = 0.133411
I0309 13:33:59.574199 55597 solver.cpp:245]     Train net output #0: loss = 0.133411 (* 1 = 0.133411 loss)
I0309 13:33:59.574232 55597 sgd_solver.cpp:106] Iteration 4750, lr = 0.0001
I0309 13:34:37.688968 55597 solver.cpp:338] Iteration 4800, Testing net (#0)
I0309 13:34:38.995869 55597 solver.cpp:406]     Test net output #0: accuracy = 0.958
I0309 13:34:38.996052 55597 solver.cpp:406]     Test net output #1: loss = 0.121123 (* 1 = 0.121123 loss)
I0309 13:34:39.597040 55597 solver.cpp:229] Iteration 4800, loss = 0.131339
I0309 13:34:39.597084 55597 solver.cpp:245]     Train net output #0: loss = 0.131339 (* 1 = 0.131339 loss)
I0309 13:34:39.597113 55597 sgd_solver.cpp:106] Iteration 4800, lr = 0.0001
I0309 13:35:18.478744 55597 solver.cpp:229] Iteration 4850, loss = 0.129223
I0309 13:35:18.478960 55597 solver.cpp:245]     Train net output #0: loss = 0.129223 (* 1 = 0.129223 loss)
I0309 13:35:18.478993 55597 sgd_solver.cpp:106] Iteration 4850, lr = 0.0001
I0309 13:35:57.366178 55597 solver.cpp:229] Iteration 4900, loss = 0.0580913
I0309 13:35:57.366385 55597 solver.cpp:245]     Train net output #0: loss = 0.0580914 (* 1 = 0.0580914 loss)
I0309 13:35:57.366418 55597 sgd_solver.cpp:106] Iteration 4900, lr = 0.0001
I0309 13:36:36.244900 55597 solver.cpp:229] Iteration 4950, loss = 0.14651
I0309 13:36:36.245216 55597 solver.cpp:245]     Train net output #0: loss = 0.14651 (* 1 = 0.14651 loss)
I0309 13:36:36.245255 55597 sgd_solver.cpp:106] Iteration 4950, lr = 0.0001
I0309 13:37:14.326189 55597 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_5000.caffemodel
I0309 13:37:15.968677 55597 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_5000.solverstate
I0309 13:37:17.503062 55597 solver.cpp:229] Iteration 5000, loss = 0.108103
I0309 13:37:17.503149 55597 solver.cpp:245]     Train net output #0: loss = 0.108103 (* 1 = 0.108103 loss)
I0309 13:37:17.503177 55597 sgd_solver.cpp:106] Iteration 5000, lr = 0.0001
I0309 13:37:56.358180 55597 solver.cpp:229] Iteration 5050, loss = 0.138506
I0309 13:37:56.358434 55597 solver.cpp:245]     Train net output #0: loss = 0.138506 (* 1 = 0.138506 loss)
I0309 13:37:56.358467 55597 sgd_solver.cpp:106] Iteration 5050, lr = 0.0001
I0309 13:38:34.434628 55597 solver.cpp:338] Iteration 5100, Testing net (#0)
I0309 13:38:35.740789 55597 solver.cpp:406]     Test net output #0: accuracy = 0.956
I0309 13:38:35.740927 55597 solver.cpp:406]     Test net output #1: loss = 0.130899 (* 1 = 0.130899 loss)
I0309 13:38:36.340610 55597 solver.cpp:229] Iteration 5100, loss = 0.034711
I0309 13:38:36.340654 55597 solver.cpp:245]     Train net output #0: loss = 0.034711 (* 1 = 0.034711 loss)
I0309 13:38:36.340683 55597 sgd_solver.cpp:106] Iteration 5100, lr = 0.0001
I0309 13:39:15.189581 55597 solver.cpp:229] Iteration 5150, loss = 0.0970073
I0309 13:39:15.189815 55597 solver.cpp:245]     Train net output #0: loss = 0.0970074 (* 1 = 0.0970074 loss)
I0309 13:39:15.189847 55597 sgd_solver.cpp:106] Iteration 5150, lr = 0.0001
I0309 13:39:54.041415 55597 solver.cpp:229] Iteration 5200, loss = 0.160217
I0309 13:39:54.041620 55597 solver.cpp:245]     Train net output #0: loss = 0.160217 (* 1 = 0.160217 loss)
I0309 13:39:54.041653 55597 sgd_solver.cpp:106] Iteration 5200, lr = 0.0001
I0309 13:40:32.900522 55597 solver.cpp:229] Iteration 5250, loss = 0.0683131
I0309 13:40:32.900727 55597 solver.cpp:245]     Train net output #0: loss = 0.0683131 (* 1 = 0.0683131 loss)
I0309 13:40:32.900760 55597 sgd_solver.cpp:106] Iteration 5250, lr = 0.0001
I0309 13:41:11.754348 55597 solver.cpp:229] Iteration 5300, loss = 0.10208
I0309 13:41:11.754556 55597 solver.cpp:245]     Train net output #0: loss = 0.10208 (* 1 = 0.10208 loss)
I0309 13:41:11.754590 55597 sgd_solver.cpp:106] Iteration 5300, lr = 0.0001
I0309 13:41:50.609983 55597 solver.cpp:229] Iteration 5350, loss = 0.178218
I0309 13:41:50.610180 55597 solver.cpp:245]     Train net output #0: loss = 0.178218 (* 1 = 0.178218 loss)
I0309 13:41:50.610213 55597 sgd_solver.cpp:106] Iteration 5350, lr = 0.0001
I0309 13:42:28.690007 55597 solver.cpp:338] Iteration 5400, Testing net (#0)
I0309 13:42:29.997205 55597 solver.cpp:406]     Test net output #0: accuracy = 0.962
I0309 13:42:29.997345 55597 solver.cpp:406]     Test net output #1: loss = 0.124224 (* 1 = 0.124224 loss)
I0309 13:42:30.598328 55597 solver.cpp:229] Iteration 5400, loss = 0.103197
I0309 13:42:30.598373 55597 solver.cpp:245]     Train net output #0: loss = 0.103197 (* 1 = 0.103197 loss)
I0309 13:42:30.598402 55597 sgd_solver.cpp:106] Iteration 5400, lr = 0.0001
I0309 13:43:09.451256 55597 solver.cpp:229] Iteration 5450, loss = 0.116793
I0309 13:43:09.451494 55597 solver.cpp:245]     Train net output #0: loss = 0.116793 (* 1 = 0.116793 loss)
I0309 13:43:09.451527 55597 sgd_solver.cpp:106] Iteration 5450, lr = 0.0001
I0309 13:43:47.534943 55597 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_5500.caffemodel
I0309 13:43:49.179069 55597 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_5500.solverstate
I0309 13:43:50.929949 55597 solver.cpp:229] Iteration 5500, loss = 0.149725
I0309 13:43:50.930037 55597 solver.cpp:245]     Train net output #0: loss = 0.149725 (* 1 = 0.149725 loss)
I0309 13:43:50.930066 55597 sgd_solver.cpp:106] Iteration 5500, lr = 0.0001
I0309 13:44:29.782526 55597 solver.cpp:229] Iteration 5550, loss = 0.122855
I0309 13:44:29.782739 55597 solver.cpp:245]     Train net output #0: loss = 0.122855 (* 1 = 0.122855 loss)
I0309 13:44:29.782773 55597 sgd_solver.cpp:106] Iteration 5550, lr = 0.0001
I0309 13:45:08.627773 55597 solver.cpp:229] Iteration 5600, loss = 0.0975112
I0309 13:45:08.628054 55597 solver.cpp:245]     Train net output #0: loss = 0.0975113 (* 1 = 0.0975113 loss)
I0309 13:45:08.628088 55597 sgd_solver.cpp:106] Iteration 5600, lr = 0.0001
I0309 13:45:47.490841 55597 solver.cpp:229] Iteration 5650, loss = 0.105124
I0309 13:45:47.491071 55597 solver.cpp:245]     Train net output #0: loss = 0.105124 (* 1 = 0.105124 loss)
I0309 13:45:47.491104 55597 sgd_solver.cpp:106] Iteration 5650, lr = 0.0001
I0309 13:46:25.567227 55597 solver.cpp:338] Iteration 5700, Testing net (#0)
I0309 13:46:26.873347 55597 solver.cpp:406]     Test net output #0: accuracy = 0.964
I0309 13:46:26.873483 55597 solver.cpp:406]     Test net output #1: loss = 0.116838 (* 1 = 0.116838 loss)
I0309 13:46:27.473969 55597 solver.cpp:229] Iteration 5700, loss = 0.137436
I0309 13:46:27.474014 55597 solver.cpp:245]     Train net output #0: loss = 0.137436 (* 1 = 0.137436 loss)
I0309 13:46:27.474042 55597 sgd_solver.cpp:106] Iteration 5700, lr = 0.0001
I0309 13:47:06.330059 55597 solver.cpp:229] Iteration 5750, loss = 0.105203
I0309 13:47:06.330291 55597 solver.cpp:245]     Train net output #0: loss = 0.105203 (* 1 = 0.105203 loss)
I0309 13:47:06.330324 55597 sgd_solver.cpp:106] Iteration 5750, lr = 0.0001
I0309 13:47:45.187279 55597 solver.cpp:229] Iteration 5800, loss = 0.0632859
I0309 13:47:45.187479 55597 solver.cpp:245]     Train net output #0: loss = 0.0632859 (* 1 = 0.0632859 loss)
I0309 13:47:45.187512 55597 sgd_solver.cpp:106] Iteration 5800, lr = 0.0001
I0309 13:48:24.035825 55597 solver.cpp:229] Iteration 5850, loss = 0.120848
I0309 13:48:24.036033 55597 solver.cpp:245]     Train net output #0: loss = 0.120848 (* 1 = 0.120848 loss)
I0309 13:48:24.036067 55597 sgd_solver.cpp:106] Iteration 5850, lr = 0.0001
I0309 13:49:02.885421 55597 solver.cpp:229] Iteration 5900, loss = 0.0980309
I0309 13:49:02.885612 55597 solver.cpp:245]     Train net output #0: loss = 0.0980309 (* 1 = 0.0980309 loss)
I0309 13:49:02.885645 55597 sgd_solver.cpp:106] Iteration 5900, lr = 0.0001
I0309 13:49:41.740942 55597 solver.cpp:229] Iteration 5950, loss = 0.139429
I0309 13:49:41.741140 55597 solver.cpp:245]     Train net output #0: loss = 0.13943 (* 1 = 0.13943 loss)
I0309 13:49:41.741173 55597 sgd_solver.cpp:106] Iteration 5950, lr = 0.0001
I0309 13:50:19.820937 55597 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_6000.caffemodel
I0309 13:50:21.474968 55597 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_6000.solverstate
I0309 13:50:22.396823 55597 solver.cpp:338] Iteration 6000, Testing net (#0)
I0309 13:50:23.534584 55597 solver.cpp:406]     Test net output #0: accuracy = 0.972
I0309 13:50:23.534772 55597 solver.cpp:406]     Test net output #1: loss = 0.117481 (* 1 = 0.117481 loss)
I0309 13:50:24.135171 55597 solver.cpp:229] Iteration 6000, loss = 0.109834
I0309 13:50:24.135314 55597 solver.cpp:245]     Train net output #0: loss = 0.109834 (* 1 = 0.109834 loss)
I0309 13:50:24.135346 55597 sgd_solver.cpp:106] Iteration 6000, lr = 0.0001
I0309 13:51:02.981633 55597 solver.cpp:229] Iteration 6050, loss = 0.092069
I0309 13:51:02.981884 55597 solver.cpp:245]     Train net output #0: loss = 0.092069 (* 1 = 0.092069 loss)
I0309 13:51:02.981919 55597 sgd_solver.cpp:106] Iteration 6050, lr = 0.0001
I0309 13:51:41.837345 55597 solver.cpp:229] Iteration 6100, loss = 0.0946263
I0309 13:51:41.837550 55597 solver.cpp:245]     Train net output #0: loss = 0.0946263 (* 1 = 0.0946263 loss)
I0309 13:51:41.837584 55597 sgd_solver.cpp:106] Iteration 6100, lr = 0.0001
I0309 13:52:20.708168 55597 solver.cpp:229] Iteration 6150, loss = 0.105168
I0309 13:52:20.708595 55597 solver.cpp:245]     Train net output #0: loss = 0.105168 (* 1 = 0.105168 loss)
I0309 13:52:20.708631 55597 sgd_solver.cpp:106] Iteration 6150, lr = 0.0001
I0309 13:52:59.601850 55597 solver.cpp:229] Iteration 6200, loss = 0.0754135
I0309 13:52:59.602248 55597 solver.cpp:245]     Train net output #0: loss = 0.0754135 (* 1 = 0.0754135 loss)
I0309 13:52:59.602284 55597 sgd_solver.cpp:106] Iteration 6200, lr = 0.0001
I0309 13:53:38.484757 55597 solver.cpp:229] Iteration 6250, loss = 0.0608659
I0309 13:53:38.485198 55597 solver.cpp:245]     Train net output #0: loss = 0.0608659 (* 1 = 0.0608659 loss)
I0309 13:53:38.485256 55597 sgd_solver.cpp:106] Iteration 6250, lr = 0.0001
I0309 13:54:16.601601 55597 solver.cpp:338] Iteration 6300, Testing net (#0)
I0309 13:54:17.909140 55597 solver.cpp:406]     Test net output #0: accuracy = 0.962
I0309 13:54:17.909332 55597 solver.cpp:406]     Test net output #1: loss = 0.121634 (* 1 = 0.121634 loss)
I0309 13:54:18.509778 55597 solver.cpp:229] Iteration 6300, loss = 0.139995
I0309 13:54:18.509959 55597 solver.cpp:245]     Train net output #0: loss = 0.139995 (* 1 = 0.139995 loss)
I0309 13:54:18.509992 55597 sgd_solver.cpp:106] Iteration 6300, lr = 0.0001
I0309 13:54:57.404466 55597 solver.cpp:229] Iteration 6350, loss = 0.0690297
I0309 13:54:57.404858 55597 solver.cpp:245]     Train net output #0: loss = 0.0690297 (* 1 = 0.0690297 loss)
I0309 13:54:57.404893 55597 sgd_solver.cpp:106] Iteration 6350, lr = 0.0001
I0309 13:55:36.296306 55597 solver.cpp:229] Iteration 6400, loss = 0.128172
I0309 13:55:36.296702 55597 solver.cpp:245]     Train net output #0: loss = 0.128172 (* 1 = 0.128172 loss)
I0309 13:55:36.296738 55597 sgd_solver.cpp:106] Iteration 6400, lr = 0.0001
I0309 13:56:15.191735 55597 solver.cpp:229] Iteration 6450, loss = 0.101633
I0309 13:56:15.192134 55597 solver.cpp:245]     Train net output #0: loss = 0.101633 (* 1 = 0.101633 loss)
I0309 13:56:15.192172 55597 sgd_solver.cpp:106] Iteration 6450, lr = 0.0001
I0309 13:56:53.309237 55597 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_6500.caffemodel
I0309 13:56:54.957258 55597 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_6500.solverstate
I0309 13:56:56.476802 55597 solver.cpp:229] Iteration 6500, loss = 0.106804
I0309 13:56:56.476989 55597 solver.cpp:245]     Train net output #0: loss = 0.106805 (* 1 = 0.106805 loss)
I0309 13:56:56.477020 55597 sgd_solver.cpp:106] Iteration 6500, lr = 0.0001
I0309 13:57:35.366672 55597 solver.cpp:229] Iteration 6550, loss = 0.038741
I0309 13:57:35.367043 55597 solver.cpp:245]     Train net output #0: loss = 0.0387411 (* 1 = 0.0387411 loss)
I0309 13:57:35.367077 55597 sgd_solver.cpp:106] Iteration 6550, lr = 0.0001
I0309 13:58:13.490630 55597 solver.cpp:338] Iteration 6600, Testing net (#0)
I0309 13:58:14.798806 55597 solver.cpp:406]     Test net output #0: accuracy = 0.962
I0309 13:58:14.798995 55597 solver.cpp:406]     Test net output #1: loss = 0.120294 (* 1 = 0.120294 loss)
I0309 13:58:15.400048 55597 solver.cpp:229] Iteration 6600, loss = 0.0835098
I0309 13:58:15.400218 55597 solver.cpp:245]     Train net output #0: loss = 0.08351 (* 1 = 0.08351 loss)
I0309 13:58:15.400246 55597 sgd_solver.cpp:106] Iteration 6600, lr = 0.0001
I0309 13:58:54.284458 55597 solver.cpp:229] Iteration 6650, loss = 0.103468
I0309 13:58:54.284833 55597 solver.cpp:245]     Train net output #0: loss = 0.103468 (* 1 = 0.103468 loss)
I0309 13:58:54.284868 55597 sgd_solver.cpp:106] Iteration 6650, lr = 0.0001
I0309 13:59:33.179430 55597 solver.cpp:229] Iteration 6700, loss = 0.106918
I0309 13:59:33.179821 55597 solver.cpp:245]     Train net output #0: loss = 0.106918 (* 1 = 0.106918 loss)
I0309 13:59:33.179857 55597 sgd_solver.cpp:106] Iteration 6700, lr = 0.0001
I0309 14:00:12.075454 55597 solver.cpp:229] Iteration 6750, loss = 0.082353
I0309 14:00:12.075850 55597 solver.cpp:245]     Train net output #0: loss = 0.0823531 (* 1 = 0.0823531 loss)
I0309 14:00:12.075886 55597 sgd_solver.cpp:106] Iteration 6750, lr = 0.0001
I0309 14:00:50.972200 55597 solver.cpp:229] Iteration 6800, loss = 0.0859131
I0309 14:00:50.972614 55597 solver.cpp:245]     Train net output #0: loss = 0.0859132 (* 1 = 0.0859132 loss)
I0309 14:00:50.972650 55597 sgd_solver.cpp:106] Iteration 6800, lr = 0.0001
I0309 14:01:29.853365 55597 solver.cpp:229] Iteration 6850, loss = 0.157396
I0309 14:01:29.853648 55597 solver.cpp:245]     Train net output #0: loss = 0.157396 (* 1 = 0.157396 loss)
I0309 14:01:29.853682 55597 sgd_solver.cpp:106] Iteration 6850, lr = 0.0001
I0309 14:02:07.961130 55597 solver.cpp:338] Iteration 6900, Testing net (#0)
I0309 14:02:09.268695 55597 solver.cpp:406]     Test net output #0: accuracy = 0.964
I0309 14:02:09.268875 55597 solver.cpp:406]     Test net output #1: loss = 0.120011 (* 1 = 0.120011 loss)
I0309 14:02:09.869685 55597 solver.cpp:229] Iteration 6900, loss = 0.0674187
I0309 14:02:09.869730 55597 solver.cpp:245]     Train net output #0: loss = 0.0674188 (* 1 = 0.0674188 loss)
I0309 14:02:09.869758 55597 sgd_solver.cpp:106] Iteration 6900, lr = 0.0001
I0309 14:02:48.754448 55597 solver.cpp:229] Iteration 6950, loss = 0.0949401
I0309 14:02:48.754689 55597 solver.cpp:245]     Train net output #0: loss = 0.0949401 (* 1 = 0.0949401 loss)
I0309 14:02:48.754722 55597 sgd_solver.cpp:106] Iteration 6950, lr = 0.0001
I0309 14:03:26.864171 55597 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_7000.caffemodel
I0309 14:03:28.509855 55597 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_7000.solverstate
I0309 14:03:30.029888 55597 solver.cpp:229] Iteration 7000, loss = 0.0630295
I0309 14:03:30.029970 55597 solver.cpp:245]     Train net output #0: loss = 0.0630295 (* 1 = 0.0630295 loss)
I0309 14:03:30.030000 55597 sgd_solver.cpp:106] Iteration 7000, lr = 0.0001
I0309 14:04:08.918895 55597 solver.cpp:229] Iteration 7050, loss = 0.0733526
I0309 14:04:08.919123 55597 solver.cpp:245]     Train net output #0: loss = 0.0733527 (* 1 = 0.0733527 loss)
I0309 14:04:08.919157 55597 sgd_solver.cpp:106] Iteration 7050, lr = 0.0001
I0309 14:04:47.804911 55597 solver.cpp:229] Iteration 7100, loss = 0.0791919
I0309 14:04:47.805081 55597 solver.cpp:245]     Train net output #0: loss = 0.079192 (* 1 = 0.079192 loss)
I0309 14:04:47.805114 55597 sgd_solver.cpp:106] Iteration 7100, lr = 0.0001
I0309 14:05:26.691534 55597 solver.cpp:229] Iteration 7150, loss = 0.125689
I0309 14:05:26.691742 55597 solver.cpp:245]     Train net output #0: loss = 0.125689 (* 1 = 0.125689 loss)
I0309 14:05:26.691776 55597 sgd_solver.cpp:106] Iteration 7150, lr = 0.0001
I0309 14:06:04.808004 55597 solver.cpp:338] Iteration 7200, Testing net (#0)
I0309 14:06:06.115290 55597 solver.cpp:406]     Test net output #0: accuracy = 0.958
I0309 14:06:06.115478 55597 solver.cpp:406]     Test net output #1: loss = 0.123376 (* 1 = 0.123376 loss)
I0309 14:06:06.716671 55597 solver.cpp:229] Iteration 7200, loss = 0.0827415
I0309 14:06:06.716717 55597 solver.cpp:245]     Train net output #0: loss = 0.0827415 (* 1 = 0.0827415 loss)
I0309 14:06:06.716758 55597 sgd_solver.cpp:106] Iteration 7200, lr = 0.0001
I0309 14:06:45.594171 55597 solver.cpp:229] Iteration 7250, loss = 0.0925826
I0309 14:06:45.594394 55597 solver.cpp:245]     Train net output #0: loss = 0.0925827 (* 1 = 0.0925827 loss)
I0309 14:06:45.594427 55597 sgd_solver.cpp:106] Iteration 7250, lr = 0.0001
I0309 14:07:24.467978 55597 solver.cpp:229] Iteration 7300, loss = 0.0984866
I0309 14:07:24.468185 55597 solver.cpp:245]     Train net output #0: loss = 0.0984867 (* 1 = 0.0984867 loss)
I0309 14:07:24.468219 55597 sgd_solver.cpp:106] Iteration 7300, lr = 0.0001
I0309 14:08:03.354863 55597 solver.cpp:229] Iteration 7350, loss = 0.0556431
I0309 14:08:03.355038 55597 solver.cpp:245]     Train net output #0: loss = 0.0556432 (* 1 = 0.0556432 loss)
I0309 14:08:03.355070 55597 sgd_solver.cpp:106] Iteration 7350, lr = 0.0001
I0309 14:08:42.232141 55597 solver.cpp:229] Iteration 7400, loss = 0.04994
I0309 14:08:42.232348 55597 solver.cpp:245]     Train net output #0: loss = 0.0499401 (* 1 = 0.0499401 loss)
I0309 14:08:42.232381 55597 sgd_solver.cpp:106] Iteration 7400, lr = 0.0001
I0309 14:09:21.114471 55597 solver.cpp:229] Iteration 7450, loss = 0.103289
I0309 14:09:21.114650 55597 solver.cpp:245]     Train net output #0: loss = 0.103289 (* 1 = 0.103289 loss)
I0309 14:09:21.114681 55597 sgd_solver.cpp:106] Iteration 7450, lr = 0.0001
I0309 14:09:59.225371 55597 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_7500.caffemodel
I0309 14:10:00.869210 55597 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_7500.solverstate
I0309 14:10:01.788367 55597 solver.cpp:338] Iteration 7500, Testing net (#0)
I0309 14:10:02.926430 55597 solver.cpp:406]     Test net output #0: accuracy = 0.96
I0309 14:10:02.926621 55597 solver.cpp:406]     Test net output #1: loss = 0.123833 (* 1 = 0.123833 loss)
I0309 14:10:03.527387 55597 solver.cpp:229] Iteration 7500, loss = 0.0572419
I0309 14:10:03.527431 55597 solver.cpp:245]     Train net output #0: loss = 0.057242 (* 1 = 0.057242 loss)
I0309 14:10:03.527458 55597 sgd_solver.cpp:106] Iteration 7500, lr = 0.0001
I0309 14:10:42.422453 55597 solver.cpp:229] Iteration 7550, loss = 0.0666302
I0309 14:10:42.422672 55597 solver.cpp:245]     Train net output #0: loss = 0.0666303 (* 1 = 0.0666303 loss)
I0309 14:10:42.422703 55597 sgd_solver.cpp:106] Iteration 7550, lr = 0.0001
I0309 14:11:21.313024 55597 solver.cpp:229] Iteration 7600, loss = 0.0623829
I0309 14:11:21.313210 55597 solver.cpp:245]     Train net output #0: loss = 0.0623829 (* 1 = 0.0623829 loss)
I0309 14:11:21.313242 55597 sgd_solver.cpp:106] Iteration 7600, lr = 0.0001
I0309 14:12:00.198992 55597 solver.cpp:229] Iteration 7650, loss = 0.110484
I0309 14:12:00.199203 55597 solver.cpp:245]     Train net output #0: loss = 0.110484 (* 1 = 0.110484 loss)
I0309 14:12:00.199235 55597 sgd_solver.cpp:106] Iteration 7650, lr = 0.0001
I0309 14:12:39.082782 55597 solver.cpp:229] Iteration 7700, loss = 0.0981916
I0309 14:12:39.082989 55597 solver.cpp:245]     Train net output #0: loss = 0.0981917 (* 1 = 0.0981917 loss)
I0309 14:12:39.083022 55597 sgd_solver.cpp:106] Iteration 7700, lr = 0.0001
I0309 14:13:17.963265 55597 solver.cpp:229] Iteration 7750, loss = 0.120335
I0309 14:13:17.963474 55597 solver.cpp:245]     Train net output #0: loss = 0.120335 (* 1 = 0.120335 loss)
I0309 14:13:17.963506 55597 sgd_solver.cpp:106] Iteration 7750, lr = 0.0001
I0309 14:13:56.081671 55597 solver.cpp:338] Iteration 7800, Testing net (#0)
I0309 14:13:57.389487 55597 solver.cpp:406]     Test net output #0: accuracy = 0.958
I0309 14:13:57.389673 55597 solver.cpp:406]     Test net output #1: loss = 0.130178 (* 1 = 0.130178 loss)
I0309 14:13:57.990070 55597 solver.cpp:229] Iteration 7800, loss = 0.0906713
I0309 14:13:57.990118 55597 solver.cpp:245]     Train net output #0: loss = 0.0906714 (* 1 = 0.0906714 loss)
I0309 14:13:57.990146 55597 sgd_solver.cpp:106] Iteration 7800, lr = 0.0001
I0309 14:14:36.878392 55597 solver.cpp:229] Iteration 7850, loss = 0.091875
I0309 14:14:36.878640 55597 solver.cpp:245]     Train net output #0: loss = 0.0918751 (* 1 = 0.0918751 loss)
I0309 14:14:36.878672 55597 sgd_solver.cpp:106] Iteration 7850, lr = 0.0001
I0309 14:15:15.768620 55597 solver.cpp:229] Iteration 7900, loss = 0.193023
I0309 14:15:15.768817 55597 solver.cpp:245]     Train net output #0: loss = 0.193023 (* 1 = 0.193023 loss)
I0309 14:15:15.768851 55597 sgd_solver.cpp:106] Iteration 7900, lr = 0.0001
I0309 14:15:54.663674 55597 solver.cpp:229] Iteration 7950, loss = 0.101159
I0309 14:15:54.663877 55597 solver.cpp:245]     Train net output #0: loss = 0.101159 (* 1 = 0.101159 loss)
I0309 14:15:54.663910 55597 sgd_solver.cpp:106] Iteration 7950, lr = 0.0001
I0309 14:16:32.780966 55597 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_8000.caffemodel
I0309 14:16:34.423446 55597 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_8000.solverstate
I0309 14:16:35.941527 55597 solver.cpp:229] Iteration 8000, loss = 0.0915517
I0309 14:16:35.941609 55597 solver.cpp:245]     Train net output #0: loss = 0.0915518 (* 1 = 0.0915518 loss)
I0309 14:16:35.941639 55597 sgd_solver.cpp:106] Iteration 8000, lr = 0.0001
I0309 14:17:14.825714 55597 solver.cpp:229] Iteration 8050, loss = 0.0752538
I0309 14:17:14.825979 55597 solver.cpp:245]     Train net output #0: loss = 0.0752539 (* 1 = 0.0752539 loss)
I0309 14:17:14.826011 55597 sgd_solver.cpp:106] Iteration 8050, lr = 0.0001
I0309 14:17:52.936051 55597 solver.cpp:338] Iteration 8100, Testing net (#0)
I0309 14:17:54.242923 55597 solver.cpp:406]     Test net output #0: accuracy = 0.958
I0309 14:17:54.243101 55597 solver.cpp:406]     Test net output #1: loss = 0.126946 (* 1 = 0.126946 loss)
I0309 14:17:54.844674 55597 solver.cpp:229] Iteration 8100, loss = 0.0788646
I0309 14:17:54.844719 55597 solver.cpp:245]     Train net output #0: loss = 0.0788647 (* 1 = 0.0788647 loss)
I0309 14:17:54.844748 55597 sgd_solver.cpp:106] Iteration 8100, lr = 0.0001
I0309 14:18:33.726526 55597 solver.cpp:229] Iteration 8150, loss = 0.024487
I0309 14:18:33.726775 55597 solver.cpp:245]     Train net output #0: loss = 0.0244871 (* 1 = 0.0244871 loss)
I0309 14:18:33.726809 55597 sgd_solver.cpp:106] Iteration 8150, lr = 0.0001
I0309 14:19:12.614302 55597 solver.cpp:229] Iteration 8200, loss = 0.0514027
I0309 14:19:12.614475 55597 solver.cpp:245]     Train net output #0: loss = 0.0514028 (* 1 = 0.0514028 loss)
I0309 14:19:12.614506 55597 sgd_solver.cpp:106] Iteration 8200, lr = 0.0001
I0309 14:19:51.502342 55597 solver.cpp:229] Iteration 8250, loss = 0.0814056
I0309 14:19:51.502548 55597 solver.cpp:245]     Train net output #0: loss = 0.0814057 (* 1 = 0.0814057 loss)
I0309 14:19:51.502580 55597 sgd_solver.cpp:106] Iteration 8250, lr = 0.0001
I0309 14:20:30.392573 55597 solver.cpp:229] Iteration 8300, loss = 0.0965167
I0309 14:20:30.392783 55597 solver.cpp:245]     Train net output #0: loss = 0.0965168 (* 1 = 0.0965168 loss)
I0309 14:20:30.392815 55597 sgd_solver.cpp:106] Iteration 8300, lr = 0.0001
I0309 14:21:09.275475 55597 solver.cpp:229] Iteration 8350, loss = 0.0683883
I0309 14:21:09.275660 55597 solver.cpp:245]     Train net output #0: loss = 0.0683884 (* 1 = 0.0683884 loss)
I0309 14:21:09.275692 55597 sgd_solver.cpp:106] Iteration 8350, lr = 0.0001
I0309 14:21:47.387491 55597 solver.cpp:338] Iteration 8400, Testing net (#0)
I0309 14:21:48.695049 55597 solver.cpp:406]     Test net output #0: accuracy = 0.96
I0309 14:21:48.695245 55597 solver.cpp:406]     Test net output #1: loss = 0.115404 (* 1 = 0.115404 loss)
I0309 14:21:49.296905 55597 solver.cpp:229] Iteration 8400, loss = 0.0756353
I0309 14:21:49.296949 55597 solver.cpp:245]     Train net output #0: loss = 0.0756354 (* 1 = 0.0756354 loss)
I0309 14:21:49.296978 55597 sgd_solver.cpp:106] Iteration 8400, lr = 0.0001
I0309 14:22:28.174465 55597 solver.cpp:229] Iteration 8450, loss = 0.10329
I0309 14:22:28.174713 55597 solver.cpp:245]     Train net output #0: loss = 0.10329 (* 1 = 0.10329 loss)
I0309 14:22:28.174746 55597 sgd_solver.cpp:106] Iteration 8450, lr = 0.0001
I0309 14:23:06.288655 55597 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_8500.caffemodel
I0309 14:23:07.937947 55597 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_8500.solverstate
I0309 14:23:09.457837 55597 solver.cpp:229] Iteration 8500, loss = 0.0594464
I0309 14:23:09.457916 55597 solver.cpp:245]     Train net output #0: loss = 0.0594465 (* 1 = 0.0594465 loss)
I0309 14:23:09.457945 55597 sgd_solver.cpp:106] Iteration 8500, lr = 0.0001
I0309 14:23:48.338783 55597 solver.cpp:229] Iteration 8550, loss = 0.0507272
I0309 14:23:48.339017 55597 solver.cpp:245]     Train net output #0: loss = 0.0507273 (* 1 = 0.0507273 loss)
I0309 14:23:48.339051 55597 sgd_solver.cpp:106] Iteration 8550, lr = 0.0001
I0309 14:24:27.226580 55597 solver.cpp:229] Iteration 8600, loss = 0.10262
I0309 14:24:27.226786 55597 solver.cpp:245]     Train net output #0: loss = 0.10262 (* 1 = 0.10262 loss)
I0309 14:24:27.226819 55597 sgd_solver.cpp:106] Iteration 8600, lr = 0.0001
I0309 14:25:06.109897 55597 solver.cpp:229] Iteration 8650, loss = 0.0688942
I0309 14:25:06.110122 55597 solver.cpp:245]     Train net output #0: loss = 0.0688943 (* 1 = 0.0688943 loss)
I0309 14:25:06.110155 55597 sgd_solver.cpp:106] Iteration 8650, lr = 0.0001
I0309 14:25:44.222223 55597 solver.cpp:338] Iteration 8700, Testing net (#0)
I0309 14:25:45.529326 55597 solver.cpp:406]     Test net output #0: accuracy = 0.964
I0309 14:25:45.529515 55597 solver.cpp:406]     Test net output #1: loss = 0.119195 (* 1 = 0.119195 loss)
I0309 14:25:46.131832 55597 solver.cpp:229] Iteration 8700, loss = 0.0650076
I0309 14:25:46.131877 55597 solver.cpp:245]     Train net output #0: loss = 0.0650077 (* 1 = 0.0650077 loss)
I0309 14:25:46.131906 55597 sgd_solver.cpp:106] Iteration 8700, lr = 0.0001
I0309 14:26:25.012217 55597 solver.cpp:229] Iteration 8750, loss = 0.0857993
I0309 14:26:25.012470 55597 solver.cpp:245]     Train net output #0: loss = 0.0857994 (* 1 = 0.0857994 loss)
I0309 14:26:25.012502 55597 sgd_solver.cpp:106] Iteration 8750, lr = 0.0001
I0309 14:27:03.898814 55597 solver.cpp:229] Iteration 8800, loss = 0.0578469
I0309 14:27:03.899021 55597 solver.cpp:245]     Train net output #0: loss = 0.057847 (* 1 = 0.057847 loss)
I0309 14:27:03.899055 55597 sgd_solver.cpp:106] Iteration 8800, lr = 0.0001
I0309 14:27:42.787420 55597 solver.cpp:229] Iteration 8850, loss = 0.0499959
I0309 14:27:42.787631 55597 solver.cpp:245]     Train net output #0: loss = 0.0499959 (* 1 = 0.0499959 loss)
I0309 14:27:42.787664 55597 sgd_solver.cpp:106] Iteration 8850, lr = 0.0001
I0309 14:28:21.669494 55597 solver.cpp:229] Iteration 8900, loss = 0.0798868
I0309 14:28:21.669704 55597 solver.cpp:245]     Train net output #0: loss = 0.0798869 (* 1 = 0.0798869 loss)
I0309 14:28:21.669736 55597 sgd_solver.cpp:106] Iteration 8900, lr = 0.0001
I0309 14:29:00.558619 55597 solver.cpp:229] Iteration 8950, loss = 0.101754
I0309 14:29:00.558806 55597 solver.cpp:245]     Train net output #0: loss = 0.101754 (* 1 = 0.101754 loss)
I0309 14:29:00.558838 55597 sgd_solver.cpp:106] Iteration 8950, lr = 0.0001
I0309 14:29:38.661339 55597 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_9000.caffemodel
I0309 14:29:40.301178 55597 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_9000.solverstate
I0309 14:29:41.223402 55597 solver.cpp:338] Iteration 9000, Testing net (#0)
I0309 14:29:42.361426 55597 solver.cpp:406]     Test net output #0: accuracy = 0.958
I0309 14:29:42.361608 55597 solver.cpp:406]     Test net output #1: loss = 0.128137 (* 1 = 0.128137 loss)
I0309 14:29:42.962726 55597 solver.cpp:229] Iteration 9000, loss = 0.0751647
I0309 14:29:42.962769 55597 solver.cpp:245]     Train net output #0: loss = 0.0751648 (* 1 = 0.0751648 loss)
I0309 14:29:42.962800 55597 sgd_solver.cpp:106] Iteration 9000, lr = 0.0001
I0309 14:30:21.849706 55597 solver.cpp:229] Iteration 9050, loss = 0.107985
I0309 14:30:21.849942 55597 solver.cpp:245]     Train net output #0: loss = 0.107985 (* 1 = 0.107985 loss)
I0309 14:30:21.849975 55597 sgd_solver.cpp:106] Iteration 9050, lr = 0.0001
I0309 14:31:00.735597 55597 solver.cpp:229] Iteration 9100, loss = 0.0770173
I0309 14:31:00.735785 55597 solver.cpp:245]     Train net output #0: loss = 0.0770174 (* 1 = 0.0770174 loss)
I0309 14:31:00.735817 55597 sgd_solver.cpp:106] Iteration 9100, lr = 0.0001
I0309 14:31:39.617401 55597 solver.cpp:229] Iteration 9150, loss = 0.0320382
I0309 14:31:39.617591 55597 solver.cpp:245]     Train net output #0: loss = 0.0320383 (* 1 = 0.0320383 loss)
I0309 14:31:39.617624 55597 sgd_solver.cpp:106] Iteration 9150, lr = 0.0001
I0309 14:32:18.502142 55597 solver.cpp:229] Iteration 9200, loss = 0.0918316
I0309 14:32:18.502352 55597 solver.cpp:245]     Train net output #0: loss = 0.0918317 (* 1 = 0.0918317 loss)
I0309 14:32:18.502384 55597 sgd_solver.cpp:106] Iteration 9200, lr = 0.0001
I0309 14:32:57.379895 55597 solver.cpp:229] Iteration 9250, loss = 0.111707
I0309 14:32:57.380126 55597 solver.cpp:245]     Train net output #0: loss = 0.111707 (* 1 = 0.111707 loss)
I0309 14:32:57.380159 55597 sgd_solver.cpp:106] Iteration 9250, lr = 0.0001
I0309 14:33:35.492307 55597 solver.cpp:338] Iteration 9300, Testing net (#0)
I0309 14:33:36.798871 55597 solver.cpp:406]     Test net output #0: accuracy = 0.958
I0309 14:33:36.799062 55597 solver.cpp:406]     Test net output #1: loss = 0.128216 (* 1 = 0.128216 loss)
I0309 14:33:37.401046 55597 solver.cpp:229] Iteration 9300, loss = 0.0693329
I0309 14:33:37.401090 55597 solver.cpp:245]     Train net output #0: loss = 0.069333 (* 1 = 0.069333 loss)
I0309 14:33:37.401119 55597 sgd_solver.cpp:106] Iteration 9300, lr = 0.0001
I0309 14:34:16.283726 55597 solver.cpp:229] Iteration 9350, loss = 0.0370242
I0309 14:34:16.283969 55597 solver.cpp:245]     Train net output #0: loss = 0.0370244 (* 1 = 0.0370244 loss)
I0309 14:34:16.284003 55597 sgd_solver.cpp:106] Iteration 9350, lr = 0.0001
I0309 14:34:55.179868 55597 solver.cpp:229] Iteration 9400, loss = 0.137794
I0309 14:34:55.180078 55597 solver.cpp:245]     Train net output #0: loss = 0.137794 (* 1 = 0.137794 loss)
I0309 14:34:55.180110 55597 sgd_solver.cpp:106] Iteration 9400, lr = 0.0001
I0309 14:35:34.060905 55597 solver.cpp:229] Iteration 9450, loss = 0.0700588
I0309 14:35:34.061094 55597 solver.cpp:245]     Train net output #0: loss = 0.070059 (* 1 = 0.070059 loss)
I0309 14:35:34.061127 55597 sgd_solver.cpp:106] Iteration 9450, lr = 0.0001
I0309 14:36:12.172452 55597 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_9500.caffemodel
I0309 14:36:13.816015 55597 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_9500.solverstate
I0309 14:36:15.679400 55597 solver.cpp:229] Iteration 9500, loss = 0.0331234
I0309 14:36:15.679479 55597 solver.cpp:245]     Train net output #0: loss = 0.0331235 (* 1 = 0.0331235 loss)
I0309 14:36:15.679509 55597 sgd_solver.cpp:106] Iteration 9500, lr = 0.0001
I0309 14:36:54.562644 55597 solver.cpp:229] Iteration 9550, loss = 0.0382604
I0309 14:36:54.562877 55597 solver.cpp:245]     Train net output #0: loss = 0.0382605 (* 1 = 0.0382605 loss)
I0309 14:36:54.562911 55597 sgd_solver.cpp:106] Iteration 9550, lr = 0.0001
I0309 14:37:32.679621 55597 solver.cpp:338] Iteration 9600, Testing net (#0)
I0309 14:37:33.986744 55597 solver.cpp:406]     Test net output #0: accuracy = 0.96
I0309 14:37:33.986932 55597 solver.cpp:406]     Test net output #1: loss = 0.121388 (* 1 = 0.121388 loss)
I0309 14:37:34.587282 55597 solver.cpp:229] Iteration 9600, loss = 0.0615653
I0309 14:37:34.587329 55597 solver.cpp:245]     Train net output #0: loss = 0.0615654 (* 1 = 0.0615654 loss)
I0309 14:37:34.587358 55597 sgd_solver.cpp:106] Iteration 9600, lr = 0.0001
I0309 14:38:13.463528 55597 solver.cpp:229] Iteration 9650, loss = 0.0678101
I0309 14:38:13.463769 55597 solver.cpp:245]     Train net output #0: loss = 0.0678103 (* 1 = 0.0678103 loss)
I0309 14:38:13.463803 55597 sgd_solver.cpp:106] Iteration 9650, lr = 0.0001
I0309 14:38:52.346628 55597 solver.cpp:229] Iteration 9700, loss = 0.0467121
I0309 14:38:52.346833 55597 solver.cpp:245]     Train net output #0: loss = 0.0467122 (* 1 = 0.0467122 loss)
I0309 14:38:52.346866 55597 sgd_solver.cpp:106] Iteration 9700, lr = 0.0001
I0309 14:39:31.230945 55597 solver.cpp:229] Iteration 9750, loss = 0.0297634
I0309 14:39:31.231154 55597 solver.cpp:245]     Train net output #0: loss = 0.0297635 (* 1 = 0.0297635 loss)
I0309 14:39:31.231187 55597 sgd_solver.cpp:106] Iteration 9750, lr = 0.0001
I0309 14:40:10.113636 55597 solver.cpp:229] Iteration 9800, loss = 0.0615961
I0309 14:40:10.113848 55597 solver.cpp:245]     Train net output #0: loss = 0.0615962 (* 1 = 0.0615962 loss)
I0309 14:40:10.113881 55597 sgd_solver.cpp:106] Iteration 9800, lr = 0.0001
I0309 14:40:48.994040 55597 solver.cpp:229] Iteration 9850, loss = 0.0647117
I0309 14:40:48.994266 55597 solver.cpp:245]     Train net output #0: loss = 0.0647119 (* 1 = 0.0647119 loss)
I0309 14:40:48.994318 55597 sgd_solver.cpp:106] Iteration 9850, lr = 0.0001
I0309 14:41:27.102314 55597 solver.cpp:338] Iteration 9900, Testing net (#0)
I0309 14:41:28.409868 55597 solver.cpp:406]     Test net output #0: accuracy = 0.956
I0309 14:41:28.410049 55597 solver.cpp:406]     Test net output #1: loss = 0.128359 (* 1 = 0.128359 loss)
I0309 14:41:29.010999 55597 solver.cpp:229] Iteration 9900, loss = 0.0625312
I0309 14:41:29.011044 55597 solver.cpp:245]     Train net output #0: loss = 0.0625313 (* 1 = 0.0625313 loss)
I0309 14:41:29.011072 55597 sgd_solver.cpp:106] Iteration 9900, lr = 0.0001
I0309 14:42:07.894940 55597 solver.cpp:229] Iteration 9950, loss = 0.0850494
I0309 14:42:07.895181 55597 solver.cpp:245]     Train net output #0: loss = 0.0850496 (* 1 = 0.0850496 loss)
I0309 14:42:07.895213 55597 sgd_solver.cpp:106] Iteration 9950, lr = 0.0001
I0309 14:42:46.004360 55597 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_10000.caffemodel
I0309 14:42:47.641671 55597 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_10000.solverstate
I0309 14:42:49.155956 55597 solver.cpp:229] Iteration 10000, loss = 0.0343535
I0309 14:42:49.156038 55597 solver.cpp:245]     Train net output #0: loss = 0.0343537 (* 1 = 0.0343537 loss)
I0309 14:42:49.156066 55597 sgd_solver.cpp:106] Iteration 10000, lr = 1e-05
I0309 14:43:28.037320 55597 solver.cpp:229] Iteration 10050, loss = 0.0574698
I0309 14:43:28.037559 55597 solver.cpp:245]     Train net output #0: loss = 0.05747 (* 1 = 0.05747 loss)
I0309 14:43:28.037591 55597 sgd_solver.cpp:106] Iteration 10050, lr = 1e-05
I0309 14:44:06.921458 55597 solver.cpp:229] Iteration 10100, loss = 0.0435456
I0309 14:44:06.921641 55597 solver.cpp:245]     Train net output #0: loss = 0.0435458 (* 1 = 0.0435458 loss)
I0309 14:44:06.921674 55597 sgd_solver.cpp:106] Iteration 10100, lr = 1e-05
I0309 14:44:45.799909 55597 solver.cpp:229] Iteration 10150, loss = 0.0403663
I0309 14:44:45.800117 55597 solver.cpp:245]     Train net output #0: loss = 0.0403664 (* 1 = 0.0403664 loss)
I0309 14:44:45.800149 55597 sgd_solver.cpp:106] Iteration 10150, lr = 1e-05
I0309 14:45:23.911927 55597 solver.cpp:338] Iteration 10200, Testing net (#0)
I0309 14:45:25.219449 55597 solver.cpp:406]     Test net output #0: accuracy = 0.954
I0309 14:45:25.219626 55597 solver.cpp:406]     Test net output #1: loss = 0.128221 (* 1 = 0.128221 loss)
I0309 14:45:25.821831 55597 solver.cpp:229] Iteration 10200, loss = 0.0635786
I0309 14:45:25.821877 55597 solver.cpp:245]     Train net output #0: loss = 0.0635787 (* 1 = 0.0635787 loss)
I0309 14:45:25.821904 55597 sgd_solver.cpp:106] Iteration 10200, lr = 1e-05
I0309 14:46:04.702796 55597 solver.cpp:229] Iteration 10250, loss = 0.0394642
I0309 14:46:04.703018 55597 solver.cpp:245]     Train net output #0: loss = 0.0394644 (* 1 = 0.0394644 loss)
I0309 14:46:04.703052 55597 sgd_solver.cpp:106] Iteration 10250, lr = 1e-05
I0309 14:46:43.593971 55597 solver.cpp:229] Iteration 10300, loss = 0.0765007
I0309 14:46:43.594174 55597 solver.cpp:245]     Train net output #0: loss = 0.0765008 (* 1 = 0.0765008 loss)
I0309 14:46:43.594207 55597 sgd_solver.cpp:106] Iteration 10300, lr = 1e-05
I0309 14:47:22.475345 55597 solver.cpp:229] Iteration 10350, loss = 0.0494699
I0309 14:47:22.475528 55597 solver.cpp:245]     Train net output #0: loss = 0.04947 (* 1 = 0.04947 loss)
I0309 14:47:22.475560 55597 sgd_solver.cpp:106] Iteration 10350, lr = 1e-05
I0309 14:48:01.353008 55597 solver.cpp:229] Iteration 10400, loss = 0.0683458
I0309 14:48:01.353219 55597 solver.cpp:245]     Train net output #0: loss = 0.068346 (* 1 = 0.068346 loss)
I0309 14:48:01.353251 55597 sgd_solver.cpp:106] Iteration 10400, lr = 1e-05
I0309 14:48:40.230104 55597 solver.cpp:229] Iteration 10450, loss = 0.080698
I0309 14:48:40.230340 55597 solver.cpp:245]     Train net output #0: loss = 0.0806981 (* 1 = 0.0806981 loss)
I0309 14:48:40.230388 55597 sgd_solver.cpp:106] Iteration 10450, lr = 1e-05
I0309 14:49:18.337007 55597 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_10500.caffemodel
I0309 14:49:19.979991 55597 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_10500.solverstate
I0309 14:49:20.897233 55597 solver.cpp:338] Iteration 10500, Testing net (#0)
I0309 14:49:22.034586 55597 solver.cpp:406]     Test net output #0: accuracy = 0.954
I0309 14:49:22.034773 55597 solver.cpp:406]     Test net output #1: loss = 0.125602 (* 1 = 0.125602 loss)
I0309 14:49:22.635748 55597 solver.cpp:229] Iteration 10500, loss = 0.023639
I0309 14:49:22.635792 55597 solver.cpp:245]     Train net output #0: loss = 0.0236391 (* 1 = 0.0236391 loss)
I0309 14:49:22.635820 55597 sgd_solver.cpp:106] Iteration 10500, lr = 1e-05
I0309 14:50:01.521500 55597 solver.cpp:229] Iteration 10550, loss = 0.128661
I0309 14:50:01.521708 55597 solver.cpp:245]     Train net output #0: loss = 0.128661 (* 1 = 0.128661 loss)
I0309 14:50:01.521740 55597 sgd_solver.cpp:106] Iteration 10550, lr = 1e-05
I0309 14:50:40.409467 55597 solver.cpp:229] Iteration 10600, loss = 0.0530311
I0309 14:50:40.409674 55597 solver.cpp:245]     Train net output #0: loss = 0.0530312 (* 1 = 0.0530312 loss)
I0309 14:50:40.409708 55597 sgd_solver.cpp:106] Iteration 10600, lr = 1e-05
I0309 14:51:19.291335 55597 solver.cpp:229] Iteration 10650, loss = 0.0635434
I0309 14:51:19.291539 55597 solver.cpp:245]     Train net output #0: loss = 0.0635436 (* 1 = 0.0635436 loss)
I0309 14:51:19.291571 55597 sgd_solver.cpp:106] Iteration 10650, lr = 1e-05
I0309 14:51:58.173645 55597 solver.cpp:229] Iteration 10700, loss = 0.0641366
I0309 14:51:58.173820 55597 solver.cpp:245]     Train net output #0: loss = 0.0641368 (* 1 = 0.0641368 loss)
I0309 14:51:58.173853 55597 sgd_solver.cpp:106] Iteration 10700, lr = 1e-05
I0309 14:52:37.049799 55597 solver.cpp:229] Iteration 10750, loss = 0.0705425
I0309 14:52:37.050006 55597 solver.cpp:245]     Train net output #0: loss = 0.0705426 (* 1 = 0.0705426 loss)
I0309 14:52:37.050039 55597 sgd_solver.cpp:106] Iteration 10750, lr = 1e-05
I0309 14:53:15.164064 55597 solver.cpp:338] Iteration 10800, Testing net (#0)
I0309 14:53:16.472090 55597 solver.cpp:406]     Test net output #0: accuracy = 0.954
I0309 14:53:16.472270 55597 solver.cpp:406]     Test net output #1: loss = 0.124844 (* 1 = 0.124844 loss)
I0309 14:53:17.072334 55597 solver.cpp:229] Iteration 10800, loss = 0.0587509
I0309 14:53:17.072377 55597 solver.cpp:245]     Train net output #0: loss = 0.0587511 (* 1 = 0.0587511 loss)
I0309 14:53:17.072407 55597 sgd_solver.cpp:106] Iteration 10800, lr = 1e-05
I0309 14:53:55.950067 55597 solver.cpp:229] Iteration 10850, loss = 0.113019
I0309 14:53:55.950314 55597 solver.cpp:245]     Train net output #0: loss = 0.11302 (* 1 = 0.11302 loss)
I0309 14:53:55.950346 55597 sgd_solver.cpp:106] Iteration 10850, lr = 1e-05
I0309 14:54:34.831871 55597 solver.cpp:229] Iteration 10900, loss = 0.0944407
I0309 14:54:34.832051 55597 solver.cpp:245]     Train net output #0: loss = 0.0944408 (* 1 = 0.0944408 loss)
I0309 14:54:34.832084 55597 sgd_solver.cpp:106] Iteration 10900, lr = 1e-05
I0309 14:55:13.722331 55597 solver.cpp:229] Iteration 10950, loss = 0.0528054
I0309 14:55:13.722537 55597 solver.cpp:245]     Train net output #0: loss = 0.0528056 (* 1 = 0.0528056 loss)
I0309 14:55:13.722569 55597 sgd_solver.cpp:106] Iteration 10950, lr = 1e-05
I0309 14:55:51.828922 55597 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_11000.caffemodel
I0309 14:55:53.465080 55597 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_11000.solverstate
I0309 14:55:54.983016 55597 solver.cpp:229] Iteration 11000, loss = 0.035379
I0309 14:55:54.983095 55597 solver.cpp:245]     Train net output #0: loss = 0.0353791 (* 1 = 0.0353791 loss)
I0309 14:55:54.983139 55597 sgd_solver.cpp:106] Iteration 11000, lr = 1e-05
I0309 14:56:33.865159 55597 solver.cpp:229] Iteration 11050, loss = 0.0993998
I0309 14:56:33.865386 55597 solver.cpp:245]     Train net output #0: loss = 0.0994 (* 1 = 0.0994 loss)
I0309 14:56:33.865418 55597 sgd_solver.cpp:106] Iteration 11050, lr = 1e-05
I0309 14:57:11.962610 55597 solver.cpp:338] Iteration 11100, Testing net (#0)
I0309 14:57:13.269137 55597 solver.cpp:406]     Test net output #0: accuracy = 0.956
I0309 14:57:13.269325 55597 solver.cpp:406]     Test net output #1: loss = 0.124907 (* 1 = 0.124907 loss)
I0309 14:57:13.870422 55597 solver.cpp:229] Iteration 11100, loss = 0.0442066
I0309 14:57:13.870471 55597 solver.cpp:245]     Train net output #0: loss = 0.0442068 (* 1 = 0.0442068 loss)
I0309 14:57:13.870502 55597 sgd_solver.cpp:106] Iteration 11100, lr = 1e-05
I0309 14:57:52.750141 55597 solver.cpp:229] Iteration 11150, loss = 0.0512613
I0309 14:57:52.750383 55597 solver.cpp:245]     Train net output #0: loss = 0.0512614 (* 1 = 0.0512614 loss)
I0309 14:57:52.750416 55597 sgd_solver.cpp:106] Iteration 11150, lr = 1e-05
I0309 14:58:31.626062 55597 solver.cpp:229] Iteration 11200, loss = 0.0749732
I0309 14:58:31.626253 55597 solver.cpp:245]     Train net output #0: loss = 0.0749734 (* 1 = 0.0749734 loss)
I0309 14:58:31.626286 55597 sgd_solver.cpp:106] Iteration 11200, lr = 1e-05
I0309 14:59:10.504197 55597 solver.cpp:229] Iteration 11250, loss = 0.0441897
I0309 14:59:10.504407 55597 solver.cpp:245]     Train net output #0: loss = 0.0441899 (* 1 = 0.0441899 loss)
I0309 14:59:10.504441 55597 sgd_solver.cpp:106] Iteration 11250, lr = 1e-05
I0309 14:59:49.379216 55597 solver.cpp:229] Iteration 11300, loss = 0.0599398
I0309 14:59:49.379426 55597 solver.cpp:245]     Train net output #0: loss = 0.05994 (* 1 = 0.05994 loss)
I0309 14:59:49.379458 55597 sgd_solver.cpp:106] Iteration 11300, lr = 1e-05
I0309 15:00:28.263470 55597 solver.cpp:229] Iteration 11350, loss = 0.0462923
I0309 15:00:28.263679 55597 solver.cpp:245]     Train net output #0: loss = 0.0462924 (* 1 = 0.0462924 loss)
I0309 15:00:28.263710 55597 sgd_solver.cpp:106] Iteration 11350, lr = 1e-05
I0309 15:01:06.373042 55597 solver.cpp:338] Iteration 11400, Testing net (#0)
I0309 15:01:07.680079 55597 solver.cpp:406]     Test net output #0: accuracy = 0.958
I0309 15:01:07.680263 55597 solver.cpp:406]     Test net output #1: loss = 0.123911 (* 1 = 0.123911 loss)
I0309 15:01:08.281193 55597 solver.cpp:229] Iteration 11400, loss = 0.0672229
I0309 15:01:08.281237 55597 solver.cpp:245]     Train net output #0: loss = 0.067223 (* 1 = 0.067223 loss)
I0309 15:01:08.281266 55597 sgd_solver.cpp:106] Iteration 11400, lr = 1e-05
I0309 15:01:47.165565 55597 solver.cpp:229] Iteration 11450, loss = 0.0606783
I0309 15:01:47.165802 55597 solver.cpp:245]     Train net output #0: loss = 0.0606784 (* 1 = 0.0606784 loss)
I0309 15:01:47.165834 55597 sgd_solver.cpp:106] Iteration 11450, lr = 1e-05
I0309 15:02:25.270772 55597 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_11500.caffemodel
I0309 15:02:26.913048 55597 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_11500.solverstate
I0309 15:02:28.429250 55597 solver.cpp:229] Iteration 11500, loss = 0.027723
I0309 15:02:28.429337 55597 solver.cpp:245]     Train net output #0: loss = 0.0277231 (* 1 = 0.0277231 loss)
I0309 15:02:28.429366 55597 sgd_solver.cpp:106] Iteration 11500, lr = 1e-05
I0309 15:03:07.310740 55597 solver.cpp:229] Iteration 11550, loss = 0.0616161
I0309 15:03:07.310973 55597 solver.cpp:245]     Train net output #0: loss = 0.0616162 (* 1 = 0.0616162 loss)
I0309 15:03:07.311007 55597 sgd_solver.cpp:106] Iteration 11550, lr = 1e-05
I0309 15:03:46.195036 55597 solver.cpp:229] Iteration 11600, loss = 0.0650798
I0309 15:03:46.195257 55597 solver.cpp:245]     Train net output #0: loss = 0.0650799 (* 1 = 0.0650799 loss)
I0309 15:03:46.195307 55597 sgd_solver.cpp:106] Iteration 11600, lr = 1e-05
I0309 15:04:25.087836 55597 solver.cpp:229] Iteration 11650, loss = 0.10208
I0309 15:04:25.088052 55597 solver.cpp:245]     Train net output #0: loss = 0.10208 (* 1 = 0.10208 loss)
I0309 15:04:25.088085 55597 sgd_solver.cpp:106] Iteration 11650, lr = 1e-05
I0309 15:05:03.203279 55597 solver.cpp:338] Iteration 11700, Testing net (#0)
I0309 15:05:04.510334 55597 solver.cpp:406]     Test net output #0: accuracy = 0.958
I0309 15:05:04.510512 55597 solver.cpp:406]     Test net output #1: loss = 0.12516 (* 1 = 0.12516 loss)
I0309 15:05:05.111878 55597 solver.cpp:229] Iteration 11700, loss = 0.0986942
I0309 15:05:05.112052 55597 solver.cpp:245]     Train net output #0: loss = 0.0986944 (* 1 = 0.0986944 loss)
I0309 15:05:05.112082 55597 sgd_solver.cpp:106] Iteration 11700, lr = 1e-05
I0309 15:05:44.002694 55597 solver.cpp:229] Iteration 11750, loss = 0.0332149
I0309 15:05:44.003103 55597 solver.cpp:245]     Train net output #0: loss = 0.0332151 (* 1 = 0.0332151 loss)
I0309 15:05:44.003139 55597 sgd_solver.cpp:106] Iteration 11750, lr = 1e-05
I0309 15:06:22.888658 55597 solver.cpp:229] Iteration 11800, loss = 0.0591913
I0309 15:06:22.888932 55597 solver.cpp:245]     Train net output #0: loss = 0.0591915 (* 1 = 0.0591915 loss)
I0309 15:06:22.888965 55597 sgd_solver.cpp:106] Iteration 11800, lr = 1e-05
I0309 15:07:01.779072 55597 solver.cpp:229] Iteration 11850, loss = 0.139242
I0309 15:07:01.779278 55597 solver.cpp:245]     Train net output #0: loss = 0.139242 (* 1 = 0.139242 loss)
I0309 15:07:01.779314 55597 sgd_solver.cpp:106] Iteration 11850, lr = 1e-05
I0309 15:07:40.664968 55597 solver.cpp:229] Iteration 11900, loss = 0.0580066
I0309 15:07:40.665176 55597 solver.cpp:245]     Train net output #0: loss = 0.0580068 (* 1 = 0.0580068 loss)
I0309 15:07:40.665210 55597 sgd_solver.cpp:106] Iteration 11900, lr = 1e-05
I0309 15:08:19.547114 55597 solver.cpp:229] Iteration 11950, loss = 0.0820872
I0309 15:08:19.547323 55597 solver.cpp:245]     Train net output #0: loss = 0.0820874 (* 1 = 0.0820874 loss)
I0309 15:08:19.547356 55597 sgd_solver.cpp:106] Iteration 11950, lr = 1e-05
I0309 15:08:57.653983 55597 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_12000.caffemodel
I0309 15:08:59.285219 55597 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_12000.solverstate
I0309 15:09:00.202110 55597 solver.cpp:338] Iteration 12000, Testing net (#0)
I0309 15:09:01.339030 55597 solver.cpp:406]     Test net output #0: accuracy = 0.954
I0309 15:09:01.339213 55597 solver.cpp:406]     Test net output #1: loss = 0.125255 (* 1 = 0.125255 loss)
I0309 15:09:01.939513 55597 solver.cpp:229] Iteration 12000, loss = 0.0391661
I0309 15:09:01.939558 55597 solver.cpp:245]     Train net output #0: loss = 0.0391662 (* 1 = 0.0391662 loss)
I0309 15:09:01.939585 55597 sgd_solver.cpp:106] Iteration 12000, lr = 1e-05
I0309 15:09:40.821406 55597 solver.cpp:229] Iteration 12050, loss = 0.0792385
I0309 15:09:40.821615 55597 solver.cpp:245]     Train net output #0: loss = 0.0792387 (* 1 = 0.0792387 loss)
I0309 15:09:40.821647 55597 sgd_solver.cpp:106] Iteration 12050, lr = 1e-05
I0309 15:10:19.688644 55597 solver.cpp:229] Iteration 12100, loss = 0.028025
I0309 15:10:19.688963 55597 solver.cpp:245]     Train net output #0: loss = 0.0280251 (* 1 = 0.0280251 loss)
I0309 15:10:19.688997 55597 sgd_solver.cpp:106] Iteration 12100, lr = 1e-05
I0309 15:10:58.553179 55597 solver.cpp:229] Iteration 12150, loss = 0.070953
I0309 15:10:58.553378 55597 solver.cpp:245]     Train net output #0: loss = 0.0709532 (* 1 = 0.0709532 loss)
I0309 15:10:58.553411 55597 sgd_solver.cpp:106] Iteration 12150, lr = 1e-05
I0309 15:11:37.407392 55597 solver.cpp:229] Iteration 12200, loss = 0.0234383
I0309 15:11:37.407620 55597 solver.cpp:245]     Train net output #0: loss = 0.0234385 (* 1 = 0.0234385 loss)
I0309 15:11:37.407666 55597 sgd_solver.cpp:106] Iteration 12200, lr = 1e-05
I0309 15:12:16.259032 55597 solver.cpp:229] Iteration 12250, loss = 0.0437967
I0309 15:12:16.259229 55597 solver.cpp:245]     Train net output #0: loss = 0.0437969 (* 1 = 0.0437969 loss)
I0309 15:12:16.259263 55597 sgd_solver.cpp:106] Iteration 12250, lr = 1e-05
I0309 15:12:54.351783 55597 solver.cpp:338] Iteration 12300, Testing net (#0)
I0309 15:12:55.659129 55597 solver.cpp:406]     Test net output #0: accuracy = 0.958
I0309 15:12:55.659271 55597 solver.cpp:406]     Test net output #1: loss = 0.123716 (* 1 = 0.123716 loss)
I0309 15:12:56.259482 55597 solver.cpp:229] Iteration 12300, loss = 0.0509271
I0309 15:12:56.259526 55597 solver.cpp:245]     Train net output #0: loss = 0.0509272 (* 1 = 0.0509272 loss)
I0309 15:12:56.259555 55597 sgd_solver.cpp:106] Iteration 12300, lr = 1e-05
I0309 15:13:35.118890 55597 solver.cpp:229] Iteration 12350, loss = 0.0328691
I0309 15:13:35.119128 55597 solver.cpp:245]     Train net output #0: loss = 0.0328693 (* 1 = 0.0328693 loss)
I0309 15:13:35.119161 55597 sgd_solver.cpp:106] Iteration 12350, lr = 1e-05
I0309 15:14:13.964678 55597 solver.cpp:229] Iteration 12400, loss = 0.0226722
I0309 15:14:13.964884 55597 solver.cpp:245]     Train net output #0: loss = 0.0226724 (* 1 = 0.0226724 loss)
I0309 15:14:13.964916 55597 sgd_solver.cpp:106] Iteration 12400, lr = 1e-05
I0309 15:14:52.813050 55597 solver.cpp:229] Iteration 12450, loss = 0.0622511
I0309 15:14:52.813261 55597 solver.cpp:245]     Train net output #0: loss = 0.0622512 (* 1 = 0.0622512 loss)
I0309 15:14:52.813294 55597 sgd_solver.cpp:106] Iteration 12450, lr = 1e-05
I0309 15:15:30.889158 55597 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_12500.caffemodel
I0309 15:15:32.526048 55597 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_12500.solverstate
I0309 15:15:34.070549 55597 solver.cpp:229] Iteration 12500, loss = 0.124447
I0309 15:15:34.070633 55597 solver.cpp:245]     Train net output #0: loss = 0.124447 (* 1 = 0.124447 loss)
I0309 15:15:34.070662 55597 sgd_solver.cpp:106] Iteration 12500, lr = 1e-05
I0309 15:16:12.922703 55597 solver.cpp:229] Iteration 12550, loss = 0.0524029
I0309 15:16:12.922942 55597 solver.cpp:245]     Train net output #0: loss = 0.0524031 (* 1 = 0.0524031 loss)
I0309 15:16:12.922976 55597 sgd_solver.cpp:106] Iteration 12550, lr = 1e-05
I0309 15:16:50.990593 55597 solver.cpp:338] Iteration 12600, Testing net (#0)
I0309 15:16:52.297029 55597 solver.cpp:406]     Test net output #0: accuracy = 0.958
I0309 15:16:52.297168 55597 solver.cpp:406]     Test net output #1: loss = 0.123301 (* 1 = 0.123301 loss)
I0309 15:16:52.897805 55597 solver.cpp:229] Iteration 12600, loss = 0.0676784
I0309 15:16:52.897848 55597 solver.cpp:245]     Train net output #0: loss = 0.0676786 (* 1 = 0.0676786 loss)
I0309 15:16:52.897877 55597 sgd_solver.cpp:106] Iteration 12600, lr = 1e-05
I0309 15:17:31.742296 55597 solver.cpp:229] Iteration 12650, loss = 0.0807388
I0309 15:17:31.742532 55597 solver.cpp:245]     Train net output #0: loss = 0.080739 (* 1 = 0.080739 loss)
I0309 15:17:31.742565 55597 sgd_solver.cpp:106] Iteration 12650, lr = 1e-05
I0309 15:18:10.592896 55597 solver.cpp:229] Iteration 12700, loss = 0.052244
I0309 15:18:10.593101 55597 solver.cpp:245]     Train net output #0: loss = 0.0522441 (* 1 = 0.0522441 loss)
I0309 15:18:10.593133 55597 sgd_solver.cpp:106] Iteration 12700, lr = 1e-05
I0309 15:18:49.448617 55597 solver.cpp:229] Iteration 12750, loss = 0.0267106
I0309 15:18:49.448807 55597 solver.cpp:245]     Train net output #0: loss = 0.0267107 (* 1 = 0.0267107 loss)
I0309 15:18:49.448840 55597 sgd_solver.cpp:106] Iteration 12750, lr = 1e-05
I0309 15:19:28.294034 55597 solver.cpp:229] Iteration 12800, loss = 0.065725
I0309 15:19:28.294252 55597 solver.cpp:245]     Train net output #0: loss = 0.0657252 (* 1 = 0.0657252 loss)
I0309 15:19:28.294286 55597 sgd_solver.cpp:106] Iteration 12800, lr = 1e-05
I0309 15:20:07.139935 55597 solver.cpp:229] Iteration 12850, loss = 0.0568667
I0309 15:20:07.140143 55597 solver.cpp:245]     Train net output #0: loss = 0.0568669 (* 1 = 0.0568669 loss)
I0309 15:20:07.140177 55597 sgd_solver.cpp:106] Iteration 12850, lr = 1e-05
I0309 15:20:45.228323 55597 solver.cpp:338] Iteration 12900, Testing net (#0)
I0309 15:20:46.535897 55597 solver.cpp:406]     Test net output #0: accuracy = 0.956
I0309 15:20:46.536085 55597 solver.cpp:406]     Test net output #1: loss = 0.125739 (* 1 = 0.125739 loss)
I0309 15:20:47.136534 55597 solver.cpp:229] Iteration 12900, loss = 0.0293662
I0309 15:20:47.136708 55597 solver.cpp:245]     Train net output #0: loss = 0.0293664 (* 1 = 0.0293664 loss)
I0309 15:20:47.136736 55597 sgd_solver.cpp:106] Iteration 12900, lr = 1e-05
I0309 15:21:26.018952 55597 solver.cpp:229] Iteration 12950, loss = 0.0589789
I0309 15:21:26.019269 55597 solver.cpp:245]     Train net output #0: loss = 0.0589791 (* 1 = 0.0589791 loss)
I0309 15:21:26.019307 55597 sgd_solver.cpp:106] Iteration 12950, lr = 1e-05
I0309 15:22:04.129397 55597 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_13000.caffemodel
I0309 15:22:05.770422 55597 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_13000.solverstate
I0309 15:22:07.298578 55597 solver.cpp:229] Iteration 13000, loss = 0.0841853
I0309 15:22:07.298658 55597 solver.cpp:245]     Train net output #0: loss = 0.0841855 (* 1 = 0.0841855 loss)
I0309 15:22:07.298688 55597 sgd_solver.cpp:106] Iteration 13000, lr = 1e-05
I0309 15:22:46.187592 55597 solver.cpp:229] Iteration 13050, loss = 0.0629449
I0309 15:22:46.187801 55597 solver.cpp:245]     Train net output #0: loss = 0.0629451 (* 1 = 0.0629451 loss)
I0309 15:22:46.187834 55597 sgd_solver.cpp:106] Iteration 13050, lr = 1e-05
I0309 15:23:25.073087 55597 solver.cpp:229] Iteration 13100, loss = 0.0576298
I0309 15:23:25.073292 55597 solver.cpp:245]     Train net output #0: loss = 0.05763 (* 1 = 0.05763 loss)
I0309 15:23:25.073328 55597 sgd_solver.cpp:106] Iteration 13100, lr = 1e-05
I0309 15:24:03.952118 55597 solver.cpp:229] Iteration 13150, loss = 0.0548856
I0309 15:24:03.952332 55597 solver.cpp:245]     Train net output #0: loss = 0.0548858 (* 1 = 0.0548858 loss)
I0309 15:24:03.952364 55597 sgd_solver.cpp:106] Iteration 13150, lr = 1e-05
I0309 15:24:42.063148 55597 solver.cpp:338] Iteration 13200, Testing net (#0)
I0309 15:24:43.370822 55597 solver.cpp:406]     Test net output #0: accuracy = 0.956
I0309 15:24:43.371008 55597 solver.cpp:406]     Test net output #1: loss = 0.124752 (* 1 = 0.124752 loss)
I0309 15:24:43.971742 55597 solver.cpp:229] Iteration 13200, loss = 0.0746168
I0309 15:24:43.971793 55597 solver.cpp:245]     Train net output #0: loss = 0.074617 (* 1 = 0.074617 loss)
I0309 15:24:43.971827 55597 sgd_solver.cpp:106] Iteration 13200, lr = 1e-05
I0309 15:25:22.857909 55597 solver.cpp:229] Iteration 13250, loss = 0.0407371
I0309 15:25:22.858127 55597 solver.cpp:245]     Train net output #0: loss = 0.0407373 (* 1 = 0.0407373 loss)
I0309 15:25:22.858160 55597 sgd_solver.cpp:106] Iteration 13250, lr = 1e-05
I0309 15:26:01.751727 55597 solver.cpp:229] Iteration 13300, loss = 0.0545071
I0309 15:26:01.751911 55597 solver.cpp:245]     Train net output #0: loss = 0.0545073 (* 1 = 0.0545073 loss)
I0309 15:26:01.751945 55597 sgd_solver.cpp:106] Iteration 13300, lr = 1e-05
I0309 15:26:40.638095 55597 solver.cpp:229] Iteration 13350, loss = 0.0668755
I0309 15:26:40.638309 55597 solver.cpp:245]     Train net output #0: loss = 0.0668757 (* 1 = 0.0668757 loss)
I0309 15:26:40.638342 55597 sgd_solver.cpp:106] Iteration 13350, lr = 1e-05
I0309 15:27:19.522192 55597 solver.cpp:229] Iteration 13400, loss = 0.0872108
I0309 15:27:19.522380 55597 solver.cpp:245]     Train net output #0: loss = 0.087211 (* 1 = 0.087211 loss)
I0309 15:27:19.522413 55597 sgd_solver.cpp:106] Iteration 13400, lr = 1e-05
I0309 15:27:58.402282 55597 solver.cpp:229] Iteration 13450, loss = 0.0319481
I0309 15:27:58.402513 55597 solver.cpp:245]     Train net output #0: loss = 0.0319483 (* 1 = 0.0319483 loss)
I0309 15:27:58.402545 55597 sgd_solver.cpp:106] Iteration 13450, lr = 1e-05
I0309 15:28:36.519878 55597 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_13500.caffemodel
I0309 15:28:38.157229 55597 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_13500.solverstate
I0309 15:28:39.073683 55597 solver.cpp:338] Iteration 13500, Testing net (#0)
I0309 15:28:40.211525 55597 solver.cpp:406]     Test net output #0: accuracy = 0.958
I0309 15:28:40.211711 55597 solver.cpp:406]     Test net output #1: loss = 0.123146 (* 1 = 0.123146 loss)
I0309 15:28:40.813367 55597 solver.cpp:229] Iteration 13500, loss = 0.0516989
I0309 15:28:40.813410 55597 solver.cpp:245]     Train net output #0: loss = 0.0516991 (* 1 = 0.0516991 loss)
I0309 15:28:40.813437 55597 sgd_solver.cpp:106] Iteration 13500, lr = 1e-05
I0309 15:29:19.705293 55597 solver.cpp:229] Iteration 13550, loss = 0.0553328
I0309 15:29:19.705544 55597 solver.cpp:245]     Train net output #0: loss = 0.055333 (* 1 = 0.055333 loss)
I0309 15:29:19.705577 55597 sgd_solver.cpp:106] Iteration 13550, lr = 1e-05
I0309 15:29:58.586604 55597 solver.cpp:229] Iteration 13600, loss = 0.0651995
I0309 15:29:58.586807 55597 solver.cpp:245]     Train net output #0: loss = 0.0651997 (* 1 = 0.0651997 loss)
I0309 15:29:58.586838 55597 sgd_solver.cpp:106] Iteration 13600, lr = 1e-05
I0309 15:30:37.443953 55597 solver.cpp:229] Iteration 13650, loss = 0.058263
I0309 15:30:37.444305 55597 solver.cpp:245]     Train net output #0: loss = 0.0582632 (* 1 = 0.0582632 loss)
I0309 15:30:37.444342 55597 sgd_solver.cpp:106] Iteration 13650, lr = 1e-05
I0309 15:31:16.311159 55597 solver.cpp:229] Iteration 13700, loss = 0.0732329
I0309 15:31:16.311516 55597 solver.cpp:245]     Train net output #0: loss = 0.0732331 (* 1 = 0.0732331 loss)
I0309 15:31:16.311550 55597 sgd_solver.cpp:106] Iteration 13700, lr = 1e-05
I0309 15:31:55.171851 55597 solver.cpp:229] Iteration 13750, loss = 0.0434458
I0309 15:31:55.172185 55597 solver.cpp:245]     Train net output #0: loss = 0.043446 (* 1 = 0.043446 loss)
I0309 15:31:55.172221 55597 sgd_solver.cpp:106] Iteration 13750, lr = 1e-05
slurmstepd: *** JOB 447360 CANCELLED AT 2016-03-09T15:31:56 DUE TO TIME LIMIT on c221-104 ***
*** Aborted at 1457559116 (unix time) try "date -d @1457559116" if you are using GNU date ***
PC: @     0x7fff05af9a01 (unknown)
