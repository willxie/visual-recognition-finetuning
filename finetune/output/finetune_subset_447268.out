I0309 02:54:03.534410  1118 caffe.cpp:185] Using GPUs 0
I0309 02:54:03.551151  1118 caffe.cpp:190] GPU 0: Tesla K40m
I0309 02:54:04.607448  1118 solver.cpp:48] Initializing solver from parameters: 
test_iter: 25
test_interval: 300
base_lr: 0.0001
display: 50
max_iter: 100000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 10000
snapshot: 500
snapshot_prefix: "/work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb"
device_id: 0
net: "/work/04018/wxie/maverick/visual_recognition/finetune/train_val_lmdb.prototxt"
I0309 02:54:04.611673  1118 solver.cpp:91] Creating training net from net file: /work/04018/wxie/maverick/visual_recognition/finetune/train_val_lmdb.prototxt
I0309 02:54:04.615644  1118 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0309 02:54:04.615713  1118 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0309 02:54:04.615918  1118 net.cpp:49] Initializing net from parameters: 
name: "FlickrStyleCaffeNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/work/01932/dineshj/CS381V/caffe_install_scripts/caffe/data/ilsvrc12/imagenet_mean.binaryproto"
  }
  data_param {
    source: "/work/04018/wxie/maverick/visual_recognition/data/train-lmdb"
    batch_size: 128
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_subset"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8_subset"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  inner_product_param {
    num_output: 25
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_subset"
  bottom: "label"
  top: "loss"
}
I0309 02:54:04.616205  1118 layer_factory.hpp:77] Creating layer data
I0309 02:54:04.617005  1118 net.cpp:106] Creating Layer data
I0309 02:54:04.617064  1118 net.cpp:411] data -> data
I0309 02:54:04.617172  1118 net.cpp:411] data -> label
I0309 02:54:04.617252  1118 data_transformer.cpp:25] Loading mean file from: /work/01932/dineshj/CS381V/caffe_install_scripts/caffe/data/ilsvrc12/imagenet_mean.binaryproto
I0309 02:54:04.689596  1121 db_lmdb.cpp:38] Opened lmdb /work/04018/wxie/maverick/visual_recognition/data/train-lmdb
I0309 02:54:04.698359  1118 data_layer.cpp:41] output data size: 128,3,227,227
I0309 02:54:04.858721  1118 net.cpp:150] Setting up data
I0309 02:54:04.858829  1118 net.cpp:157] Top shape: 128 3 227 227 (19787136)
I0309 02:54:04.858866  1118 net.cpp:157] Top shape: 128 (128)
I0309 02:54:04.858896  1118 net.cpp:165] Memory required for data: 79149056
I0309 02:54:04.858943  1118 layer_factory.hpp:77] Creating layer conv1
I0309 02:54:04.859031  1118 net.cpp:106] Creating Layer conv1
I0309 02:54:04.859067  1118 net.cpp:454] conv1 <- data
I0309 02:54:04.859117  1118 net.cpp:411] conv1 -> conv1
I0309 02:54:04.869377  1118 net.cpp:150] Setting up conv1
I0309 02:54:04.869424  1118 net.cpp:157] Top shape: 128 96 55 55 (37171200)
I0309 02:54:04.869453  1118 net.cpp:165] Memory required for data: 227833856
I0309 02:54:04.869524  1118 layer_factory.hpp:77] Creating layer relu1
I0309 02:54:04.869560  1118 net.cpp:106] Creating Layer relu1
I0309 02:54:04.869587  1118 net.cpp:454] relu1 <- conv1
I0309 02:54:04.869621  1118 net.cpp:397] relu1 -> conv1 (in-place)
I0309 02:54:04.869657  1118 net.cpp:150] Setting up relu1
I0309 02:54:04.869686  1118 net.cpp:157] Top shape: 128 96 55 55 (37171200)
I0309 02:54:04.869711  1118 net.cpp:165] Memory required for data: 376518656
I0309 02:54:04.869738  1118 layer_factory.hpp:77] Creating layer pool1
I0309 02:54:04.869771  1118 net.cpp:106] Creating Layer pool1
I0309 02:54:04.869797  1118 net.cpp:454] pool1 <- conv1
I0309 02:54:04.869827  1118 net.cpp:411] pool1 -> pool1
I0309 02:54:04.869987  1118 net.cpp:150] Setting up pool1
I0309 02:54:04.870023  1118 net.cpp:157] Top shape: 128 96 27 27 (8957952)
I0309 02:54:04.870101  1118 net.cpp:165] Memory required for data: 412350464
I0309 02:54:04.870126  1118 layer_factory.hpp:77] Creating layer norm1
I0309 02:54:04.870157  1118 net.cpp:106] Creating Layer norm1
I0309 02:54:04.870182  1118 net.cpp:454] norm1 <- pool1
I0309 02:54:04.870209  1118 net.cpp:411] norm1 -> norm1
I0309 02:54:04.870313  1118 net.cpp:150] Setting up norm1
I0309 02:54:04.870348  1118 net.cpp:157] Top shape: 128 96 27 27 (8957952)
I0309 02:54:04.870376  1118 net.cpp:165] Memory required for data: 448182272
I0309 02:54:04.870403  1118 layer_factory.hpp:77] Creating layer conv2
I0309 02:54:04.870435  1118 net.cpp:106] Creating Layer conv2
I0309 02:54:04.870465  1118 net.cpp:454] conv2 <- norm1
I0309 02:54:04.870502  1118 net.cpp:411] conv2 -> conv2
I0309 02:54:04.883014  1118 net.cpp:150] Setting up conv2
I0309 02:54:04.883090  1118 net.cpp:157] Top shape: 128 256 27 27 (23887872)
I0309 02:54:04.883118  1118 net.cpp:165] Memory required for data: 543733760
I0309 02:54:04.883152  1118 layer_factory.hpp:77] Creating layer relu2
I0309 02:54:04.883183  1118 net.cpp:106] Creating Layer relu2
I0309 02:54:04.883209  1118 net.cpp:454] relu2 <- conv2
I0309 02:54:04.883235  1118 net.cpp:397] relu2 -> conv2 (in-place)
I0309 02:54:04.883265  1118 net.cpp:150] Setting up relu2
I0309 02:54:04.883291  1118 net.cpp:157] Top shape: 128 256 27 27 (23887872)
I0309 02:54:04.883316  1118 net.cpp:165] Memory required for data: 639285248
I0309 02:54:04.883342  1118 layer_factory.hpp:77] Creating layer pool2
I0309 02:54:04.883375  1118 net.cpp:106] Creating Layer pool2
I0309 02:54:04.883404  1118 net.cpp:454] pool2 <- conv2
I0309 02:54:04.883432  1118 net.cpp:411] pool2 -> pool2
I0309 02:54:04.883496  1118 net.cpp:150] Setting up pool2
I0309 02:54:04.883535  1118 net.cpp:157] Top shape: 128 256 13 13 (5537792)
I0309 02:54:04.883561  1118 net.cpp:165] Memory required for data: 661436416
I0309 02:54:04.883587  1118 layer_factory.hpp:77] Creating layer norm2
I0309 02:54:04.883620  1118 net.cpp:106] Creating Layer norm2
I0309 02:54:04.883648  1118 net.cpp:454] norm2 <- pool2
I0309 02:54:04.883677  1118 net.cpp:411] norm2 -> norm2
I0309 02:54:04.883738  1118 net.cpp:150] Setting up norm2
I0309 02:54:04.883771  1118 net.cpp:157] Top shape: 128 256 13 13 (5537792)
I0309 02:54:04.883798  1118 net.cpp:165] Memory required for data: 683587584
I0309 02:54:04.883826  1118 layer_factory.hpp:77] Creating layer conv3
I0309 02:54:04.883860  1118 net.cpp:106] Creating Layer conv3
I0309 02:54:04.883889  1118 net.cpp:454] conv3 <- norm2
I0309 02:54:04.883922  1118 net.cpp:411] conv3 -> conv3
I0309 02:54:04.918949  1118 net.cpp:150] Setting up conv3
I0309 02:54:04.919093  1118 net.cpp:157] Top shape: 128 384 13 13 (8306688)
I0309 02:54:04.919119  1118 net.cpp:165] Memory required for data: 716814336
I0309 02:54:04.919158  1118 layer_factory.hpp:77] Creating layer relu3
I0309 02:54:04.919198  1118 net.cpp:106] Creating Layer relu3
I0309 02:54:04.919227  1118 net.cpp:454] relu3 <- conv3
I0309 02:54:04.919267  1118 net.cpp:397] relu3 -> conv3 (in-place)
I0309 02:54:04.919314  1118 net.cpp:150] Setting up relu3
I0309 02:54:04.919342  1118 net.cpp:157] Top shape: 128 384 13 13 (8306688)
I0309 02:54:04.919363  1118 net.cpp:165] Memory required for data: 750041088
I0309 02:54:04.919386  1118 layer_factory.hpp:77] Creating layer conv4
I0309 02:54:04.919423  1118 net.cpp:106] Creating Layer conv4
I0309 02:54:04.919450  1118 net.cpp:454] conv4 <- conv3
I0309 02:54:04.919479  1118 net.cpp:411] conv4 -> conv4
I0309 02:54:04.951750  1118 net.cpp:150] Setting up conv4
I0309 02:54:04.951835  1118 net.cpp:157] Top shape: 128 384 13 13 (8306688)
I0309 02:54:04.951864  1118 net.cpp:165] Memory required for data: 783267840
I0309 02:54:04.951899  1118 layer_factory.hpp:77] Creating layer relu4
I0309 02:54:04.951936  1118 net.cpp:106] Creating Layer relu4
I0309 02:54:04.951966  1118 net.cpp:454] relu4 <- conv4
I0309 02:54:04.951998  1118 net.cpp:397] relu4 -> conv4 (in-place)
I0309 02:54:04.952033  1118 net.cpp:150] Setting up relu4
I0309 02:54:04.952088  1118 net.cpp:157] Top shape: 128 384 13 13 (8306688)
I0309 02:54:04.952147  1118 net.cpp:165] Memory required for data: 816494592
I0309 02:54:04.952175  1118 layer_factory.hpp:77] Creating layer conv5
I0309 02:54:04.952215  1118 net.cpp:106] Creating Layer conv5
I0309 02:54:04.952245  1118 net.cpp:454] conv5 <- conv4
I0309 02:54:04.952275  1118 net.cpp:411] conv5 -> conv5
I0309 02:54:04.969988  1118 net.cpp:150] Setting up conv5
I0309 02:54:04.970094  1118 net.cpp:157] Top shape: 128 256 13 13 (5537792)
I0309 02:54:04.970121  1118 net.cpp:165] Memory required for data: 838645760
I0309 02:54:04.970170  1118 layer_factory.hpp:77] Creating layer relu5
I0309 02:54:04.970207  1118 net.cpp:106] Creating Layer relu5
I0309 02:54:04.970244  1118 net.cpp:454] relu5 <- conv5
I0309 02:54:04.970273  1118 net.cpp:397] relu5 -> conv5 (in-place)
I0309 02:54:04.970306  1118 net.cpp:150] Setting up relu5
I0309 02:54:04.970335  1118 net.cpp:157] Top shape: 128 256 13 13 (5537792)
I0309 02:54:04.970371  1118 net.cpp:165] Memory required for data: 860796928
I0309 02:54:04.970402  1118 layer_factory.hpp:77] Creating layer pool5
I0309 02:54:04.970443  1118 net.cpp:106] Creating Layer pool5
I0309 02:54:04.970484  1118 net.cpp:454] pool5 <- conv5
I0309 02:54:04.970521  1118 net.cpp:411] pool5 -> pool5
I0309 02:54:04.970592  1118 net.cpp:150] Setting up pool5
I0309 02:54:04.970628  1118 net.cpp:157] Top shape: 128 256 6 6 (1179648)
I0309 02:54:04.970674  1118 net.cpp:165] Memory required for data: 865515520
I0309 02:54:04.970700  1118 layer_factory.hpp:77] Creating layer fc6
I0309 02:54:04.970788  1118 net.cpp:106] Creating Layer fc6
I0309 02:54:04.970819  1118 net.cpp:454] fc6 <- pool5
I0309 02:54:04.970852  1118 net.cpp:411] fc6 -> fc6
I0309 02:54:05.026434  1122 blocking_queue.cpp:50] Waiting for data
I0309 02:54:06.392537  1118 net.cpp:150] Setting up fc6
I0309 02:54:06.392678  1118 net.cpp:157] Top shape: 128 4096 (524288)
I0309 02:54:06.392704  1118 net.cpp:165] Memory required for data: 867612672
I0309 02:54:06.392736  1118 layer_factory.hpp:77] Creating layer relu6
I0309 02:54:06.392771  1118 net.cpp:106] Creating Layer relu6
I0309 02:54:06.392794  1118 net.cpp:454] relu6 <- fc6
I0309 02:54:06.392822  1118 net.cpp:397] relu6 -> fc6 (in-place)
I0309 02:54:06.392858  1118 net.cpp:150] Setting up relu6
I0309 02:54:06.392882  1118 net.cpp:157] Top shape: 128 4096 (524288)
I0309 02:54:06.392904  1118 net.cpp:165] Memory required for data: 869709824
I0309 02:54:06.392923  1118 layer_factory.hpp:77] Creating layer drop6
I0309 02:54:06.392951  1118 net.cpp:106] Creating Layer drop6
I0309 02:54:06.392972  1118 net.cpp:454] drop6 <- fc6
I0309 02:54:06.392998  1118 net.cpp:397] drop6 -> fc6 (in-place)
I0309 02:54:06.393090  1118 net.cpp:150] Setting up drop6
I0309 02:54:06.393120  1118 net.cpp:157] Top shape: 128 4096 (524288)
I0309 02:54:06.393141  1118 net.cpp:165] Memory required for data: 871806976
I0309 02:54:06.393162  1118 layer_factory.hpp:77] Creating layer fc7
I0309 02:54:06.393193  1118 net.cpp:106] Creating Layer fc7
I0309 02:54:06.393216  1118 net.cpp:454] fc7 <- fc6
I0309 02:54:06.393239  1118 net.cpp:411] fc7 -> fc7
I0309 02:54:07.007221  1118 net.cpp:150] Setting up fc7
I0309 02:54:07.007357  1118 net.cpp:157] Top shape: 128 4096 (524288)
I0309 02:54:07.007381  1118 net.cpp:165] Memory required for data: 873904128
I0309 02:54:07.007413  1118 layer_factory.hpp:77] Creating layer relu7
I0309 02:54:07.007447  1118 net.cpp:106] Creating Layer relu7
I0309 02:54:07.007472  1118 net.cpp:454] relu7 <- fc7
I0309 02:54:07.007505  1118 net.cpp:397] relu7 -> fc7 (in-place)
I0309 02:54:07.007544  1118 net.cpp:150] Setting up relu7
I0309 02:54:07.007570  1118 net.cpp:157] Top shape: 128 4096 (524288)
I0309 02:54:07.007591  1118 net.cpp:165] Memory required for data: 876001280
I0309 02:54:07.007611  1118 layer_factory.hpp:77] Creating layer drop7
I0309 02:54:07.007638  1118 net.cpp:106] Creating Layer drop7
I0309 02:54:07.007660  1118 net.cpp:454] drop7 <- fc7
I0309 02:54:07.007683  1118 net.cpp:397] drop7 -> fc7 (in-place)
I0309 02:54:07.007755  1118 net.cpp:150] Setting up drop7
I0309 02:54:07.007817  1118 net.cpp:157] Top shape: 128 4096 (524288)
I0309 02:54:07.007839  1118 net.cpp:165] Memory required for data: 878098432
I0309 02:54:07.007860  1118 layer_factory.hpp:77] Creating layer fc8_subset
I0309 02:54:07.007892  1118 net.cpp:106] Creating Layer fc8_subset
I0309 02:54:07.007916  1118 net.cpp:454] fc8_subset <- fc7
I0309 02:54:07.007941  1118 net.cpp:411] fc8_subset -> fc8_subset
I0309 02:54:07.012205  1118 net.cpp:150] Setting up fc8_subset
I0309 02:54:07.012243  1118 net.cpp:157] Top shape: 128 25 (3200)
I0309 02:54:07.012265  1118 net.cpp:165] Memory required for data: 878111232
I0309 02:54:07.012290  1118 layer_factory.hpp:77] Creating layer loss
I0309 02:54:07.012316  1118 net.cpp:106] Creating Layer loss
I0309 02:54:07.012338  1118 net.cpp:454] loss <- fc8_subset
I0309 02:54:07.012362  1118 net.cpp:454] loss <- label
I0309 02:54:07.012389  1118 net.cpp:411] loss -> loss
I0309 02:54:07.012462  1118 layer_factory.hpp:77] Creating layer loss
I0309 02:54:07.012593  1118 net.cpp:150] Setting up loss
I0309 02:54:07.012624  1118 net.cpp:157] Top shape: (1)
I0309 02:54:07.012645  1118 net.cpp:160]     with loss weight 1
I0309 02:54:07.012709  1118 net.cpp:165] Memory required for data: 878111236
I0309 02:54:07.012732  1118 net.cpp:226] loss needs backward computation.
I0309 02:54:07.012753  1118 net.cpp:226] fc8_subset needs backward computation.
I0309 02:54:07.012774  1118 net.cpp:226] drop7 needs backward computation.
I0309 02:54:07.012794  1118 net.cpp:226] relu7 needs backward computation.
I0309 02:54:07.012814  1118 net.cpp:226] fc7 needs backward computation.
I0309 02:54:07.012835  1118 net.cpp:226] drop6 needs backward computation.
I0309 02:54:07.012856  1118 net.cpp:226] relu6 needs backward computation.
I0309 02:54:07.012874  1118 net.cpp:226] fc6 needs backward computation.
I0309 02:54:07.012895  1118 net.cpp:226] pool5 needs backward computation.
I0309 02:54:07.012917  1118 net.cpp:226] relu5 needs backward computation.
I0309 02:54:07.012936  1118 net.cpp:226] conv5 needs backward computation.
I0309 02:54:07.012956  1118 net.cpp:226] relu4 needs backward computation.
I0309 02:54:07.012977  1118 net.cpp:226] conv4 needs backward computation.
I0309 02:54:07.012998  1118 net.cpp:226] relu3 needs backward computation.
I0309 02:54:07.013018  1118 net.cpp:226] conv3 needs backward computation.
I0309 02:54:07.013043  1118 net.cpp:226] norm2 needs backward computation.
I0309 02:54:07.013067  1118 net.cpp:226] pool2 needs backward computation.
I0309 02:54:07.013087  1118 net.cpp:226] relu2 needs backward computation.
I0309 02:54:07.013108  1118 net.cpp:226] conv2 needs backward computation.
I0309 02:54:07.013128  1118 net.cpp:226] norm1 needs backward computation.
I0309 02:54:07.013149  1118 net.cpp:226] pool1 needs backward computation.
I0309 02:54:07.013170  1118 net.cpp:226] relu1 needs backward computation.
I0309 02:54:07.013190  1118 net.cpp:226] conv1 needs backward computation.
I0309 02:54:07.013211  1118 net.cpp:228] data does not need backward computation.
I0309 02:54:07.013232  1118 net.cpp:270] This network produces output loss
I0309 02:54:07.013270  1118 net.cpp:283] Network initialization done.
I0309 02:54:07.015005  1118 solver.cpp:181] Creating test net (#0) specified by net file: /work/04018/wxie/maverick/visual_recognition/finetune/train_val_lmdb.prototxt
I0309 02:54:07.015076  1118 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0309 02:54:07.015328  1118 net.cpp:49] Initializing net from parameters: 
name: "FlickrStyleCaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_file: "/work/01932/dineshj/CS381V/caffe_install_scripts/caffe/data/ilsvrc12/imagenet_mean.binaryproto"
  }
  data_param {
    source: "/work/04018/wxie/maverick/visual_recognition/data/test-lmdb"
    batch_size: 20
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_subset"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8_subset"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  inner_product_param {
    num_output: 25
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_subset"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8_subset"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0309 02:54:07.015507  1118 layer_factory.hpp:77] Creating layer data
I0309 02:54:07.015672  1118 net.cpp:106] Creating Layer data
I0309 02:54:07.015720  1118 net.cpp:411] data -> data
I0309 02:54:07.015756  1118 net.cpp:411] data -> label
I0309 02:54:07.015789  1118 data_transformer.cpp:25] Loading mean file from: /work/01932/dineshj/CS381V/caffe_install_scripts/caffe/data/ilsvrc12/imagenet_mean.binaryproto
I0309 02:54:07.088744  1123 db_lmdb.cpp:38] Opened lmdb /work/04018/wxie/maverick/visual_recognition/data/test-lmdb
I0309 02:54:07.090607  1118 data_layer.cpp:41] output data size: 20,3,227,227
I0309 02:54:07.114486  1118 net.cpp:150] Setting up data
I0309 02:54:07.114576  1118 net.cpp:157] Top shape: 20 3 227 227 (3091740)
I0309 02:54:07.114624  1118 net.cpp:157] Top shape: 20 (20)
I0309 02:54:07.114655  1118 net.cpp:165] Memory required for data: 12367040
I0309 02:54:07.114684  1118 layer_factory.hpp:77] Creating layer label_data_1_split
I0309 02:54:07.114719  1118 net.cpp:106] Creating Layer label_data_1_split
I0309 02:54:07.114751  1118 net.cpp:454] label_data_1_split <- label
I0309 02:54:07.114784  1118 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0309 02:54:07.114822  1118 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0309 02:54:07.114918  1118 net.cpp:150] Setting up label_data_1_split
I0309 02:54:07.114954  1118 net.cpp:157] Top shape: 20 (20)
I0309 02:54:07.114984  1118 net.cpp:157] Top shape: 20 (20)
I0309 02:54:07.115010  1118 net.cpp:165] Memory required for data: 12367200
I0309 02:54:07.115036  1118 layer_factory.hpp:77] Creating layer conv1
I0309 02:54:07.115072  1118 net.cpp:106] Creating Layer conv1
I0309 02:54:07.115100  1118 net.cpp:454] conv1 <- data
I0309 02:54:07.115130  1118 net.cpp:411] conv1 -> conv1
I0309 02:54:07.116711  1118 net.cpp:150] Setting up conv1
I0309 02:54:07.116758  1118 net.cpp:157] Top shape: 20 96 55 55 (5808000)
I0309 02:54:07.116787  1118 net.cpp:165] Memory required for data: 35599200
I0309 02:54:07.116822  1118 layer_factory.hpp:77] Creating layer relu1
I0309 02:54:07.116853  1118 net.cpp:106] Creating Layer relu1
I0309 02:54:07.116880  1118 net.cpp:454] relu1 <- conv1
I0309 02:54:07.116909  1118 net.cpp:397] relu1 -> conv1 (in-place)
I0309 02:54:07.116941  1118 net.cpp:150] Setting up relu1
I0309 02:54:07.116971  1118 net.cpp:157] Top shape: 20 96 55 55 (5808000)
I0309 02:54:07.116998  1118 net.cpp:165] Memory required for data: 58831200
I0309 02:54:07.117025  1118 layer_factory.hpp:77] Creating layer pool1
I0309 02:54:07.117055  1118 net.cpp:106] Creating Layer pool1
I0309 02:54:07.117084  1118 net.cpp:454] pool1 <- conv1
I0309 02:54:07.117113  1118 net.cpp:411] pool1 -> pool1
I0309 02:54:07.117173  1118 net.cpp:150] Setting up pool1
I0309 02:54:07.117209  1118 net.cpp:157] Top shape: 20 96 27 27 (1399680)
I0309 02:54:07.117236  1118 net.cpp:165] Memory required for data: 64429920
I0309 02:54:07.117261  1118 layer_factory.hpp:77] Creating layer norm1
I0309 02:54:07.117291  1118 net.cpp:106] Creating Layer norm1
I0309 02:54:07.117317  1118 net.cpp:454] norm1 <- pool1
I0309 02:54:07.117347  1118 net.cpp:411] norm1 -> norm1
I0309 02:54:07.117403  1118 net.cpp:150] Setting up norm1
I0309 02:54:07.117437  1118 net.cpp:157] Top shape: 20 96 27 27 (1399680)
I0309 02:54:07.117465  1118 net.cpp:165] Memory required for data: 70028640
I0309 02:54:07.117488  1118 layer_factory.hpp:77] Creating layer conv2
I0309 02:54:07.117522  1118 net.cpp:106] Creating Layer conv2
I0309 02:54:07.117566  1118 net.cpp:454] conv2 <- norm1
I0309 02:54:07.117621  1118 net.cpp:411] conv2 -> conv2
I0309 02:54:07.130342  1118 net.cpp:150] Setting up conv2
I0309 02:54:07.130389  1118 net.cpp:157] Top shape: 20 256 27 27 (3732480)
I0309 02:54:07.130425  1118 net.cpp:165] Memory required for data: 84958560
I0309 02:54:07.130455  1118 layer_factory.hpp:77] Creating layer relu2
I0309 02:54:07.130494  1118 net.cpp:106] Creating Layer relu2
I0309 02:54:07.130525  1118 net.cpp:454] relu2 <- conv2
I0309 02:54:07.130568  1118 net.cpp:397] relu2 -> conv2 (in-place)
I0309 02:54:07.130610  1118 net.cpp:150] Setting up relu2
I0309 02:54:07.130643  1118 net.cpp:157] Top shape: 20 256 27 27 (3732480)
I0309 02:54:07.130671  1118 net.cpp:165] Memory required for data: 99888480
I0309 02:54:07.130698  1118 layer_factory.hpp:77] Creating layer pool2
I0309 02:54:07.130733  1118 net.cpp:106] Creating Layer pool2
I0309 02:54:07.130764  1118 net.cpp:454] pool2 <- conv2
I0309 02:54:07.130805  1118 net.cpp:411] pool2 -> pool2
I0309 02:54:07.130882  1118 net.cpp:150] Setting up pool2
I0309 02:54:07.130928  1118 net.cpp:157] Top shape: 20 256 13 13 (865280)
I0309 02:54:07.130956  1118 net.cpp:165] Memory required for data: 103349600
I0309 02:54:07.130982  1118 layer_factory.hpp:77] Creating layer norm2
I0309 02:54:07.131013  1118 net.cpp:106] Creating Layer norm2
I0309 02:54:07.131042  1118 net.cpp:454] norm2 <- pool2
I0309 02:54:07.131069  1118 net.cpp:411] norm2 -> norm2
I0309 02:54:07.131129  1118 net.cpp:150] Setting up norm2
I0309 02:54:07.131165  1118 net.cpp:157] Top shape: 20 256 13 13 (865280)
I0309 02:54:07.131191  1118 net.cpp:165] Memory required for data: 106810720
I0309 02:54:07.131217  1118 layer_factory.hpp:77] Creating layer conv3
I0309 02:54:07.131250  1118 net.cpp:106] Creating Layer conv3
I0309 02:54:07.131279  1118 net.cpp:454] conv3 <- norm2
I0309 02:54:07.131319  1118 net.cpp:411] conv3 -> conv3
I0309 02:54:07.167719  1118 net.cpp:150] Setting up conv3
I0309 02:54:07.167812  1118 net.cpp:157] Top shape: 20 384 13 13 (1297920)
I0309 02:54:07.167841  1118 net.cpp:165] Memory required for data: 112002400
I0309 02:54:07.167878  1118 layer_factory.hpp:77] Creating layer relu3
I0309 02:54:07.167913  1118 net.cpp:106] Creating Layer relu3
I0309 02:54:07.167943  1118 net.cpp:454] relu3 <- conv3
I0309 02:54:07.167973  1118 net.cpp:397] relu3 -> conv3 (in-place)
I0309 02:54:07.168009  1118 net.cpp:150] Setting up relu3
I0309 02:54:07.168040  1118 net.cpp:157] Top shape: 20 384 13 13 (1297920)
I0309 02:54:07.168066  1118 net.cpp:165] Memory required for data: 117194080
I0309 02:54:07.168094  1118 layer_factory.hpp:77] Creating layer conv4
I0309 02:54:07.168133  1118 net.cpp:106] Creating Layer conv4
I0309 02:54:07.168162  1118 net.cpp:454] conv4 <- conv3
I0309 02:54:07.168196  1118 net.cpp:411] conv4 -> conv4
I0309 02:54:07.195217  1118 net.cpp:150] Setting up conv4
I0309 02:54:07.195266  1118 net.cpp:157] Top shape: 20 384 13 13 (1297920)
I0309 02:54:07.195294  1118 net.cpp:165] Memory required for data: 122385760
I0309 02:54:07.195324  1118 layer_factory.hpp:77] Creating layer relu4
I0309 02:54:07.195358  1118 net.cpp:106] Creating Layer relu4
I0309 02:54:07.195384  1118 net.cpp:454] relu4 <- conv4
I0309 02:54:07.195412  1118 net.cpp:397] relu4 -> conv4 (in-place)
I0309 02:54:07.195444  1118 net.cpp:150] Setting up relu4
I0309 02:54:07.195473  1118 net.cpp:157] Top shape: 20 384 13 13 (1297920)
I0309 02:54:07.195503  1118 net.cpp:165] Memory required for data: 127577440
I0309 02:54:07.195530  1118 layer_factory.hpp:77] Creating layer conv5
I0309 02:54:07.195564  1118 net.cpp:106] Creating Layer conv5
I0309 02:54:07.195593  1118 net.cpp:454] conv5 <- conv4
I0309 02:54:07.195624  1118 net.cpp:411] conv5 -> conv5
I0309 02:54:07.213304  1118 net.cpp:150] Setting up conv5
I0309 02:54:07.213343  1118 net.cpp:157] Top shape: 20 256 13 13 (865280)
I0309 02:54:07.213366  1118 net.cpp:165] Memory required for data: 131038560
I0309 02:54:07.213394  1118 layer_factory.hpp:77] Creating layer relu5
I0309 02:54:07.213423  1118 net.cpp:106] Creating Layer relu5
I0309 02:54:07.213531  1118 net.cpp:454] relu5 <- conv5
I0309 02:54:07.213560  1118 net.cpp:397] relu5 -> conv5 (in-place)
I0309 02:54:07.213587  1118 net.cpp:150] Setting up relu5
I0309 02:54:07.213613  1118 net.cpp:157] Top shape: 20 256 13 13 (865280)
I0309 02:54:07.213632  1118 net.cpp:165] Memory required for data: 134499680
I0309 02:54:07.213654  1118 layer_factory.hpp:77] Creating layer pool5
I0309 02:54:07.213685  1118 net.cpp:106] Creating Layer pool5
I0309 02:54:07.213709  1118 net.cpp:454] pool5 <- conv5
I0309 02:54:07.213732  1118 net.cpp:411] pool5 -> pool5
I0309 02:54:07.213806  1118 net.cpp:150] Setting up pool5
I0309 02:54:07.213837  1118 net.cpp:157] Top shape: 20 256 6 6 (184320)
I0309 02:54:07.213871  1118 net.cpp:165] Memory required for data: 135236960
I0309 02:54:07.213894  1118 layer_factory.hpp:77] Creating layer fc6
I0309 02:54:07.213923  1118 net.cpp:106] Creating Layer fc6
I0309 02:54:07.213946  1118 net.cpp:454] fc6 <- pool5
I0309 02:54:07.213975  1118 net.cpp:411] fc6 -> fc6
I0309 02:54:08.596266  1118 net.cpp:150] Setting up fc6
I0309 02:54:08.596400  1118 net.cpp:157] Top shape: 20 4096 (81920)
I0309 02:54:08.596424  1118 net.cpp:165] Memory required for data: 135564640
I0309 02:54:08.596457  1118 layer_factory.hpp:77] Creating layer relu6
I0309 02:54:08.596494  1118 net.cpp:106] Creating Layer relu6
I0309 02:54:08.596524  1118 net.cpp:454] relu6 <- fc6
I0309 02:54:08.596552  1118 net.cpp:397] relu6 -> fc6 (in-place)
I0309 02:54:08.596590  1118 net.cpp:150] Setting up relu6
I0309 02:54:08.596614  1118 net.cpp:157] Top shape: 20 4096 (81920)
I0309 02:54:08.596634  1118 net.cpp:165] Memory required for data: 135892320
I0309 02:54:08.596655  1118 layer_factory.hpp:77] Creating layer drop6
I0309 02:54:08.596683  1118 net.cpp:106] Creating Layer drop6
I0309 02:54:08.596704  1118 net.cpp:454] drop6 <- fc6
I0309 02:54:08.596727  1118 net.cpp:397] drop6 -> fc6 (in-place)
I0309 02:54:08.596778  1118 net.cpp:150] Setting up drop6
I0309 02:54:08.596808  1118 net.cpp:157] Top shape: 20 4096 (81920)
I0309 02:54:08.596829  1118 net.cpp:165] Memory required for data: 136220000
I0309 02:54:08.596850  1118 layer_factory.hpp:77] Creating layer fc7
I0309 02:54:08.596880  1118 net.cpp:106] Creating Layer fc7
I0309 02:54:08.596902  1118 net.cpp:454] fc7 <- fc6
I0309 02:54:08.596927  1118 net.cpp:411] fc7 -> fc7
I0309 02:54:09.210281  1118 net.cpp:150] Setting up fc7
I0309 02:54:09.210418  1118 net.cpp:157] Top shape: 20 4096 (81920)
I0309 02:54:09.210443  1118 net.cpp:165] Memory required for data: 136547680
I0309 02:54:09.210474  1118 layer_factory.hpp:77] Creating layer relu7
I0309 02:54:09.210515  1118 net.cpp:106] Creating Layer relu7
I0309 02:54:09.210541  1118 net.cpp:454] relu7 <- fc7
I0309 02:54:09.210571  1118 net.cpp:397] relu7 -> fc7 (in-place)
I0309 02:54:09.210608  1118 net.cpp:150] Setting up relu7
I0309 02:54:09.210631  1118 net.cpp:157] Top shape: 20 4096 (81920)
I0309 02:54:09.210652  1118 net.cpp:165] Memory required for data: 136875360
I0309 02:54:09.210674  1118 layer_factory.hpp:77] Creating layer drop7
I0309 02:54:09.210701  1118 net.cpp:106] Creating Layer drop7
I0309 02:54:09.210727  1118 net.cpp:454] drop7 <- fc7
I0309 02:54:09.210750  1118 net.cpp:397] drop7 -> fc7 (in-place)
I0309 02:54:09.210798  1118 net.cpp:150] Setting up drop7
I0309 02:54:09.210829  1118 net.cpp:157] Top shape: 20 4096 (81920)
I0309 02:54:09.210850  1118 net.cpp:165] Memory required for data: 137203040
I0309 02:54:09.210870  1118 layer_factory.hpp:77] Creating layer fc8_subset
I0309 02:54:09.210901  1118 net.cpp:106] Creating Layer fc8_subset
I0309 02:54:09.210925  1118 net.cpp:454] fc8_subset <- fc7
I0309 02:54:09.210952  1118 net.cpp:411] fc8_subset -> fc8_subset
I0309 02:54:09.214645  1118 net.cpp:150] Setting up fc8_subset
I0309 02:54:09.214680  1118 net.cpp:157] Top shape: 20 25 (500)
I0309 02:54:09.214702  1118 net.cpp:165] Memory required for data: 137205040
I0309 02:54:09.214727  1118 layer_factory.hpp:77] Creating layer fc8_subset_fc8_subset_0_split
I0309 02:54:09.214782  1118 net.cpp:106] Creating Layer fc8_subset_fc8_subset_0_split
I0309 02:54:09.214844  1118 net.cpp:454] fc8_subset_fc8_subset_0_split <- fc8_subset
I0309 02:54:09.214869  1118 net.cpp:411] fc8_subset_fc8_subset_0_split -> fc8_subset_fc8_subset_0_split_0
I0309 02:54:09.214896  1118 net.cpp:411] fc8_subset_fc8_subset_0_split -> fc8_subset_fc8_subset_0_split_1
I0309 02:54:09.214951  1118 net.cpp:150] Setting up fc8_subset_fc8_subset_0_split
I0309 02:54:09.214982  1118 net.cpp:157] Top shape: 20 25 (500)
I0309 02:54:09.215005  1118 net.cpp:157] Top shape: 20 25 (500)
I0309 02:54:09.215025  1118 net.cpp:165] Memory required for data: 137209040
I0309 02:54:09.215046  1118 layer_factory.hpp:77] Creating layer loss
I0309 02:54:09.215070  1118 net.cpp:106] Creating Layer loss
I0309 02:54:09.215090  1118 net.cpp:454] loss <- fc8_subset_fc8_subset_0_split_0
I0309 02:54:09.215113  1118 net.cpp:454] loss <- label_data_1_split_0
I0309 02:54:09.215139  1118 net.cpp:411] loss -> loss
I0309 02:54:09.215169  1118 layer_factory.hpp:77] Creating layer loss
I0309 02:54:09.215265  1118 net.cpp:150] Setting up loss
I0309 02:54:09.215296  1118 net.cpp:157] Top shape: (1)
I0309 02:54:09.215317  1118 net.cpp:160]     with loss weight 1
I0309 02:54:09.215351  1118 net.cpp:165] Memory required for data: 137209044
I0309 02:54:09.215373  1118 layer_factory.hpp:77] Creating layer accuracy
I0309 02:54:09.215399  1118 net.cpp:106] Creating Layer accuracy
I0309 02:54:09.215421  1118 net.cpp:454] accuracy <- fc8_subset_fc8_subset_0_split_1
I0309 02:54:09.215445  1118 net.cpp:454] accuracy <- label_data_1_split_1
I0309 02:54:09.215467  1118 net.cpp:411] accuracy -> accuracy
I0309 02:54:09.215556  1118 net.cpp:150] Setting up accuracy
I0309 02:54:09.215584  1118 net.cpp:157] Top shape: (1)
I0309 02:54:09.215605  1118 net.cpp:165] Memory required for data: 137209048
I0309 02:54:09.215627  1118 net.cpp:228] accuracy does not need backward computation.
I0309 02:54:09.215648  1118 net.cpp:226] loss needs backward computation.
I0309 02:54:09.215669  1118 net.cpp:226] fc8_subset_fc8_subset_0_split needs backward computation.
I0309 02:54:09.215694  1118 net.cpp:226] fc8_subset needs backward computation.
I0309 02:54:09.215715  1118 net.cpp:226] drop7 needs backward computation.
I0309 02:54:09.215735  1118 net.cpp:226] relu7 needs backward computation.
I0309 02:54:09.215755  1118 net.cpp:226] fc7 needs backward computation.
I0309 02:54:09.215776  1118 net.cpp:226] drop6 needs backward computation.
I0309 02:54:09.215796  1118 net.cpp:226] relu6 needs backward computation.
I0309 02:54:09.215816  1118 net.cpp:226] fc6 needs backward computation.
I0309 02:54:09.215837  1118 net.cpp:226] pool5 needs backward computation.
I0309 02:54:09.215857  1118 net.cpp:226] relu5 needs backward computation.
I0309 02:54:09.215878  1118 net.cpp:226] conv5 needs backward computation.
I0309 02:54:09.215898  1118 net.cpp:226] relu4 needs backward computation.
I0309 02:54:09.215919  1118 net.cpp:226] conv4 needs backward computation.
I0309 02:54:09.215939  1118 net.cpp:226] relu3 needs backward computation.
I0309 02:54:09.215960  1118 net.cpp:226] conv3 needs backward computation.
I0309 02:54:09.215981  1118 net.cpp:226] norm2 needs backward computation.
I0309 02:54:09.216001  1118 net.cpp:226] pool2 needs backward computation.
I0309 02:54:09.216022  1118 net.cpp:226] relu2 needs backward computation.
I0309 02:54:09.216042  1118 net.cpp:226] conv2 needs backward computation.
I0309 02:54:09.216063  1118 net.cpp:226] norm1 needs backward computation.
I0309 02:54:09.216084  1118 net.cpp:226] pool1 needs backward computation.
I0309 02:54:09.216104  1118 net.cpp:226] relu1 needs backward computation.
I0309 02:54:09.216125  1118 net.cpp:226] conv1 needs backward computation.
I0309 02:54:09.216146  1118 net.cpp:228] label_data_1_split does not need backward computation.
I0309 02:54:09.216168  1118 net.cpp:228] data does not need backward computation.
I0309 02:54:09.216188  1118 net.cpp:270] This network produces output accuracy
I0309 02:54:09.216209  1118 net.cpp:270] This network produces output loss
I0309 02:54:09.216259  1118 net.cpp:283] Network initialization done.
I0309 02:54:09.238675  1118 solver.cpp:60] Solver scaffolding done.
I0309 02:54:09.239228  1118 caffe.cpp:129] Finetuning from /work/01932/dineshj/CS381V/caffe_install_scripts/caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I0309 02:54:10.243516  1118 upgrade_proto.cpp:42] Attempting to upgrade input file specified using deprecated transformation parameters: /work/01932/dineshj/CS381V/caffe_install_scripts/caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I0309 02:54:10.243585  1118 upgrade_proto.cpp:45] Successfully upgraded file specified using deprecated data transformation parameters.
W0309 02:54:10.243624  1118 upgrade_proto.cpp:47] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0309 02:54:10.247623  1118 upgrade_proto.cpp:51] Attempting to upgrade input file specified using deprecated V1LayerParameter: /work/01932/dineshj/CS381V/caffe_install_scripts/caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I0309 02:54:10.520275  1118 upgrade_proto.cpp:59] Successfully upgraded file specified using deprecated V1LayerParameter
I0309 02:54:10.562288  1118 net.cpp:816] Ignoring source layer fc8
I0309 02:54:11.293721  1118 upgrade_proto.cpp:42] Attempting to upgrade input file specified using deprecated transformation parameters: /work/01932/dineshj/CS381V/caffe_install_scripts/caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I0309 02:54:11.293788  1118 upgrade_proto.cpp:45] Successfully upgraded file specified using deprecated data transformation parameters.
W0309 02:54:11.293812  1118 upgrade_proto.cpp:47] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0309 02:54:11.293853  1118 upgrade_proto.cpp:51] Attempting to upgrade input file specified using deprecated V1LayerParameter: /work/01932/dineshj/CS381V/caffe_install_scripts/caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I0309 02:54:11.563627  1118 upgrade_proto.cpp:59] Successfully upgraded file specified using deprecated V1LayerParameter
I0309 02:54:11.605599  1118 net.cpp:816] Ignoring source layer fc8
I0309 02:54:11.607612  1118 caffe.cpp:219] Starting Optimization
I0309 02:54:11.607648  1118 solver.cpp:280] Solving FlickrStyleCaffeNet
I0309 02:54:11.607671  1118 solver.cpp:281] Learning Rate Policy: step
I0309 02:54:11.609242  1118 solver.cpp:338] Iteration 0, Testing net (#0)
I0309 02:54:12.827632  1118 solver.cpp:406]     Test net output #0: accuracy = 0.042
I0309 02:54:12.827795  1118 solver.cpp:406]     Test net output #1: loss = 3.35317 (* 1 = 3.35317 loss)
I0309 02:54:13.456871  1118 solver.cpp:229] Iteration 0, loss = 3.81517
I0309 02:54:13.456965  1118 solver.cpp:245]     Train net output #0: loss = 3.81517 (* 1 = 3.81517 loss)
I0309 02:54:13.457033  1118 sgd_solver.cpp:106] Iteration 0, lr = 0.0001
I0309 02:54:53.088212  1118 solver.cpp:229] Iteration 50, loss = 0.557249
I0309 02:54:53.088462  1118 solver.cpp:245]     Train net output #0: loss = 0.557249 (* 1 = 0.557249 loss)
I0309 02:54:53.088497  1118 sgd_solver.cpp:106] Iteration 50, lr = 0.0001
I0309 02:55:32.746129  1118 solver.cpp:229] Iteration 100, loss = 0.363571
I0309 02:55:32.746476  1118 solver.cpp:245]     Train net output #0: loss = 0.363571 (* 1 = 0.363571 loss)
I0309 02:55:32.746520  1118 sgd_solver.cpp:106] Iteration 100, lr = 0.0001
I0309 02:56:12.395597  1118 solver.cpp:229] Iteration 150, loss = 0.36427
I0309 02:56:12.395923  1118 solver.cpp:245]     Train net output #0: loss = 0.36427 (* 1 = 0.36427 loss)
I0309 02:56:12.395961  1118 sgd_solver.cpp:106] Iteration 150, lr = 0.0001
I0309 02:56:52.039716  1118 solver.cpp:229] Iteration 200, loss = 0.302199
I0309 02:56:52.041322  1118 solver.cpp:245]     Train net output #0: loss = 0.302199 (* 1 = 0.302199 loss)
I0309 02:56:52.041373  1118 sgd_solver.cpp:106] Iteration 200, lr = 0.0001
I0309 02:57:31.687182  1118 solver.cpp:229] Iteration 250, loss = 0.274866
I0309 02:57:31.689702  1118 solver.cpp:245]     Train net output #0: loss = 0.274866 (* 1 = 0.274866 loss)
I0309 02:57:31.689739  1118 sgd_solver.cpp:106] Iteration 250, lr = 0.0001
I0309 02:58:10.533826  1118 solver.cpp:338] Iteration 300, Testing net (#0)
I0309 02:58:11.867436  1118 solver.cpp:406]     Test net output #0: accuracy = 0.938
I0309 02:58:11.867591  1118 solver.cpp:406]     Test net output #1: loss = 0.196079 (* 1 = 0.196079 loss)
I0309 02:58:12.479682  1118 solver.cpp:229] Iteration 300, loss = 0.202563
I0309 02:58:12.479831  1118 solver.cpp:245]     Train net output #0: loss = 0.202563 (* 1 = 0.202563 loss)
I0309 02:58:12.479862  1118 sgd_solver.cpp:106] Iteration 300, lr = 0.0001
I0309 02:58:52.117041  1118 solver.cpp:229] Iteration 350, loss = 0.366434
I0309 02:58:52.118443  1118 solver.cpp:245]     Train net output #0: loss = 0.366434 (* 1 = 0.366434 loss)
I0309 02:58:52.118491  1118 sgd_solver.cpp:106] Iteration 350, lr = 0.0001
I0309 02:59:31.749366  1118 solver.cpp:229] Iteration 400, loss = 0.275247
I0309 02:59:31.749723  1118 solver.cpp:245]     Train net output #0: loss = 0.275247 (* 1 = 0.275247 loss)
I0309 02:59:31.749760  1118 sgd_solver.cpp:106] Iteration 400, lr = 0.0001
I0309 03:00:11.384838  1118 solver.cpp:229] Iteration 450, loss = 0.326295
I0309 03:00:11.385203  1118 solver.cpp:245]     Train net output #0: loss = 0.326295 (* 1 = 0.326295 loss)
I0309 03:00:11.385241  1118 sgd_solver.cpp:106] Iteration 450, lr = 0.0001
I0309 03:00:50.229708  1118 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_500.caffemodel
I0309 03:00:51.953433  1118 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_500.solverstate
I0309 03:00:53.489581  1118 solver.cpp:229] Iteration 500, loss = 0.183471
I0309 03:00:53.489745  1118 solver.cpp:245]     Train net output #0: loss = 0.183471 (* 1 = 0.183471 loss)
I0309 03:00:53.489776  1118 sgd_solver.cpp:106] Iteration 500, lr = 0.0001
I0309 03:01:33.129601  1118 solver.cpp:229] Iteration 550, loss = 0.227178
I0309 03:01:33.129950  1118 solver.cpp:245]     Train net output #0: loss = 0.227178 (* 1 = 0.227178 loss)
I0309 03:01:33.129986  1118 sgd_solver.cpp:106] Iteration 550, lr = 0.0001
I0309 03:02:11.982846  1118 solver.cpp:338] Iteration 600, Testing net (#0)
I0309 03:02:13.315181  1118 solver.cpp:406]     Test net output #0: accuracy = 0.95
I0309 03:02:13.315238  1118 solver.cpp:406]     Test net output #1: loss = 0.169691 (* 1 = 0.169691 loss)
I0309 03:02:13.927703  1118 solver.cpp:229] Iteration 600, loss = 0.211882
I0309 03:02:13.927748  1118 solver.cpp:245]     Train net output #0: loss = 0.211882 (* 1 = 0.211882 loss)
I0309 03:02:13.927774  1118 sgd_solver.cpp:106] Iteration 600, lr = 0.0001
I0309 03:02:53.556416  1118 solver.cpp:229] Iteration 650, loss = 0.307147
I0309 03:02:53.556716  1118 solver.cpp:245]     Train net output #0: loss = 0.307147 (* 1 = 0.307147 loss)
I0309 03:02:53.556749  1118 sgd_solver.cpp:106] Iteration 650, lr = 0.0001
I0309 03:03:33.184785  1118 solver.cpp:229] Iteration 700, loss = 0.320092
I0309 03:03:33.186116  1118 solver.cpp:245]     Train net output #0: loss = 0.320092 (* 1 = 0.320092 loss)
I0309 03:03:33.186158  1118 sgd_solver.cpp:106] Iteration 700, lr = 0.0001
I0309 03:04:12.830348  1118 solver.cpp:229] Iteration 750, loss = 0.244399
I0309 03:04:12.830623  1118 solver.cpp:245]     Train net output #0: loss = 0.244399 (* 1 = 0.244399 loss)
I0309 03:04:12.830657  1118 sgd_solver.cpp:106] Iteration 750, lr = 0.0001
I0309 03:04:52.471034  1118 solver.cpp:229] Iteration 800, loss = 0.233805
I0309 03:04:52.471319  1118 solver.cpp:245]     Train net output #0: loss = 0.233805 (* 1 = 0.233805 loss)
I0309 03:04:52.471352  1118 sgd_solver.cpp:106] Iteration 800, lr = 0.0001
I0309 03:05:32.109555  1118 solver.cpp:229] Iteration 850, loss = 0.206111
I0309 03:05:32.109765  1118 solver.cpp:245]     Train net output #0: loss = 0.206111 (* 1 = 0.206111 loss)
I0309 03:05:32.109812  1118 sgd_solver.cpp:106] Iteration 850, lr = 0.0001
I0309 03:06:10.963430  1118 solver.cpp:338] Iteration 900, Testing net (#0)
I0309 03:06:12.296701  1118 solver.cpp:406]     Test net output #0: accuracy = 0.952
I0309 03:06:12.296746  1118 solver.cpp:406]     Test net output #1: loss = 0.161855 (* 1 = 0.161855 loss)
I0309 03:06:12.908797  1118 solver.cpp:229] Iteration 900, loss = 0.274184
I0309 03:06:12.908841  1118 solver.cpp:245]     Train net output #0: loss = 0.274184 (* 1 = 0.274184 loss)
I0309 03:06:12.908867  1118 sgd_solver.cpp:106] Iteration 900, lr = 0.0001
I0309 03:06:52.549971  1118 solver.cpp:229] Iteration 950, loss = 0.160125
I0309 03:06:52.550165  1118 solver.cpp:245]     Train net output #0: loss = 0.160125 (* 1 = 0.160125 loss)
I0309 03:06:52.550199  1118 sgd_solver.cpp:106] Iteration 950, lr = 0.0001
I0309 03:07:31.390555  1118 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_1000.caffemodel
I0309 03:07:33.037411  1118 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_1000.solverstate
I0309 03:07:34.586473  1118 solver.cpp:229] Iteration 1000, loss = 0.253008
I0309 03:07:34.586555  1118 solver.cpp:245]     Train net output #0: loss = 0.253008 (* 1 = 0.253008 loss)
I0309 03:07:34.586591  1118 sgd_solver.cpp:106] Iteration 1000, lr = 0.0001
I0309 03:08:14.222302  1118 solver.cpp:229] Iteration 1050, loss = 0.290058
I0309 03:08:14.222518  1118 solver.cpp:245]     Train net output #0: loss = 0.290058 (* 1 = 0.290058 loss)
I0309 03:08:14.222551  1118 sgd_solver.cpp:106] Iteration 1050, lr = 0.0001
I0309 03:08:53.867229  1118 solver.cpp:229] Iteration 1100, loss = 0.208456
I0309 03:08:53.867441  1118 solver.cpp:245]     Train net output #0: loss = 0.208456 (* 1 = 0.208456 loss)
I0309 03:08:53.867475  1118 sgd_solver.cpp:106] Iteration 1100, lr = 0.0001
I0309 03:09:33.505120  1118 solver.cpp:229] Iteration 1150, loss = 0.220165
I0309 03:09:33.505321  1118 solver.cpp:245]     Train net output #0: loss = 0.220165 (* 1 = 0.220165 loss)
I0309 03:09:33.505355  1118 sgd_solver.cpp:106] Iteration 1150, lr = 0.0001
I0309 03:10:12.355545  1118 solver.cpp:338] Iteration 1200, Testing net (#0)
I0309 03:10:13.688266  1118 solver.cpp:406]     Test net output #0: accuracy = 0.95
I0309 03:10:13.688313  1118 solver.cpp:406]     Test net output #1: loss = 0.148478 (* 1 = 0.148478 loss)
I0309 03:10:14.300957  1118 solver.cpp:229] Iteration 1200, loss = 0.152376
I0309 03:10:14.301002  1118 solver.cpp:245]     Train net output #0: loss = 0.152376 (* 1 = 0.152376 loss)
I0309 03:10:14.301028  1118 sgd_solver.cpp:106] Iteration 1200, lr = 0.0001
I0309 03:10:53.950500  1118 solver.cpp:229] Iteration 1250, loss = 0.276796
I0309 03:10:53.950805  1118 solver.cpp:245]     Train net output #0: loss = 0.276796 (* 1 = 0.276796 loss)
I0309 03:10:53.950839  1118 sgd_solver.cpp:106] Iteration 1250, lr = 0.0001
I0309 03:11:33.597878  1118 solver.cpp:229] Iteration 1300, loss = 0.135949
I0309 03:11:33.598075  1118 solver.cpp:245]     Train net output #0: loss = 0.135949 (* 1 = 0.135949 loss)
I0309 03:11:33.598109  1118 sgd_solver.cpp:106] Iteration 1300, lr = 0.0001
I0309 03:12:13.246992  1118 solver.cpp:229] Iteration 1350, loss = 0.176716
I0309 03:12:13.247205  1118 solver.cpp:245]     Train net output #0: loss = 0.176716 (* 1 = 0.176716 loss)
I0309 03:12:13.247237  1118 sgd_solver.cpp:106] Iteration 1350, lr = 0.0001
I0309 03:12:52.885007  1118 solver.cpp:229] Iteration 1400, loss = 0.144283
I0309 03:12:52.885216  1118 solver.cpp:245]     Train net output #0: loss = 0.144283 (* 1 = 0.144283 loss)
I0309 03:12:52.885249  1118 sgd_solver.cpp:106] Iteration 1400, lr = 0.0001
I0309 03:13:32.530279  1118 solver.cpp:229] Iteration 1450, loss = 0.210739
I0309 03:13:32.530508  1118 solver.cpp:245]     Train net output #0: loss = 0.210739 (* 1 = 0.210739 loss)
I0309 03:13:32.530541  1118 sgd_solver.cpp:106] Iteration 1450, lr = 0.0001
I0309 03:14:11.384281  1118 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_1500.caffemodel
I0309 03:14:13.043884  1118 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_1500.solverstate
I0309 03:14:13.992710  1118 solver.cpp:338] Iteration 1500, Testing net (#0)
I0309 03:14:15.152431  1118 solver.cpp:406]     Test net output #0: accuracy = 0.954
I0309 03:14:15.152487  1118 solver.cpp:406]     Test net output #1: loss = 0.146454 (* 1 = 0.146454 loss)
I0309 03:14:15.765246  1118 solver.cpp:229] Iteration 1500, loss = 0.268147
I0309 03:14:15.765290  1118 solver.cpp:245]     Train net output #0: loss = 0.268147 (* 1 = 0.268147 loss)
I0309 03:14:15.765321  1118 sgd_solver.cpp:106] Iteration 1500, lr = 0.0001
I0309 03:14:55.412256  1118 solver.cpp:229] Iteration 1550, loss = 0.187761
I0309 03:14:55.412475  1118 solver.cpp:245]     Train net output #0: loss = 0.187761 (* 1 = 0.187761 loss)
I0309 03:14:55.412508  1118 sgd_solver.cpp:106] Iteration 1550, lr = 0.0001
I0309 03:15:35.065839  1118 solver.cpp:229] Iteration 1600, loss = 0.192254
I0309 03:15:35.066143  1118 solver.cpp:245]     Train net output #0: loss = 0.192254 (* 1 = 0.192254 loss)
I0309 03:15:35.066177  1118 sgd_solver.cpp:106] Iteration 1600, lr = 0.0001
I0309 03:16:14.704934  1118 solver.cpp:229] Iteration 1650, loss = 0.139849
I0309 03:16:14.705142  1118 solver.cpp:245]     Train net output #0: loss = 0.139849 (* 1 = 0.139849 loss)
I0309 03:16:14.705176  1118 sgd_solver.cpp:106] Iteration 1650, lr = 0.0001
I0309 03:16:54.341336  1118 solver.cpp:229] Iteration 1700, loss = 0.0577597
I0309 03:16:54.341545  1118 solver.cpp:245]     Train net output #0: loss = 0.0577597 (* 1 = 0.0577597 loss)
I0309 03:16:54.341584  1118 sgd_solver.cpp:106] Iteration 1700, lr = 0.0001
I0309 03:17:33.996122  1118 solver.cpp:229] Iteration 1750, loss = 0.197819
I0309 03:17:33.996412  1118 solver.cpp:245]     Train net output #0: loss = 0.197819 (* 1 = 0.197819 loss)
I0309 03:17:33.996444  1118 sgd_solver.cpp:106] Iteration 1750, lr = 0.0001
I0309 03:18:12.858958  1118 solver.cpp:338] Iteration 1800, Testing net (#0)
I0309 03:18:14.191588  1118 solver.cpp:406]     Test net output #0: accuracy = 0.96
I0309 03:18:14.191644  1118 solver.cpp:406]     Test net output #1: loss = 0.139408 (* 1 = 0.139408 loss)
I0309 03:18:14.804333  1118 solver.cpp:229] Iteration 1800, loss = 0.125225
I0309 03:18:14.804482  1118 solver.cpp:245]     Train net output #0: loss = 0.125225 (* 1 = 0.125225 loss)
I0309 03:18:14.804512  1118 sgd_solver.cpp:106] Iteration 1800, lr = 0.0001
I0309 03:18:54.454136  1118 solver.cpp:229] Iteration 1850, loss = 0.215394
I0309 03:18:54.454479  1118 solver.cpp:245]     Train net output #0: loss = 0.215394 (* 1 = 0.215394 loss)
I0309 03:18:54.454515  1118 sgd_solver.cpp:106] Iteration 1850, lr = 0.0001
I0309 03:19:34.098132  1118 solver.cpp:229] Iteration 1900, loss = 0.138
I0309 03:19:34.098484  1118 solver.cpp:245]     Train net output #0: loss = 0.138 (* 1 = 0.138 loss)
I0309 03:19:34.098520  1118 sgd_solver.cpp:106] Iteration 1900, lr = 0.0001
I0309 03:20:13.743113  1118 solver.cpp:229] Iteration 1950, loss = 0.082467
I0309 03:20:13.743489  1118 solver.cpp:245]     Train net output #0: loss = 0.082467 (* 1 = 0.082467 loss)
I0309 03:20:13.743525  1118 sgd_solver.cpp:106] Iteration 1950, lr = 0.0001
I0309 03:20:52.606997  1118 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_2000.caffemodel
I0309 03:20:54.249230  1118 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_2000.solverstate
I0309 03:20:55.791465  1118 solver.cpp:229] Iteration 2000, loss = 0.0873293
I0309 03:20:55.791631  1118 solver.cpp:245]     Train net output #0: loss = 0.0873293 (* 1 = 0.0873293 loss)
I0309 03:20:55.791663  1118 sgd_solver.cpp:106] Iteration 2000, lr = 0.0001
I0309 03:21:35.436219  1118 solver.cpp:229] Iteration 2050, loss = 0.151407
I0309 03:21:35.436605  1118 solver.cpp:245]     Train net output #0: loss = 0.151407 (* 1 = 0.151407 loss)
I0309 03:21:35.436642  1118 sgd_solver.cpp:106] Iteration 2050, lr = 0.0001
I0309 03:22:14.296216  1118 solver.cpp:338] Iteration 2100, Testing net (#0)
I0309 03:22:15.628830  1118 solver.cpp:406]     Test net output #0: accuracy = 0.952
I0309 03:22:15.628886  1118 solver.cpp:406]     Test net output #1: loss = 0.139901 (* 1 = 0.139901 loss)
I0309 03:22:16.241992  1118 solver.cpp:229] Iteration 2100, loss = 0.134066
I0309 03:22:16.242139  1118 solver.cpp:245]     Train net output #0: loss = 0.134066 (* 1 = 0.134066 loss)
I0309 03:22:16.242171  1118 sgd_solver.cpp:106] Iteration 2100, lr = 0.0001
I0309 03:22:55.894210  1118 solver.cpp:229] Iteration 2150, loss = 0.232624
I0309 03:22:55.894557  1118 solver.cpp:245]     Train net output #0: loss = 0.232624 (* 1 = 0.232624 loss)
I0309 03:22:55.894599  1118 sgd_solver.cpp:106] Iteration 2150, lr = 0.0001
I0309 03:23:35.529671  1118 solver.cpp:229] Iteration 2200, loss = 0.128369
I0309 03:23:35.529973  1118 solver.cpp:245]     Train net output #0: loss = 0.128369 (* 1 = 0.128369 loss)
I0309 03:23:35.530006  1118 sgd_solver.cpp:106] Iteration 2200, lr = 0.0001
I0309 03:24:15.173408  1118 solver.cpp:229] Iteration 2250, loss = 0.164476
I0309 03:24:15.173727  1118 solver.cpp:245]     Train net output #0: loss = 0.164476 (* 1 = 0.164476 loss)
I0309 03:24:15.173761  1118 sgd_solver.cpp:106] Iteration 2250, lr = 0.0001
I0309 03:24:54.837728  1118 solver.cpp:229] Iteration 2300, loss = 0.102657
I0309 03:24:54.838045  1118 solver.cpp:245]     Train net output #0: loss = 0.102657 (* 1 = 0.102657 loss)
I0309 03:24:54.838078  1118 sgd_solver.cpp:106] Iteration 2300, lr = 0.0001
I0309 03:25:34.486069  1118 solver.cpp:229] Iteration 2350, loss = 0.101959
I0309 03:25:34.486311  1118 solver.cpp:245]     Train net output #0: loss = 0.101959 (* 1 = 0.101959 loss)
I0309 03:25:34.486345  1118 sgd_solver.cpp:106] Iteration 2350, lr = 0.0001
I0309 03:26:13.333472  1118 solver.cpp:338] Iteration 2400, Testing net (#0)
I0309 03:26:14.667234  1118 solver.cpp:406]     Test net output #0: accuracy = 0.966
I0309 03:26:14.667279  1118 solver.cpp:406]     Test net output #1: loss = 0.143912 (* 1 = 0.143912 loss)
I0309 03:26:15.279176  1118 solver.cpp:229] Iteration 2400, loss = 0.134693
I0309 03:26:15.279219  1118 solver.cpp:245]     Train net output #0: loss = 0.134693 (* 1 = 0.134693 loss)
I0309 03:26:15.279245  1118 sgd_solver.cpp:106] Iteration 2400, lr = 0.0001
I0309 03:26:54.907038  1118 solver.cpp:229] Iteration 2450, loss = 0.139098
I0309 03:26:54.907251  1118 solver.cpp:245]     Train net output #0: loss = 0.139098 (* 1 = 0.139098 loss)
I0309 03:26:54.907284  1118 sgd_solver.cpp:106] Iteration 2450, lr = 0.0001
I0309 03:27:33.757380  1118 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_2500.caffemodel
I0309 03:27:35.397662  1118 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_2500.solverstate
I0309 03:27:36.938021  1118 solver.cpp:229] Iteration 2500, loss = 0.113776
I0309 03:27:36.938108  1118 solver.cpp:245]     Train net output #0: loss = 0.113776 (* 1 = 0.113776 loss)
I0309 03:27:36.938143  1118 sgd_solver.cpp:106] Iteration 2500, lr = 0.0001
I0309 03:28:16.575031  1118 solver.cpp:229] Iteration 2550, loss = 0.139325
I0309 03:28:16.575270  1118 solver.cpp:245]     Train net output #0: loss = 0.139325 (* 1 = 0.139325 loss)
I0309 03:28:16.575304  1118 sgd_solver.cpp:106] Iteration 2550, lr = 0.0001
I0309 03:28:56.206310  1118 solver.cpp:229] Iteration 2600, loss = 0.154028
I0309 03:28:56.206519  1118 solver.cpp:245]     Train net output #0: loss = 0.154028 (* 1 = 0.154028 loss)
I0309 03:28:56.206552  1118 sgd_solver.cpp:106] Iteration 2600, lr = 0.0001
I0309 03:29:35.838531  1118 solver.cpp:229] Iteration 2650, loss = 0.110314
I0309 03:29:35.838757  1118 solver.cpp:245]     Train net output #0: loss = 0.110314 (* 1 = 0.110314 loss)
I0309 03:29:35.838789  1118 sgd_solver.cpp:106] Iteration 2650, lr = 0.0001
I0309 03:30:14.695909  1118 solver.cpp:338] Iteration 2700, Testing net (#0)
I0309 03:30:16.027709  1118 solver.cpp:406]     Test net output #0: accuracy = 0.958
I0309 03:30:16.027757  1118 solver.cpp:406]     Test net output #1: loss = 0.130527 (* 1 = 0.130527 loss)
I0309 03:30:16.639230  1118 solver.cpp:229] Iteration 2700, loss = 0.132814
I0309 03:30:16.639274  1118 solver.cpp:245]     Train net output #0: loss = 0.132814 (* 1 = 0.132814 loss)
I0309 03:30:16.639300  1118 sgd_solver.cpp:106] Iteration 2700, lr = 0.0001
I0309 03:30:56.273568  1118 solver.cpp:229] Iteration 2750, loss = 0.169151
I0309 03:30:56.273772  1118 solver.cpp:245]     Train net output #0: loss = 0.169151 (* 1 = 0.169151 loss)
I0309 03:30:56.273805  1118 sgd_solver.cpp:106] Iteration 2750, lr = 0.0001
I0309 03:31:35.903267  1118 solver.cpp:229] Iteration 2800, loss = 0.265559
I0309 03:31:35.903468  1118 solver.cpp:245]     Train net output #0: loss = 0.265559 (* 1 = 0.265559 loss)
I0309 03:31:35.903501  1118 sgd_solver.cpp:106] Iteration 2800, lr = 0.0001
I0309 03:32:15.546377  1118 solver.cpp:229] Iteration 2850, loss = 0.0961977
I0309 03:32:15.546581  1118 solver.cpp:245]     Train net output #0: loss = 0.0961976 (* 1 = 0.0961976 loss)
I0309 03:32:15.546613  1118 sgd_solver.cpp:106] Iteration 2850, lr = 0.0001
I0309 03:32:55.190322  1118 solver.cpp:229] Iteration 2900, loss = 0.114945
I0309 03:32:55.190533  1118 solver.cpp:245]     Train net output #0: loss = 0.114945 (* 1 = 0.114945 loss)
I0309 03:32:55.190572  1118 sgd_solver.cpp:106] Iteration 2900, lr = 0.0001
I0309 03:33:34.825623  1118 solver.cpp:229] Iteration 2950, loss = 0.181278
I0309 03:33:34.825830  1118 solver.cpp:245]     Train net output #0: loss = 0.181278 (* 1 = 0.181278 loss)
I0309 03:33:34.825863  1118 sgd_solver.cpp:106] Iteration 2950, lr = 0.0001
I0309 03:34:13.679743  1118 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_3000.caffemodel
I0309 03:34:15.330014  1118 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_3000.solverstate
I0309 03:34:16.251567  1118 solver.cpp:338] Iteration 3000, Testing net (#0)
I0309 03:34:17.410768  1118 solver.cpp:406]     Test net output #0: accuracy = 0.954
I0309 03:34:17.410825  1118 solver.cpp:406]     Test net output #1: loss = 0.139003 (* 1 = 0.139003 loss)
I0309 03:34:18.023362  1118 solver.cpp:229] Iteration 3000, loss = 0.0748627
I0309 03:34:18.023519  1118 solver.cpp:245]     Train net output #0: loss = 0.0748627 (* 1 = 0.0748627 loss)
I0309 03:34:18.023550  1118 sgd_solver.cpp:106] Iteration 3000, lr = 0.0001
I0309 03:34:57.672830  1118 solver.cpp:229] Iteration 3050, loss = 0.118154
I0309 03:34:57.673185  1118 solver.cpp:245]     Train net output #0: loss = 0.118154 (* 1 = 0.118154 loss)
I0309 03:34:57.673221  1118 sgd_solver.cpp:106] Iteration 3050, lr = 0.0001
I0309 03:35:37.314738  1118 solver.cpp:229] Iteration 3100, loss = 0.157684
I0309 03:35:37.315090  1118 solver.cpp:245]     Train net output #0: loss = 0.157684 (* 1 = 0.157684 loss)
I0309 03:35:37.315126  1118 sgd_solver.cpp:106] Iteration 3100, lr = 0.0001
I0309 03:36:16.953157  1118 solver.cpp:229] Iteration 3150, loss = 0.123
I0309 03:36:16.953483  1118 solver.cpp:245]     Train net output #0: loss = 0.123 (* 1 = 0.123 loss)
I0309 03:36:16.953516  1118 sgd_solver.cpp:106] Iteration 3150, lr = 0.0001
I0309 03:36:56.589932  1118 solver.cpp:229] Iteration 3200, loss = 0.137368
I0309 03:36:56.590231  1118 solver.cpp:245]     Train net output #0: loss = 0.137368 (* 1 = 0.137368 loss)
I0309 03:36:56.590265  1118 sgd_solver.cpp:106] Iteration 3200, lr = 0.0001
I0309 03:37:36.232628  1118 solver.cpp:229] Iteration 3250, loss = 0.198563
I0309 03:37:36.232846  1118 solver.cpp:245]     Train net output #0: loss = 0.198563 (* 1 = 0.198563 loss)
I0309 03:37:36.232892  1118 sgd_solver.cpp:106] Iteration 3250, lr = 0.0001
I0309 03:38:15.086895  1118 solver.cpp:338] Iteration 3300, Testing net (#0)
I0309 03:38:16.420239  1118 solver.cpp:406]     Test net output #0: accuracy = 0.964
I0309 03:38:16.420284  1118 solver.cpp:406]     Test net output #1: loss = 0.130152 (* 1 = 0.130152 loss)
I0309 03:38:17.032532  1118 solver.cpp:229] Iteration 3300, loss = 0.187485
I0309 03:38:17.032579  1118 solver.cpp:245]     Train net output #0: loss = 0.187485 (* 1 = 0.187485 loss)
I0309 03:38:17.032606  1118 sgd_solver.cpp:106] Iteration 3300, lr = 0.0001
I0309 03:38:56.662992  1118 solver.cpp:229] Iteration 3350, loss = 0.124122
I0309 03:38:56.663193  1118 solver.cpp:245]     Train net output #0: loss = 0.124122 (* 1 = 0.124122 loss)
I0309 03:38:56.663226  1118 sgd_solver.cpp:106] Iteration 3350, lr = 0.0001
I0309 03:39:36.292424  1118 solver.cpp:229] Iteration 3400, loss = 0.238265
I0309 03:39:36.292632  1118 solver.cpp:245]     Train net output #0: loss = 0.238265 (* 1 = 0.238265 loss)
I0309 03:39:36.292665  1118 sgd_solver.cpp:106] Iteration 3400, lr = 0.0001
I0309 03:40:15.934958  1118 solver.cpp:229] Iteration 3450, loss = 0.150161
I0309 03:40:15.935184  1118 solver.cpp:245]     Train net output #0: loss = 0.150161 (* 1 = 0.150161 loss)
I0309 03:40:15.935219  1118 sgd_solver.cpp:106] Iteration 3450, lr = 0.0001
I0309 03:40:54.792536  1118 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_3500.caffemodel
I0309 03:40:56.435456  1118 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_3500.solverstate
I0309 03:40:57.982348  1118 solver.cpp:229] Iteration 3500, loss = 0.117197
I0309 03:40:57.982432  1118 solver.cpp:245]     Train net output #0: loss = 0.117197 (* 1 = 0.117197 loss)
I0309 03:40:57.982462  1118 sgd_solver.cpp:106] Iteration 3500, lr = 0.0001
I0309 03:41:37.620200  1118 solver.cpp:229] Iteration 3550, loss = 0.0652554
I0309 03:41:37.620426  1118 solver.cpp:245]     Train net output #0: loss = 0.0652553 (* 1 = 0.0652553 loss)
I0309 03:41:37.620460  1118 sgd_solver.cpp:106] Iteration 3550, lr = 0.0001
I0309 03:42:16.467428  1118 solver.cpp:338] Iteration 3600, Testing net (#0)
I0309 03:42:17.799741  1118 solver.cpp:406]     Test net output #0: accuracy = 0.954
I0309 03:42:17.799787  1118 solver.cpp:406]     Test net output #1: loss = 0.128738 (* 1 = 0.128738 loss)
I0309 03:42:18.412519  1118 solver.cpp:229] Iteration 3600, loss = 0.180861
I0309 03:42:18.412564  1118 solver.cpp:245]     Train net output #0: loss = 0.180861 (* 1 = 0.180861 loss)
I0309 03:42:18.412590  1118 sgd_solver.cpp:106] Iteration 3600, lr = 0.0001
I0309 03:42:58.050045  1118 solver.cpp:229] Iteration 3650, loss = 0.186376
I0309 03:42:58.050252  1118 solver.cpp:245]     Train net output #0: loss = 0.186376 (* 1 = 0.186376 loss)
I0309 03:42:58.050285  1118 sgd_solver.cpp:106] Iteration 3650, lr = 0.0001
I0309 03:43:37.691507  1118 solver.cpp:229] Iteration 3700, loss = 0.108236
I0309 03:43:37.691807  1118 solver.cpp:245]     Train net output #0: loss = 0.108236 (* 1 = 0.108236 loss)
I0309 03:43:37.691840  1118 sgd_solver.cpp:106] Iteration 3700, lr = 0.0001
I0309 03:44:17.332211  1118 solver.cpp:229] Iteration 3750, loss = 0.108889
I0309 03:44:17.332422  1118 solver.cpp:245]     Train net output #0: loss = 0.108889 (* 1 = 0.108889 loss)
I0309 03:44:17.332455  1118 sgd_solver.cpp:106] Iteration 3750, lr = 0.0001
I0309 03:44:56.975425  1118 solver.cpp:229] Iteration 3800, loss = 0.10848
I0309 03:44:56.975630  1118 solver.cpp:245]     Train net output #0: loss = 0.10848 (* 1 = 0.10848 loss)
I0309 03:44:56.975662  1118 sgd_solver.cpp:106] Iteration 3800, lr = 0.0001
I0309 03:45:36.621076  1118 solver.cpp:229] Iteration 3850, loss = 0.0949726
I0309 03:45:36.621414  1118 solver.cpp:245]     Train net output #0: loss = 0.0949726 (* 1 = 0.0949726 loss)
I0309 03:45:36.621448  1118 sgd_solver.cpp:106] Iteration 3850, lr = 0.0001
I0309 03:46:15.475460  1118 solver.cpp:338] Iteration 3900, Testing net (#0)
I0309 03:46:16.808827  1118 solver.cpp:406]     Test net output #0: accuracy = 0.962
I0309 03:46:16.808873  1118 solver.cpp:406]     Test net output #1: loss = 0.126818 (* 1 = 0.126818 loss)
I0309 03:46:17.420394  1118 solver.cpp:229] Iteration 3900, loss = 0.13522
I0309 03:46:17.420439  1118 solver.cpp:245]     Train net output #0: loss = 0.13522 (* 1 = 0.13522 loss)
I0309 03:46:17.420464  1118 sgd_solver.cpp:106] Iteration 3900, lr = 0.0001
I0309 03:46:57.070201  1118 solver.cpp:229] Iteration 3950, loss = 0.141678
I0309 03:46:57.070400  1118 solver.cpp:245]     Train net output #0: loss = 0.141678 (* 1 = 0.141678 loss)
I0309 03:46:57.070435  1118 sgd_solver.cpp:106] Iteration 3950, lr = 0.0001
I0309 03:47:35.927646  1118 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_4000.caffemodel
I0309 03:47:37.574411  1118 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_4000.solverstate
I0309 03:47:39.117460  1118 solver.cpp:229] Iteration 4000, loss = 0.12485
I0309 03:47:39.117547  1118 solver.cpp:245]     Train net output #0: loss = 0.12485 (* 1 = 0.12485 loss)
I0309 03:47:39.117578  1118 sgd_solver.cpp:106] Iteration 4000, lr = 0.0001
I0309 03:48:18.760246  1118 solver.cpp:229] Iteration 4050, loss = 0.139885
I0309 03:48:18.760478  1118 solver.cpp:245]     Train net output #0: loss = 0.139885 (* 1 = 0.139885 loss)
I0309 03:48:18.760509  1118 sgd_solver.cpp:106] Iteration 4050, lr = 0.0001
I0309 03:48:58.402958  1118 solver.cpp:229] Iteration 4100, loss = 0.136143
I0309 03:48:58.403167  1118 solver.cpp:245]     Train net output #0: loss = 0.136143 (* 1 = 0.136143 loss)
I0309 03:48:58.403200  1118 sgd_solver.cpp:106] Iteration 4100, lr = 0.0001
I0309 03:49:38.046630  1118 solver.cpp:229] Iteration 4150, loss = 0.0760476
I0309 03:49:38.046831  1118 solver.cpp:245]     Train net output #0: loss = 0.0760476 (* 1 = 0.0760476 loss)
I0309 03:49:38.046864  1118 sgd_solver.cpp:106] Iteration 4150, lr = 0.0001
I0309 03:50:16.902642  1118 solver.cpp:338] Iteration 4200, Testing net (#0)
I0309 03:50:18.236886  1118 solver.cpp:406]     Test net output #0: accuracy = 0.956
I0309 03:50:18.236930  1118 solver.cpp:406]     Test net output #1: loss = 0.133389 (* 1 = 0.133389 loss)
I0309 03:50:18.848600  1118 solver.cpp:229] Iteration 4200, loss = 0.0987754
I0309 03:50:18.848645  1118 solver.cpp:245]     Train net output #0: loss = 0.0987754 (* 1 = 0.0987754 loss)
I0309 03:50:18.848671  1118 sgd_solver.cpp:106] Iteration 4200, lr = 0.0001
I0309 03:50:58.492081  1118 solver.cpp:229] Iteration 4250, loss = 0.144278
I0309 03:50:58.492290  1118 solver.cpp:245]     Train net output #0: loss = 0.144278 (* 1 = 0.144278 loss)
I0309 03:50:58.492322  1118 sgd_solver.cpp:106] Iteration 4250, lr = 0.0001
I0309 03:51:38.138916  1118 solver.cpp:229] Iteration 4300, loss = 0.1068
I0309 03:51:38.139119  1118 solver.cpp:245]     Train net output #0: loss = 0.1068 (* 1 = 0.1068 loss)
I0309 03:51:38.139153  1118 sgd_solver.cpp:106] Iteration 4300, lr = 0.0001
I0309 03:52:17.781607  1118 solver.cpp:229] Iteration 4350, loss = 0.107773
I0309 03:52:17.781811  1118 solver.cpp:245]     Train net output #0: loss = 0.107773 (* 1 = 0.107773 loss)
I0309 03:52:17.781844  1118 sgd_solver.cpp:106] Iteration 4350, lr = 0.0001
I0309 03:52:57.431241  1118 solver.cpp:229] Iteration 4400, loss = 0.0769683
I0309 03:52:57.431454  1118 solver.cpp:245]     Train net output #0: loss = 0.0769683 (* 1 = 0.0769683 loss)
I0309 03:52:57.431488  1118 sgd_solver.cpp:106] Iteration 4400, lr = 0.0001
I0309 03:53:37.074568  1118 solver.cpp:229] Iteration 4450, loss = 0.054906
I0309 03:53:37.074771  1118 solver.cpp:245]     Train net output #0: loss = 0.054906 (* 1 = 0.054906 loss)
I0309 03:53:37.074805  1118 sgd_solver.cpp:106] Iteration 4450, lr = 0.0001
I0309 03:54:15.923975  1118 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_4500.caffemodel
I0309 03:54:17.571717  1118 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_4500.solverstate
I0309 03:54:18.499845  1118 solver.cpp:338] Iteration 4500, Testing net (#0)
I0309 03:54:19.658175  1118 solver.cpp:406]     Test net output #0: accuracy = 0.96
I0309 03:54:19.658232  1118 solver.cpp:406]     Test net output #1: loss = 0.125073 (* 1 = 0.125073 loss)
I0309 03:54:20.270416  1118 solver.cpp:229] Iteration 4500, loss = 0.0687367
I0309 03:54:20.270460  1118 solver.cpp:245]     Train net output #0: loss = 0.0687367 (* 1 = 0.0687367 loss)
I0309 03:54:20.270489  1118 sgd_solver.cpp:106] Iteration 4500, lr = 0.0001
I0309 03:54:59.911667  1118 solver.cpp:229] Iteration 4550, loss = 0.0516817
I0309 03:54:59.911890  1118 solver.cpp:245]     Train net output #0: loss = 0.0516817 (* 1 = 0.0516817 loss)
I0309 03:54:59.911924  1118 sgd_solver.cpp:106] Iteration 4550, lr = 0.0001
I0309 03:55:39.543164  1118 solver.cpp:229] Iteration 4600, loss = 0.0735334
I0309 03:55:39.543372  1118 solver.cpp:245]     Train net output #0: loss = 0.0735334 (* 1 = 0.0735334 loss)
I0309 03:55:39.543406  1118 sgd_solver.cpp:106] Iteration 4600, lr = 0.0001
I0309 03:56:19.183332  1118 solver.cpp:229] Iteration 4650, loss = 0.202084
I0309 03:56:19.183538  1118 solver.cpp:245]     Train net output #0: loss = 0.202084 (* 1 = 0.202084 loss)
I0309 03:56:19.183571  1118 sgd_solver.cpp:106] Iteration 4650, lr = 0.0001
I0309 03:56:58.828960  1118 solver.cpp:229] Iteration 4700, loss = 0.103616
I0309 03:56:58.829308  1118 solver.cpp:245]     Train net output #0: loss = 0.103616 (* 1 = 0.103616 loss)
I0309 03:56:58.829344  1118 sgd_solver.cpp:106] Iteration 4700, lr = 0.0001
I0309 03:57:38.470458  1118 solver.cpp:229] Iteration 4750, loss = 0.113323
I0309 03:57:38.470803  1118 solver.cpp:245]     Train net output #0: loss = 0.113323 (* 1 = 0.113323 loss)
I0309 03:57:38.470839  1118 sgd_solver.cpp:106] Iteration 4750, lr = 0.0001
I0309 03:58:17.333650  1118 solver.cpp:338] Iteration 4800, Testing net (#0)
I0309 03:58:18.667055  1118 solver.cpp:406]     Test net output #0: accuracy = 0.958
I0309 03:58:18.667111  1118 solver.cpp:406]     Test net output #1: loss = 0.121305 (* 1 = 0.121305 loss)
I0309 03:58:19.278998  1118 solver.cpp:229] Iteration 4800, loss = 0.197992
I0309 03:58:19.279155  1118 solver.cpp:245]     Train net output #0: loss = 0.197992 (* 1 = 0.197992 loss)
I0309 03:58:19.279186  1118 sgd_solver.cpp:106] Iteration 4800, lr = 0.0001
I0309 03:58:58.927404  1118 solver.cpp:229] Iteration 4850, loss = 0.0701834
I0309 03:58:58.927721  1118 solver.cpp:245]     Train net output #0: loss = 0.0701834 (* 1 = 0.0701834 loss)
I0309 03:58:58.927754  1118 sgd_solver.cpp:106] Iteration 4850, lr = 0.0001
I0309 03:59:38.570927  1118 solver.cpp:229] Iteration 4900, loss = 0.0766001
I0309 03:59:38.571128  1118 solver.cpp:245]     Train net output #0: loss = 0.0766001 (* 1 = 0.0766001 loss)
I0309 03:59:38.571161  1118 sgd_solver.cpp:106] Iteration 4900, lr = 0.0001
I0309 04:00:18.212065  1118 solver.cpp:229] Iteration 4950, loss = 0.13389
I0309 04:00:18.212371  1118 solver.cpp:245]     Train net output #0: loss = 0.13389 (* 1 = 0.13389 loss)
I0309 04:00:18.212405  1118 sgd_solver.cpp:106] Iteration 4950, lr = 0.0001
I0309 04:00:57.050047  1118 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_5000.caffemodel
I0309 04:00:58.688468  1118 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_5000.solverstate
I0309 04:01:00.223124  1118 solver.cpp:229] Iteration 5000, loss = 0.10976
I0309 04:01:00.223206  1118 solver.cpp:245]     Train net output #0: loss = 0.10976 (* 1 = 0.10976 loss)
I0309 04:01:00.223237  1118 sgd_solver.cpp:106] Iteration 5000, lr = 0.0001
I0309 04:01:39.862411  1118 solver.cpp:229] Iteration 5050, loss = 0.148145
I0309 04:01:39.862664  1118 solver.cpp:245]     Train net output #0: loss = 0.148145 (* 1 = 0.148145 loss)
I0309 04:01:39.862697  1118 sgd_solver.cpp:106] Iteration 5050, lr = 0.0001
I0309 04:02:18.717720  1118 solver.cpp:338] Iteration 5100, Testing net (#0)
I0309 04:02:20.051057  1118 solver.cpp:406]     Test net output #0: accuracy = 0.966
I0309 04:02:20.051103  1118 solver.cpp:406]     Test net output #1: loss = 0.125047 (* 1 = 0.125047 loss)
I0309 04:02:20.664069  1118 solver.cpp:229] Iteration 5100, loss = 0.121961
I0309 04:02:20.664114  1118 solver.cpp:245]     Train net output #0: loss = 0.121961 (* 1 = 0.121961 loss)
I0309 04:02:20.664140  1118 sgd_solver.cpp:106] Iteration 5100, lr = 0.0001
I0309 04:03:00.299319  1118 solver.cpp:229] Iteration 5150, loss = 0.0888091
I0309 04:03:00.299624  1118 solver.cpp:245]     Train net output #0: loss = 0.0888091 (* 1 = 0.0888091 loss)
I0309 04:03:00.299657  1118 sgd_solver.cpp:106] Iteration 5150, lr = 0.0001
I0309 04:03:39.944842  1118 solver.cpp:229] Iteration 5200, loss = 0.134588
I0309 04:03:39.945053  1118 solver.cpp:245]     Train net output #0: loss = 0.134588 (* 1 = 0.134588 loss)
I0309 04:03:39.945086  1118 sgd_solver.cpp:106] Iteration 5200, lr = 0.0001
I0309 04:04:19.585465  1118 solver.cpp:229] Iteration 5250, loss = 0.166958
I0309 04:04:19.585669  1118 solver.cpp:245]     Train net output #0: loss = 0.166958 (* 1 = 0.166958 loss)
I0309 04:04:19.585702  1118 sgd_solver.cpp:106] Iteration 5250, lr = 0.0001
I0309 04:04:59.226671  1118 solver.cpp:229] Iteration 5300, loss = 0.107926
I0309 04:04:59.226874  1118 solver.cpp:245]     Train net output #0: loss = 0.107926 (* 1 = 0.107926 loss)
I0309 04:04:59.226907  1118 sgd_solver.cpp:106] Iteration 5300, lr = 0.0001
I0309 04:05:38.860563  1118 solver.cpp:229] Iteration 5350, loss = 0.106152
I0309 04:05:38.860769  1118 solver.cpp:245]     Train net output #0: loss = 0.106152 (* 1 = 0.106152 loss)
I0309 04:05:38.860802  1118 sgd_solver.cpp:106] Iteration 5350, lr = 0.0001
I0309 04:06:17.717303  1118 solver.cpp:338] Iteration 5400, Testing net (#0)
I0309 04:06:19.049455  1118 solver.cpp:406]     Test net output #0: accuracy = 0.96
I0309 04:06:19.049500  1118 solver.cpp:406]     Test net output #1: loss = 0.13083 (* 1 = 0.13083 loss)
I0309 04:06:19.660956  1118 solver.cpp:229] Iteration 5400, loss = 0.0646484
I0309 04:06:19.661000  1118 solver.cpp:245]     Train net output #0: loss = 0.0646484 (* 1 = 0.0646484 loss)
I0309 04:06:19.661026  1118 sgd_solver.cpp:106] Iteration 5400, lr = 0.0001
I0309 04:06:59.290103  1118 solver.cpp:229] Iteration 5450, loss = 0.104769
I0309 04:06:59.290292  1118 solver.cpp:245]     Train net output #0: loss = 0.104769 (* 1 = 0.104769 loss)
I0309 04:06:59.290323  1118 sgd_solver.cpp:106] Iteration 5450, lr = 0.0001
I0309 04:07:38.140578  1118 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_5500.caffemodel
I0309 04:07:39.781921  1118 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_5500.solverstate
I0309 04:07:41.322777  1118 solver.cpp:229] Iteration 5500, loss = 0.141705
I0309 04:07:41.322860  1118 solver.cpp:245]     Train net output #0: loss = 0.141705 (* 1 = 0.141705 loss)
I0309 04:07:41.322891  1118 sgd_solver.cpp:106] Iteration 5500, lr = 0.0001
I0309 04:08:20.957651  1118 solver.cpp:229] Iteration 5550, loss = 0.0857272
I0309 04:08:20.957898  1118 solver.cpp:245]     Train net output #0: loss = 0.0857272 (* 1 = 0.0857272 loss)
I0309 04:08:20.957931  1118 sgd_solver.cpp:106] Iteration 5550, lr = 0.0001
I0309 04:09:00.597108  1118 solver.cpp:229] Iteration 5600, loss = 0.0964973
I0309 04:09:00.597304  1118 solver.cpp:245]     Train net output #0: loss = 0.0964973 (* 1 = 0.0964973 loss)
I0309 04:09:00.597337  1118 sgd_solver.cpp:106] Iteration 5600, lr = 0.0001
I0309 04:09:40.249932  1118 solver.cpp:229] Iteration 5650, loss = 0.115044
I0309 04:09:40.250241  1118 solver.cpp:245]     Train net output #0: loss = 0.115044 (* 1 = 0.115044 loss)
I0309 04:09:40.250275  1118 sgd_solver.cpp:106] Iteration 5650, lr = 0.0001
I0309 04:10:19.099027  1118 solver.cpp:338] Iteration 5700, Testing net (#0)
I0309 04:10:20.432564  1118 solver.cpp:406]     Test net output #0: accuracy = 0.958
I0309 04:10:20.432610  1118 solver.cpp:406]     Test net output #1: loss = 0.134425 (* 1 = 0.134425 loss)
I0309 04:10:21.043990  1118 solver.cpp:229] Iteration 5700, loss = 0.0777603
I0309 04:10:21.044037  1118 solver.cpp:245]     Train net output #0: loss = 0.0777603 (* 1 = 0.0777603 loss)
I0309 04:10:21.044064  1118 sgd_solver.cpp:106] Iteration 5700, lr = 0.0001
I0309 04:11:00.664234  1118 solver.cpp:229] Iteration 5750, loss = 0.0815292
I0309 04:11:00.664438  1118 solver.cpp:245]     Train net output #0: loss = 0.0815292 (* 1 = 0.0815292 loss)
I0309 04:11:00.664472  1118 sgd_solver.cpp:106] Iteration 5750, lr = 0.0001
I0309 04:11:40.302451  1118 solver.cpp:229] Iteration 5800, loss = 0.123027
I0309 04:11:40.302675  1118 solver.cpp:245]     Train net output #0: loss = 0.123027 (* 1 = 0.123027 loss)
I0309 04:11:40.302708  1118 sgd_solver.cpp:106] Iteration 5800, lr = 0.0001
I0309 04:12:19.927448  1118 solver.cpp:229] Iteration 5850, loss = 0.104397
I0309 04:12:19.927655  1118 solver.cpp:245]     Train net output #0: loss = 0.104397 (* 1 = 0.104397 loss)
I0309 04:12:19.927688  1118 sgd_solver.cpp:106] Iteration 5850, lr = 0.0001
I0309 04:12:59.572576  1118 solver.cpp:229] Iteration 5900, loss = 0.0757062
I0309 04:12:59.572783  1118 solver.cpp:245]     Train net output #0: loss = 0.0757061 (* 1 = 0.0757061 loss)
I0309 04:12:59.572815  1118 sgd_solver.cpp:106] Iteration 5900, lr = 0.0001
I0309 04:13:39.211503  1118 solver.cpp:229] Iteration 5950, loss = 0.0911878
I0309 04:13:39.211726  1118 solver.cpp:245]     Train net output #0: loss = 0.0911878 (* 1 = 0.0911878 loss)
I0309 04:13:39.211760  1118 sgd_solver.cpp:106] Iteration 5950, lr = 0.0001
I0309 04:14:18.064530  1118 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_6000.caffemodel
I0309 04:14:19.698493  1118 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_6000.solverstate
I0309 04:14:20.629276  1118 solver.cpp:338] Iteration 6000, Testing net (#0)
I0309 04:14:21.790025  1118 solver.cpp:406]     Test net output #0: accuracy = 0.96
I0309 04:14:21.790082  1118 solver.cpp:406]     Test net output #1: loss = 0.128191 (* 1 = 0.128191 loss)
I0309 04:14:22.401953  1118 solver.cpp:229] Iteration 6000, loss = 0.0979971
I0309 04:14:22.401998  1118 solver.cpp:245]     Train net output #0: loss = 0.0979971 (* 1 = 0.0979971 loss)
I0309 04:14:22.402029  1118 sgd_solver.cpp:106] Iteration 6000, lr = 0.0001
I0309 04:15:02.029656  1118 solver.cpp:229] Iteration 6050, loss = 0.0969213
I0309 04:15:02.029893  1118 solver.cpp:245]     Train net output #0: loss = 0.0969213 (* 1 = 0.0969213 loss)
I0309 04:15:02.029927  1118 sgd_solver.cpp:106] Iteration 6050, lr = 0.0001
I0309 04:15:41.672649  1118 solver.cpp:229] Iteration 6100, loss = 0.0961896
I0309 04:15:41.672955  1118 solver.cpp:245]     Train net output #0: loss = 0.0961896 (* 1 = 0.0961896 loss)
I0309 04:15:41.672989  1118 sgd_solver.cpp:106] Iteration 6100, lr = 0.0001
I0309 04:16:21.311102  1118 solver.cpp:229] Iteration 6150, loss = 0.0575606
I0309 04:16:21.311384  1118 solver.cpp:245]     Train net output #0: loss = 0.0575606 (* 1 = 0.0575606 loss)
I0309 04:16:21.311419  1118 sgd_solver.cpp:106] Iteration 6150, lr = 0.0001
I0309 04:17:00.958582  1118 solver.cpp:229] Iteration 6200, loss = 0.112201
I0309 04:17:00.958787  1118 solver.cpp:245]     Train net output #0: loss = 0.112201 (* 1 = 0.112201 loss)
I0309 04:17:00.958820  1118 sgd_solver.cpp:106] Iteration 6200, lr = 0.0001
I0309 04:17:40.600576  1118 solver.cpp:229] Iteration 6250, loss = 0.133555
I0309 04:17:40.600797  1118 solver.cpp:245]     Train net output #0: loss = 0.133555 (* 1 = 0.133555 loss)
I0309 04:17:40.600843  1118 sgd_solver.cpp:106] Iteration 6250, lr = 0.0001
I0309 04:18:19.459314  1118 solver.cpp:338] Iteration 6300, Testing net (#0)
I0309 04:18:20.793083  1118 solver.cpp:406]     Test net output #0: accuracy = 0.96
I0309 04:18:20.793128  1118 solver.cpp:406]     Test net output #1: loss = 0.129408 (* 1 = 0.129408 loss)
I0309 04:18:21.406539  1118 solver.cpp:229] Iteration 6300, loss = 0.107229
I0309 04:18:21.406584  1118 solver.cpp:245]     Train net output #0: loss = 0.107229 (* 1 = 0.107229 loss)
I0309 04:18:21.406610  1118 sgd_solver.cpp:106] Iteration 6300, lr = 0.0001
I0309 04:19:01.051475  1118 solver.cpp:229] Iteration 6350, loss = 0.158596
I0309 04:19:01.051678  1118 solver.cpp:245]     Train net output #0: loss = 0.158596 (* 1 = 0.158596 loss)
I0309 04:19:01.051712  1118 sgd_solver.cpp:106] Iteration 6350, lr = 0.0001
I0309 04:19:40.694432  1118 solver.cpp:229] Iteration 6400, loss = 0.12631
I0309 04:19:40.694634  1118 solver.cpp:245]     Train net output #0: loss = 0.12631 (* 1 = 0.12631 loss)
I0309 04:19:40.694667  1118 sgd_solver.cpp:106] Iteration 6400, lr = 0.0001
I0309 04:20:20.353348  1118 solver.cpp:229] Iteration 6450, loss = 0.0472668
I0309 04:20:20.353691  1118 solver.cpp:245]     Train net output #0: loss = 0.0472668 (* 1 = 0.0472668 loss)
I0309 04:20:20.353729  1118 sgd_solver.cpp:106] Iteration 6450, lr = 0.0001
I0309 04:20:59.211426  1118 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_6500.caffemodel
I0309 04:21:00.861742  1118 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_6500.solverstate
I0309 04:21:02.403971  1118 solver.cpp:229] Iteration 6500, loss = 0.0903208
I0309 04:21:02.404125  1118 solver.cpp:245]     Train net output #0: loss = 0.0903207 (* 1 = 0.0903207 loss)
I0309 04:21:02.404156  1118 sgd_solver.cpp:106] Iteration 6500, lr = 0.0001
I0309 04:21:42.053820  1118 solver.cpp:229] Iteration 6550, loss = 0.105658
I0309 04:21:42.054136  1118 solver.cpp:245]     Train net output #0: loss = 0.105658 (* 1 = 0.105658 loss)
I0309 04:21:42.054169  1118 sgd_solver.cpp:106] Iteration 6550, lr = 0.0001
I0309 04:22:20.907477  1118 solver.cpp:338] Iteration 6600, Testing net (#0)
I0309 04:22:22.240481  1118 solver.cpp:406]     Test net output #0: accuracy = 0.964
I0309 04:22:22.240530  1118 solver.cpp:406]     Test net output #1: loss = 0.126277 (* 1 = 0.126277 loss)
I0309 04:22:22.854368  1118 solver.cpp:229] Iteration 6600, loss = 0.110683
I0309 04:22:22.854413  1118 solver.cpp:245]     Train net output #0: loss = 0.110683 (* 1 = 0.110683 loss)
I0309 04:22:22.854439  1118 sgd_solver.cpp:106] Iteration 6600, lr = 0.0001
I0309 04:23:02.489480  1118 solver.cpp:229] Iteration 6650, loss = 0.117103
I0309 04:23:02.489696  1118 solver.cpp:245]     Train net output #0: loss = 0.117103 (* 1 = 0.117103 loss)
I0309 04:23:02.489729  1118 sgd_solver.cpp:106] Iteration 6650, lr = 0.0001
I0309 04:23:42.137845  1118 solver.cpp:229] Iteration 6700, loss = 0.0395886
I0309 04:23:42.138051  1118 solver.cpp:245]     Train net output #0: loss = 0.0395886 (* 1 = 0.0395886 loss)
I0309 04:23:42.138083  1118 sgd_solver.cpp:106] Iteration 6700, lr = 0.0001
I0309 04:24:21.779867  1118 solver.cpp:229] Iteration 6750, loss = 0.0597165
I0309 04:24:21.780062  1118 solver.cpp:245]     Train net output #0: loss = 0.0597164 (* 1 = 0.0597164 loss)
I0309 04:24:21.780097  1118 sgd_solver.cpp:106] Iteration 6750, lr = 0.0001
I0309 04:25:01.419046  1118 solver.cpp:229] Iteration 6800, loss = 0.0842718
I0309 04:25:01.419252  1118 solver.cpp:245]     Train net output #0: loss = 0.0842718 (* 1 = 0.0842718 loss)
I0309 04:25:01.419286  1118 sgd_solver.cpp:106] Iteration 6800, lr = 0.0001
I0309 04:25:41.066429  1118 solver.cpp:229] Iteration 6850, loss = 0.0906772
I0309 04:25:41.066645  1118 solver.cpp:245]     Train net output #0: loss = 0.0906771 (* 1 = 0.0906771 loss)
I0309 04:25:41.066679  1118 sgd_solver.cpp:106] Iteration 6850, lr = 0.0001
I0309 04:26:19.917225  1118 solver.cpp:338] Iteration 6900, Testing net (#0)
I0309 04:26:21.251507  1118 solver.cpp:406]     Test net output #0: accuracy = 0.96
I0309 04:26:21.251555  1118 solver.cpp:406]     Test net output #1: loss = 0.132805 (* 1 = 0.132805 loss)
I0309 04:26:21.863003  1118 solver.cpp:229] Iteration 6900, loss = 0.0872735
I0309 04:26:21.863054  1118 solver.cpp:245]     Train net output #0: loss = 0.0872734 (* 1 = 0.0872734 loss)
I0309 04:26:21.863083  1118 sgd_solver.cpp:106] Iteration 6900, lr = 0.0001
I0309 04:27:01.511361  1118 solver.cpp:229] Iteration 6950, loss = 0.0927685
I0309 04:27:01.511723  1118 solver.cpp:245]     Train net output #0: loss = 0.0927684 (* 1 = 0.0927684 loss)
I0309 04:27:01.511759  1118 sgd_solver.cpp:106] Iteration 6950, lr = 0.0001
I0309 04:27:40.377943  1118 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_7000.caffemodel
I0309 04:27:42.030540  1118 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_7000.solverstate
I0309 04:27:43.583204  1118 solver.cpp:229] Iteration 7000, loss = 0.162058
I0309 04:27:43.583364  1118 solver.cpp:245]     Train net output #0: loss = 0.162058 (* 1 = 0.162058 loss)
I0309 04:27:43.583395  1118 sgd_solver.cpp:106] Iteration 7000, lr = 0.0001
I0309 04:28:23.224638  1118 solver.cpp:229] Iteration 7050, loss = 0.0440044
I0309 04:28:23.224990  1118 solver.cpp:245]     Train net output #0: loss = 0.0440043 (* 1 = 0.0440043 loss)
I0309 04:28:23.225028  1118 sgd_solver.cpp:106] Iteration 7050, lr = 0.0001
I0309 04:29:02.866075  1118 solver.cpp:229] Iteration 7100, loss = 0.104192
I0309 04:29:02.866420  1118 solver.cpp:245]     Train net output #0: loss = 0.104192 (* 1 = 0.104192 loss)
I0309 04:29:02.866457  1118 sgd_solver.cpp:106] Iteration 7100, lr = 0.0001
I0309 04:29:42.506796  1118 solver.cpp:229] Iteration 7150, loss = 0.054841
I0309 04:29:42.507127  1118 solver.cpp:245]     Train net output #0: loss = 0.0548409 (* 1 = 0.0548409 loss)
I0309 04:29:42.507164  1118 sgd_solver.cpp:106] Iteration 7150, lr = 0.0001
I0309 04:30:21.383524  1118 solver.cpp:338] Iteration 7200, Testing net (#0)
I0309 04:30:22.716769  1118 solver.cpp:406]     Test net output #0: accuracy = 0.966
I0309 04:30:22.716827  1118 solver.cpp:406]     Test net output #1: loss = 0.121433 (* 1 = 0.121433 loss)
I0309 04:30:23.329294  1118 solver.cpp:229] Iteration 7200, loss = 0.096634
I0309 04:30:23.329448  1118 solver.cpp:245]     Train net output #0: loss = 0.0966339 (* 1 = 0.0966339 loss)
I0309 04:30:23.329479  1118 sgd_solver.cpp:106] Iteration 7200, lr = 0.0001
I0309 04:31:02.986404  1118 solver.cpp:229] Iteration 7250, loss = 0.129935
I0309 04:31:02.986762  1118 solver.cpp:245]     Train net output #0: loss = 0.129935 (* 1 = 0.129935 loss)
I0309 04:31:02.986799  1118 sgd_solver.cpp:106] Iteration 7250, lr = 0.0001
I0309 04:31:42.645715  1118 solver.cpp:229] Iteration 7300, loss = 0.0723574
I0309 04:31:42.646047  1118 solver.cpp:245]     Train net output #0: loss = 0.0723572 (* 1 = 0.0723572 loss)
I0309 04:31:42.646082  1118 sgd_solver.cpp:106] Iteration 7300, lr = 0.0001
I0309 04:32:22.298331  1118 solver.cpp:229] Iteration 7350, loss = 0.106608
I0309 04:32:22.298683  1118 solver.cpp:245]     Train net output #0: loss = 0.106608 (* 1 = 0.106608 loss)
I0309 04:32:22.298722  1118 sgd_solver.cpp:106] Iteration 7350, lr = 0.0001
I0309 04:33:01.937819  1118 solver.cpp:229] Iteration 7400, loss = 0.0834517
I0309 04:33:01.938143  1118 solver.cpp:245]     Train net output #0: loss = 0.0834516 (* 1 = 0.0834516 loss)
I0309 04:33:01.938179  1118 sgd_solver.cpp:106] Iteration 7400, lr = 0.0001
I0309 04:33:41.583891  1118 solver.cpp:229] Iteration 7450, loss = 0.0651516
I0309 04:33:41.584249  1118 solver.cpp:245]     Train net output #0: loss = 0.0651515 (* 1 = 0.0651515 loss)
I0309 04:33:41.584285  1118 sgd_solver.cpp:106] Iteration 7450, lr = 0.0001
I0309 04:34:20.444921  1118 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_7500.caffemodel
I0309 04:34:22.095008  1118 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_7500.solverstate
I0309 04:34:23.031888  1118 solver.cpp:338] Iteration 7500, Testing net (#0)
I0309 04:34:24.191592  1118 solver.cpp:406]     Test net output #0: accuracy = 0.962
I0309 04:34:24.191650  1118 solver.cpp:406]     Test net output #1: loss = 0.124039 (* 1 = 0.124039 loss)
I0309 04:34:24.804718  1118 solver.cpp:229] Iteration 7500, loss = 0.1093
I0309 04:34:24.804764  1118 solver.cpp:245]     Train net output #0: loss = 0.1093 (* 1 = 0.1093 loss)
I0309 04:34:24.804793  1118 sgd_solver.cpp:106] Iteration 7500, lr = 0.0001
I0309 04:35:04.452946  1118 solver.cpp:229] Iteration 7550, loss = 0.0807126
I0309 04:35:04.453164  1118 solver.cpp:245]     Train net output #0: loss = 0.0807124 (* 1 = 0.0807124 loss)
I0309 04:35:04.453198  1118 sgd_solver.cpp:106] Iteration 7550, lr = 0.0001
I0309 04:35:44.093834  1118 solver.cpp:229] Iteration 7600, loss = 0.0525635
I0309 04:35:44.094046  1118 solver.cpp:245]     Train net output #0: loss = 0.0525633 (* 1 = 0.0525633 loss)
I0309 04:35:44.094079  1118 sgd_solver.cpp:106] Iteration 7600, lr = 0.0001
I0309 04:36:23.732170  1118 solver.cpp:229] Iteration 7650, loss = 0.0469142
I0309 04:36:23.732369  1118 solver.cpp:245]     Train net output #0: loss = 0.0469141 (* 1 = 0.0469141 loss)
I0309 04:36:23.732403  1118 sgd_solver.cpp:106] Iteration 7650, lr = 0.0001
I0309 04:37:03.378051  1118 solver.cpp:229] Iteration 7700, loss = 0.122016
I0309 04:37:03.378264  1118 solver.cpp:245]     Train net output #0: loss = 0.122015 (* 1 = 0.122015 loss)
I0309 04:37:03.378298  1118 sgd_solver.cpp:106] Iteration 7700, lr = 0.0001
I0309 04:37:43.014729  1118 solver.cpp:229] Iteration 7750, loss = 0.0922097
I0309 04:37:43.014920  1118 solver.cpp:245]     Train net output #0: loss = 0.0922096 (* 1 = 0.0922096 loss)
I0309 04:37:43.014953  1118 sgd_solver.cpp:106] Iteration 7750, lr = 0.0001
I0309 04:38:21.867693  1118 solver.cpp:338] Iteration 7800, Testing net (#0)
I0309 04:38:23.201419  1118 solver.cpp:406]     Test net output #0: accuracy = 0.964
I0309 04:38:23.201464  1118 solver.cpp:406]     Test net output #1: loss = 0.129689 (* 1 = 0.129689 loss)
I0309 04:38:23.814555  1118 solver.cpp:229] Iteration 7800, loss = 0.0575156
I0309 04:38:23.814599  1118 solver.cpp:245]     Train net output #0: loss = 0.0575155 (* 1 = 0.0575155 loss)
I0309 04:38:23.814625  1118 sgd_solver.cpp:106] Iteration 7800, lr = 0.0001
I0309 04:39:03.445999  1118 solver.cpp:229] Iteration 7850, loss = 0.0661883
I0309 04:39:03.446208  1118 solver.cpp:245]     Train net output #0: loss = 0.0661881 (* 1 = 0.0661881 loss)
I0309 04:39:03.446241  1118 sgd_solver.cpp:106] Iteration 7850, lr = 0.0001
I0309 04:39:43.091532  1118 solver.cpp:229] Iteration 7900, loss = 0.0543618
I0309 04:39:43.091749  1118 solver.cpp:245]     Train net output #0: loss = 0.0543616 (* 1 = 0.0543616 loss)
I0309 04:39:43.091784  1118 sgd_solver.cpp:106] Iteration 7900, lr = 0.0001
I0309 04:40:22.752897  1118 solver.cpp:229] Iteration 7950, loss = 0.0989517
I0309 04:40:22.753101  1118 solver.cpp:245]     Train net output #0: loss = 0.0989516 (* 1 = 0.0989516 loss)
I0309 04:40:22.753135  1118 sgd_solver.cpp:106] Iteration 7950, lr = 0.0001
I0309 04:41:01.615578  1118 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_8000.caffemodel
I0309 04:41:03.266294  1118 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_8000.solverstate
I0309 04:41:04.811105  1118 solver.cpp:229] Iteration 8000, loss = 0.0684317
I0309 04:41:04.811189  1118 solver.cpp:245]     Train net output #0: loss = 0.0684316 (* 1 = 0.0684316 loss)
I0309 04:41:04.811220  1118 sgd_solver.cpp:106] Iteration 8000, lr = 0.0001
I0309 04:41:44.462973  1118 solver.cpp:229] Iteration 8050, loss = 0.106159
I0309 04:41:44.463199  1118 solver.cpp:245]     Train net output #0: loss = 0.106159 (* 1 = 0.106159 loss)
I0309 04:41:44.463233  1118 sgd_solver.cpp:106] Iteration 8050, lr = 0.0001
I0309 04:42:23.333645  1118 solver.cpp:338] Iteration 8100, Testing net (#0)
I0309 04:42:24.666529  1118 solver.cpp:406]     Test net output #0: accuracy = 0.962
I0309 04:42:24.666589  1118 solver.cpp:406]     Test net output #1: loss = 0.130451 (* 1 = 0.130451 loss)
I0309 04:42:25.279758  1118 solver.cpp:229] Iteration 8100, loss = 0.0791484
I0309 04:42:25.279914  1118 solver.cpp:245]     Train net output #0: loss = 0.0791483 (* 1 = 0.0791483 loss)
I0309 04:42:25.279944  1118 sgd_solver.cpp:106] Iteration 8100, lr = 0.0001
I0309 04:43:04.927284  1118 solver.cpp:229] Iteration 8150, loss = 0.0532463
I0309 04:43:04.927654  1118 solver.cpp:245]     Train net output #0: loss = 0.0532462 (* 1 = 0.0532462 loss)
I0309 04:43:04.927691  1118 sgd_solver.cpp:106] Iteration 8150, lr = 0.0001
I0309 04:43:44.582135  1118 solver.cpp:229] Iteration 8200, loss = 0.0732074
I0309 04:43:44.582469  1118 solver.cpp:245]     Train net output #0: loss = 0.0732073 (* 1 = 0.0732073 loss)
I0309 04:43:44.582506  1118 sgd_solver.cpp:106] Iteration 8200, lr = 0.0001
I0309 04:44:24.232062  1118 solver.cpp:229] Iteration 8250, loss = 0.157291
I0309 04:44:24.232389  1118 solver.cpp:245]     Train net output #0: loss = 0.15729 (* 1 = 0.15729 loss)
I0309 04:44:24.232425  1118 sgd_solver.cpp:106] Iteration 8250, lr = 0.0001
I0309 04:45:03.882753  1118 solver.cpp:229] Iteration 8300, loss = 0.0698598
I0309 04:45:03.883030  1118 solver.cpp:245]     Train net output #0: loss = 0.0698597 (* 1 = 0.0698597 loss)
I0309 04:45:03.883067  1118 sgd_solver.cpp:106] Iteration 8300, lr = 0.0001
I0309 04:45:43.524600  1118 solver.cpp:229] Iteration 8350, loss = 0.0777218
I0309 04:45:43.524960  1118 solver.cpp:245]     Train net output #0: loss = 0.0777216 (* 1 = 0.0777216 loss)
I0309 04:45:43.524996  1118 sgd_solver.cpp:106] Iteration 8350, lr = 0.0001
I0309 04:46:22.383050  1118 solver.cpp:338] Iteration 8400, Testing net (#0)
I0309 04:46:23.716886  1118 solver.cpp:406]     Test net output #0: accuracy = 0.962
I0309 04:46:23.716943  1118 solver.cpp:406]     Test net output #1: loss = 0.137753 (* 1 = 0.137753 loss)
I0309 04:46:24.328479  1118 solver.cpp:229] Iteration 8400, loss = 0.121417
I0309 04:46:24.328634  1118 solver.cpp:245]     Train net output #0: loss = 0.121417 (* 1 = 0.121417 loss)
I0309 04:46:24.328665  1118 sgd_solver.cpp:106] Iteration 8400, lr = 0.0001
I0309 04:47:03.962659  1118 solver.cpp:229] Iteration 8450, loss = 0.0617627
I0309 04:47:03.963021  1118 solver.cpp:245]     Train net output #0: loss = 0.0617625 (* 1 = 0.0617625 loss)
I0309 04:47:03.963058  1118 sgd_solver.cpp:106] Iteration 8450, lr = 0.0001
I0309 04:47:42.825479  1118 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_8500.caffemodel
I0309 04:47:44.472339  1118 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_8500.solverstate
I0309 04:47:46.017060  1118 solver.cpp:229] Iteration 8500, loss = 0.0249028
I0309 04:47:46.017143  1118 solver.cpp:245]     Train net output #0: loss = 0.0249026 (* 1 = 0.0249026 loss)
I0309 04:47:46.017174  1118 sgd_solver.cpp:106] Iteration 8500, lr = 0.0001
I0309 04:48:25.659566  1118 solver.cpp:229] Iteration 8550, loss = 0.0692663
I0309 04:48:25.659787  1118 solver.cpp:245]     Train net output #0: loss = 0.0692661 (* 1 = 0.0692661 loss)
I0309 04:48:25.659821  1118 sgd_solver.cpp:106] Iteration 8550, lr = 0.0001
I0309 04:49:05.303735  1118 solver.cpp:229] Iteration 8600, loss = 0.0859988
I0309 04:49:05.304092  1118 solver.cpp:245]     Train net output #0: loss = 0.0859987 (* 1 = 0.0859987 loss)
I0309 04:49:05.304128  1118 sgd_solver.cpp:106] Iteration 8600, lr = 0.0001
I0309 04:49:44.957160  1118 solver.cpp:229] Iteration 8650, loss = 0.0434549
I0309 04:49:44.957545  1118 solver.cpp:245]     Train net output #0: loss = 0.0434548 (* 1 = 0.0434548 loss)
I0309 04:49:44.957587  1118 sgd_solver.cpp:106] Iteration 8650, lr = 0.0001
I0309 04:50:23.819069  1118 solver.cpp:338] Iteration 8700, Testing net (#0)
I0309 04:50:25.152209  1118 solver.cpp:406]     Test net output #0: accuracy = 0.962
I0309 04:50:25.152264  1118 solver.cpp:406]     Test net output #1: loss = 0.131953 (* 1 = 0.131953 loss)
I0309 04:50:25.765360  1118 solver.cpp:229] Iteration 8700, loss = 0.113962
I0309 04:50:25.765517  1118 solver.cpp:245]     Train net output #0: loss = 0.113961 (* 1 = 0.113961 loss)
I0309 04:50:25.765548  1118 sgd_solver.cpp:106] Iteration 8700, lr = 0.0001
I0309 04:51:05.415671  1118 solver.cpp:229] Iteration 8750, loss = 0.0261127
I0309 04:51:05.416026  1118 solver.cpp:245]     Train net output #0: loss = 0.0261126 (* 1 = 0.0261126 loss)
I0309 04:51:05.416064  1118 sgd_solver.cpp:106] Iteration 8750, lr = 0.0001
I0309 04:51:45.055326  1118 solver.cpp:229] Iteration 8800, loss = 0.0753625
I0309 04:51:45.055690  1118 solver.cpp:245]     Train net output #0: loss = 0.0753624 (* 1 = 0.0753624 loss)
I0309 04:51:45.055726  1118 sgd_solver.cpp:106] Iteration 8800, lr = 0.0001
I0309 04:52:24.697140  1118 solver.cpp:229] Iteration 8850, loss = 0.0600502
I0309 04:52:24.697473  1118 solver.cpp:245]     Train net output #0: loss = 0.0600501 (* 1 = 0.0600501 loss)
I0309 04:52:24.697509  1118 sgd_solver.cpp:106] Iteration 8850, lr = 0.0001
I0309 04:53:04.340172  1118 solver.cpp:229] Iteration 8900, loss = 0.0500358
I0309 04:53:04.340504  1118 solver.cpp:245]     Train net output #0: loss = 0.0500357 (* 1 = 0.0500357 loss)
I0309 04:53:04.340541  1118 sgd_solver.cpp:106] Iteration 8900, lr = 0.0001
I0309 04:53:43.979373  1118 solver.cpp:229] Iteration 8950, loss = 0.100338
I0309 04:53:43.979754  1118 solver.cpp:245]     Train net output #0: loss = 0.100338 (* 1 = 0.100338 loss)
I0309 04:53:43.979791  1118 sgd_solver.cpp:106] Iteration 8950, lr = 0.0001
I0309 04:54:22.837980  1118 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_9000.caffemodel
I0309 04:54:24.482921  1118 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_9000.solverstate
I0309 04:54:25.408282  1118 solver.cpp:338] Iteration 9000, Testing net (#0)
I0309 04:54:26.567968  1118 solver.cpp:406]     Test net output #0: accuracy = 0.96
I0309 04:54:26.568023  1118 solver.cpp:406]     Test net output #1: loss = 0.125728 (* 1 = 0.125728 loss)
I0309 04:54:27.180275  1118 solver.cpp:229] Iteration 9000, loss = 0.0880921
I0309 04:54:27.180431  1118 solver.cpp:245]     Train net output #0: loss = 0.088092 (* 1 = 0.088092 loss)
I0309 04:54:27.180462  1118 sgd_solver.cpp:106] Iteration 9000, lr = 0.0001
I0309 04:55:06.826992  1118 solver.cpp:229] Iteration 9050, loss = 0.084751
I0309 04:55:06.827265  1118 solver.cpp:245]     Train net output #0: loss = 0.0847509 (* 1 = 0.0847509 loss)
I0309 04:55:06.827298  1118 sgd_solver.cpp:106] Iteration 9050, lr = 0.0001
I0309 04:55:46.470676  1118 solver.cpp:229] Iteration 9100, loss = 0.0912882
I0309 04:55:46.470976  1118 solver.cpp:245]     Train net output #0: loss = 0.0912881 (* 1 = 0.0912881 loss)
I0309 04:55:46.471010  1118 sgd_solver.cpp:106] Iteration 9100, lr = 0.0001
I0309 04:56:26.115711  1118 solver.cpp:229] Iteration 9150, loss = 0.0943129
I0309 04:56:26.115911  1118 solver.cpp:245]     Train net output #0: loss = 0.0943128 (* 1 = 0.0943128 loss)
I0309 04:56:26.115944  1118 sgd_solver.cpp:106] Iteration 9150, lr = 0.0001
I0309 04:57:05.760943  1118 solver.cpp:229] Iteration 9200, loss = 0.058415
I0309 04:57:05.761142  1118 solver.cpp:245]     Train net output #0: loss = 0.0584149 (* 1 = 0.0584149 loss)
I0309 04:57:05.761175  1118 sgd_solver.cpp:106] Iteration 9200, lr = 0.0001
I0309 04:57:45.395493  1118 solver.cpp:229] Iteration 9250, loss = 0.074527
I0309 04:57:45.395726  1118 solver.cpp:245]     Train net output #0: loss = 0.0745269 (* 1 = 0.0745269 loss)
I0309 04:57:45.395761  1118 sgd_solver.cpp:106] Iteration 9250, lr = 0.0001
I0309 04:58:24.256109  1118 solver.cpp:338] Iteration 9300, Testing net (#0)
I0309 04:58:25.589191  1118 solver.cpp:406]     Test net output #0: accuracy = 0.956
I0309 04:58:25.589236  1118 solver.cpp:406]     Test net output #1: loss = 0.142198 (* 1 = 0.142198 loss)
I0309 04:58:26.199959  1118 solver.cpp:229] Iteration 9300, loss = 0.112231
I0309 04:58:26.200002  1118 solver.cpp:245]     Train net output #0: loss = 0.112231 (* 1 = 0.112231 loss)
I0309 04:58:26.200028  1118 sgd_solver.cpp:106] Iteration 9300, lr = 0.0001
I0309 04:59:05.850723  1118 solver.cpp:229] Iteration 9350, loss = 0.0629864
I0309 04:59:05.850929  1118 solver.cpp:245]     Train net output #0: loss = 0.0629864 (* 1 = 0.0629864 loss)
I0309 04:59:05.850962  1118 sgd_solver.cpp:106] Iteration 9350, lr = 0.0001
I0309 04:59:45.481808  1118 solver.cpp:229] Iteration 9400, loss = 0.0744473
I0309 04:59:45.481993  1118 solver.cpp:245]     Train net output #0: loss = 0.0744472 (* 1 = 0.0744472 loss)
I0309 04:59:45.482026  1118 sgd_solver.cpp:106] Iteration 9400, lr = 0.0001
I0309 05:00:25.121177  1118 solver.cpp:229] Iteration 9450, loss = 0.0569329
I0309 05:00:25.121460  1118 solver.cpp:245]     Train net output #0: loss = 0.0569328 (* 1 = 0.0569328 loss)
I0309 05:00:25.121495  1118 sgd_solver.cpp:106] Iteration 9450, lr = 0.0001
I0309 05:01:03.978821  1118 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_9500.caffemodel
I0309 05:01:05.632105  1118 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_9500.solverstate
I0309 05:01:07.181500  1118 solver.cpp:229] Iteration 9500, loss = 0.0215587
I0309 05:01:07.181587  1118 solver.cpp:245]     Train net output #0: loss = 0.0215586 (* 1 = 0.0215586 loss)
I0309 05:01:07.181619  1118 sgd_solver.cpp:106] Iteration 9500, lr = 0.0001
I0309 05:01:46.827371  1118 solver.cpp:229] Iteration 9550, loss = 0.0899223
I0309 05:01:46.827566  1118 solver.cpp:245]     Train net output #0: loss = 0.0899222 (* 1 = 0.0899222 loss)
I0309 05:01:46.827600  1118 sgd_solver.cpp:106] Iteration 9550, lr = 0.0001
I0309 05:02:25.680541  1118 solver.cpp:338] Iteration 9600, Testing net (#0)
I0309 05:02:27.014777  1118 solver.cpp:406]     Test net output #0: accuracy = 0.956
I0309 05:02:27.014822  1118 solver.cpp:406]     Test net output #1: loss = 0.142328 (* 1 = 0.142328 loss)
I0309 05:02:27.627099  1118 solver.cpp:229] Iteration 9600, loss = 0.111748
I0309 05:02:27.627143  1118 solver.cpp:245]     Train net output #0: loss = 0.111748 (* 1 = 0.111748 loss)
I0309 05:02:27.627171  1118 sgd_solver.cpp:106] Iteration 9600, lr = 0.0001
I0309 05:03:07.265724  1118 solver.cpp:229] Iteration 9650, loss = 0.0619015
I0309 05:03:07.265925  1118 solver.cpp:245]     Train net output #0: loss = 0.0619014 (* 1 = 0.0619014 loss)
I0309 05:03:07.265959  1118 sgd_solver.cpp:106] Iteration 9650, lr = 0.0001
I0309 05:03:46.907322  1118 solver.cpp:229] Iteration 9700, loss = 0.0710177
I0309 05:03:46.907527  1118 solver.cpp:245]     Train net output #0: loss = 0.0710176 (* 1 = 0.0710176 loss)
I0309 05:03:46.907567  1118 sgd_solver.cpp:106] Iteration 9700, lr = 0.0001
I0309 05:04:26.552943  1118 solver.cpp:229] Iteration 9750, loss = 0.0638134
I0309 05:04:26.553138  1118 solver.cpp:245]     Train net output #0: loss = 0.0638133 (* 1 = 0.0638133 loss)
I0309 05:04:26.553170  1118 sgd_solver.cpp:106] Iteration 9750, lr = 0.0001
I0309 05:05:06.195459  1118 solver.cpp:229] Iteration 9800, loss = 0.0624419
I0309 05:05:06.195659  1118 solver.cpp:245]     Train net output #0: loss = 0.0624419 (* 1 = 0.0624419 loss)
I0309 05:05:06.195693  1118 sgd_solver.cpp:106] Iteration 9800, lr = 0.0001
I0309 05:05:45.833879  1118 solver.cpp:229] Iteration 9850, loss = 0.0646496
I0309 05:05:45.834087  1118 solver.cpp:245]     Train net output #0: loss = 0.0646496 (* 1 = 0.0646496 loss)
I0309 05:05:45.834132  1118 sgd_solver.cpp:106] Iteration 9850, lr = 0.0001
I0309 05:06:24.692271  1118 solver.cpp:338] Iteration 9900, Testing net (#0)
I0309 05:06:26.026051  1118 solver.cpp:406]     Test net output #0: accuracy = 0.956
I0309 05:06:26.026095  1118 solver.cpp:406]     Test net output #1: loss = 0.137521 (* 1 = 0.137521 loss)
I0309 05:06:26.638629  1118 solver.cpp:229] Iteration 9900, loss = 0.0377934
I0309 05:06:26.638672  1118 solver.cpp:245]     Train net output #0: loss = 0.0377933 (* 1 = 0.0377933 loss)
I0309 05:06:26.638698  1118 sgd_solver.cpp:106] Iteration 9900, lr = 0.0001
I0309 05:07:06.275118  1118 solver.cpp:229] Iteration 9950, loss = 0.0736722
I0309 05:07:06.275321  1118 solver.cpp:245]     Train net output #0: loss = 0.0736721 (* 1 = 0.0736721 loss)
I0309 05:07:06.275353  1118 sgd_solver.cpp:106] Iteration 9950, lr = 0.0001
I0309 05:07:45.122892  1118 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_10000.caffemodel
I0309 05:07:46.775316  1118 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_10000.solverstate
I0309 05:07:48.328419  1118 solver.cpp:229] Iteration 10000, loss = 0.0943834
I0309 05:07:48.328501  1118 solver.cpp:245]     Train net output #0: loss = 0.0943834 (* 1 = 0.0943834 loss)
I0309 05:07:48.328532  1118 sgd_solver.cpp:106] Iteration 10000, lr = 1e-05
I0309 05:08:27.968588  1118 solver.cpp:229] Iteration 10050, loss = 0.0504433
I0309 05:08:27.968834  1118 solver.cpp:245]     Train net output #0: loss = 0.0504432 (* 1 = 0.0504432 loss)
I0309 05:08:27.968868  1118 sgd_solver.cpp:106] Iteration 10050, lr = 1e-05
I0309 05:09:07.608391  1118 solver.cpp:229] Iteration 10100, loss = 0.0643466
I0309 05:09:07.608675  1118 solver.cpp:245]     Train net output #0: loss = 0.0643465 (* 1 = 0.0643465 loss)
I0309 05:09:07.608707  1118 sgd_solver.cpp:106] Iteration 10100, lr = 1e-05
I0309 05:09:47.252677  1118 solver.cpp:229] Iteration 10150, loss = 0.0647229
I0309 05:09:47.252979  1118 solver.cpp:245]     Train net output #0: loss = 0.0647229 (* 1 = 0.0647229 loss)
I0309 05:09:47.253012  1118 sgd_solver.cpp:106] Iteration 10150, lr = 1e-05
I0309 05:10:26.105316  1118 solver.cpp:338] Iteration 10200, Testing net (#0)
I0309 05:10:27.438602  1118 solver.cpp:406]     Test net output #0: accuracy = 0.964
I0309 05:10:27.438648  1118 solver.cpp:406]     Test net output #1: loss = 0.131394 (* 1 = 0.131394 loss)
I0309 05:10:28.051599  1118 solver.cpp:229] Iteration 10200, loss = 0.101308
I0309 05:10:28.051645  1118 solver.cpp:245]     Train net output #0: loss = 0.101308 (* 1 = 0.101308 loss)
I0309 05:10:28.051671  1118 sgd_solver.cpp:106] Iteration 10200, lr = 1e-05
I0309 05:11:07.693274  1118 solver.cpp:229] Iteration 10250, loss = 0.0174134
I0309 05:11:07.693478  1118 solver.cpp:245]     Train net output #0: loss = 0.0174134 (* 1 = 0.0174134 loss)
I0309 05:11:07.693512  1118 sgd_solver.cpp:106] Iteration 10250, lr = 1e-05
I0309 05:11:47.329409  1118 solver.cpp:229] Iteration 10300, loss = 0.040025
I0309 05:11:47.329619  1118 solver.cpp:245]     Train net output #0: loss = 0.0400249 (* 1 = 0.0400249 loss)
I0309 05:11:47.329653  1118 sgd_solver.cpp:106] Iteration 10300, lr = 1e-05
I0309 05:12:26.973878  1118 solver.cpp:229] Iteration 10350, loss = 0.0391995
I0309 05:12:26.974068  1118 solver.cpp:245]     Train net output #0: loss = 0.0391995 (* 1 = 0.0391995 loss)
I0309 05:12:26.974102  1118 sgd_solver.cpp:106] Iteration 10350, lr = 1e-05
I0309 05:13:06.621579  1118 solver.cpp:229] Iteration 10400, loss = 0.0422106
I0309 05:13:06.621784  1118 solver.cpp:245]     Train net output #0: loss = 0.0422105 (* 1 = 0.0422105 loss)
I0309 05:13:06.621819  1118 sgd_solver.cpp:106] Iteration 10400, lr = 1e-05
I0309 05:13:46.264127  1118 solver.cpp:229] Iteration 10450, loss = 0.0919328
I0309 05:13:46.264336  1118 solver.cpp:245]     Train net output #0: loss = 0.0919328 (* 1 = 0.0919328 loss)
I0309 05:13:46.264384  1118 sgd_solver.cpp:106] Iteration 10450, lr = 1e-05
I0309 05:14:25.121997  1118 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_10500.caffemodel
I0309 05:14:26.769651  1118 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_10500.solverstate
I0309 05:14:27.697067  1118 solver.cpp:338] Iteration 10500, Testing net (#0)
I0309 05:14:28.856853  1118 solver.cpp:406]     Test net output #0: accuracy = 0.964
I0309 05:14:28.856909  1118 solver.cpp:406]     Test net output #1: loss = 0.129731 (* 1 = 0.129731 loss)
I0309 05:14:29.469925  1118 solver.cpp:229] Iteration 10500, loss = 0.0742377
I0309 05:14:29.469969  1118 solver.cpp:245]     Train net output #0: loss = 0.0742376 (* 1 = 0.0742376 loss)
I0309 05:14:29.470000  1118 sgd_solver.cpp:106] Iteration 10500, lr = 1e-05
I0309 05:15:09.123132  1118 solver.cpp:229] Iteration 10550, loss = 0.0486789
I0309 05:15:09.123489  1118 solver.cpp:245]     Train net output #0: loss = 0.0486788 (* 1 = 0.0486788 loss)
I0309 05:15:09.123527  1118 sgd_solver.cpp:106] Iteration 10550, lr = 1e-05
I0309 05:15:48.764799  1118 solver.cpp:229] Iteration 10600, loss = 0.0332326
I0309 05:15:48.765107  1118 solver.cpp:245]     Train net output #0: loss = 0.0332326 (* 1 = 0.0332326 loss)
I0309 05:15:48.765141  1118 sgd_solver.cpp:106] Iteration 10600, lr = 1e-05
I0309 05:16:28.407287  1118 solver.cpp:229] Iteration 10650, loss = 0.0288473
I0309 05:16:28.407498  1118 solver.cpp:245]     Train net output #0: loss = 0.0288472 (* 1 = 0.0288472 loss)
I0309 05:16:28.407531  1118 sgd_solver.cpp:106] Iteration 10650, lr = 1e-05
I0309 05:17:08.043244  1118 solver.cpp:229] Iteration 10700, loss = 0.0314309
I0309 05:17:08.043439  1118 solver.cpp:245]     Train net output #0: loss = 0.0314308 (* 1 = 0.0314308 loss)
I0309 05:17:08.043473  1118 sgd_solver.cpp:106] Iteration 10700, lr = 1e-05
I0309 05:17:47.683476  1118 solver.cpp:229] Iteration 10750, loss = 0.0940887
I0309 05:17:47.683681  1118 solver.cpp:245]     Train net output #0: loss = 0.0940887 (* 1 = 0.0940887 loss)
I0309 05:17:47.683715  1118 sgd_solver.cpp:106] Iteration 10750, lr = 1e-05
I0309 05:18:26.543838  1118 solver.cpp:338] Iteration 10800, Testing net (#0)
I0309 05:18:27.877488  1118 solver.cpp:406]     Test net output #0: accuracy = 0.964
I0309 05:18:27.877535  1118 solver.cpp:406]     Test net output #1: loss = 0.130068 (* 1 = 0.130068 loss)
I0309 05:18:28.490756  1118 solver.cpp:229] Iteration 10800, loss = 0.0712497
I0309 05:18:28.490799  1118 solver.cpp:245]     Train net output #0: loss = 0.0712496 (* 1 = 0.0712496 loss)
I0309 05:18:28.490825  1118 sgd_solver.cpp:106] Iteration 10800, lr = 1e-05
I0309 05:19:08.127343  1118 solver.cpp:229] Iteration 10850, loss = 0.0535698
I0309 05:19:08.127545  1118 solver.cpp:245]     Train net output #0: loss = 0.0535698 (* 1 = 0.0535698 loss)
I0309 05:19:08.127586  1118 sgd_solver.cpp:106] Iteration 10850, lr = 1e-05
I0309 05:19:47.772066  1118 solver.cpp:229] Iteration 10900, loss = 0.0548652
I0309 05:19:47.772260  1118 solver.cpp:245]     Train net output #0: loss = 0.0548651 (* 1 = 0.0548651 loss)
I0309 05:19:47.772294  1118 sgd_solver.cpp:106] Iteration 10900, lr = 1e-05
I0309 05:20:27.412827  1118 solver.cpp:229] Iteration 10950, loss = 0.0586738
I0309 05:20:27.413033  1118 solver.cpp:245]     Train net output #0: loss = 0.0586738 (* 1 = 0.0586738 loss)
I0309 05:20:27.413065  1118 sgd_solver.cpp:106] Iteration 10950, lr = 1e-05
I0309 05:21:06.270135  1118 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_11000.caffemodel
I0309 05:21:07.915837  1118 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_11000.solverstate
I0309 05:21:09.463594  1118 solver.cpp:229] Iteration 11000, loss = 0.0722808
I0309 05:21:09.463690  1118 solver.cpp:245]     Train net output #0: loss = 0.0722808 (* 1 = 0.0722808 loss)
I0309 05:21:09.463722  1118 sgd_solver.cpp:106] Iteration 11000, lr = 1e-05
I0309 05:21:49.091882  1118 solver.cpp:229] Iteration 11050, loss = 0.12639
I0309 05:21:49.092208  1118 solver.cpp:245]     Train net output #0: loss = 0.12639 (* 1 = 0.12639 loss)
I0309 05:21:49.092242  1118 sgd_solver.cpp:106] Iteration 11050, lr = 1e-05
I0309 05:22:27.940191  1118 solver.cpp:338] Iteration 11100, Testing net (#0)
I0309 05:22:29.272614  1118 solver.cpp:406]     Test net output #0: accuracy = 0.96
I0309 05:22:29.272660  1118 solver.cpp:406]     Test net output #1: loss = 0.131751 (* 1 = 0.131751 loss)
I0309 05:22:29.884958  1118 solver.cpp:229] Iteration 11100, loss = 0.0901744
I0309 05:22:29.885004  1118 solver.cpp:245]     Train net output #0: loss = 0.0901743 (* 1 = 0.0901743 loss)
I0309 05:22:29.885030  1118 sgd_solver.cpp:106] Iteration 11100, lr = 1e-05
I0309 05:23:09.533956  1118 solver.cpp:229] Iteration 11150, loss = 0.0847312
I0309 05:23:09.534159  1118 solver.cpp:245]     Train net output #0: loss = 0.0847311 (* 1 = 0.0847311 loss)
I0309 05:23:09.534193  1118 sgd_solver.cpp:106] Iteration 11150, lr = 1e-05
I0309 05:23:49.177906  1118 solver.cpp:229] Iteration 11200, loss = 0.0282269
I0309 05:23:49.178113  1118 solver.cpp:245]     Train net output #0: loss = 0.0282268 (* 1 = 0.0282268 loss)
I0309 05:23:49.178148  1118 sgd_solver.cpp:106] Iteration 11200, lr = 1e-05
I0309 05:24:28.820819  1118 solver.cpp:229] Iteration 11250, loss = 0.0742402
I0309 05:24:28.821022  1118 solver.cpp:245]     Train net output #0: loss = 0.0742401 (* 1 = 0.0742401 loss)
I0309 05:24:28.821054  1118 sgd_solver.cpp:106] Iteration 11250, lr = 1e-05
I0309 05:25:08.464227  1118 solver.cpp:229] Iteration 11300, loss = 0.0351491
I0309 05:25:08.464416  1118 solver.cpp:245]     Train net output #0: loss = 0.035149 (* 1 = 0.035149 loss)
I0309 05:25:08.464448  1118 sgd_solver.cpp:106] Iteration 11300, lr = 1e-05
I0309 05:25:48.106576  1118 solver.cpp:229] Iteration 11350, loss = 0.0146727
I0309 05:25:48.106767  1118 solver.cpp:245]     Train net output #0: loss = 0.0146726 (* 1 = 0.0146726 loss)
I0309 05:25:48.106801  1118 sgd_solver.cpp:106] Iteration 11350, lr = 1e-05
I0309 05:26:26.967274  1118 solver.cpp:338] Iteration 11400, Testing net (#0)
I0309 05:26:28.300115  1118 solver.cpp:406]     Test net output #0: accuracy = 0.96
I0309 05:26:28.300160  1118 solver.cpp:406]     Test net output #1: loss = 0.129573 (* 1 = 0.129573 loss)
I0309 05:26:28.912379  1118 solver.cpp:229] Iteration 11400, loss = 0.0571715
I0309 05:26:28.912423  1118 solver.cpp:245]     Train net output #0: loss = 0.0571714 (* 1 = 0.0571714 loss)
I0309 05:26:28.912449  1118 sgd_solver.cpp:106] Iteration 11400, lr = 1e-05
I0309 05:27:08.549444  1118 solver.cpp:229] Iteration 11450, loss = 0.0347032
I0309 05:27:08.549641  1118 solver.cpp:245]     Train net output #0: loss = 0.0347031 (* 1 = 0.0347031 loss)
I0309 05:27:08.549674  1118 sgd_solver.cpp:106] Iteration 11450, lr = 1e-05
I0309 05:27:47.399956  1118 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_11500.caffemodel
I0309 05:27:49.048971  1118 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_11500.solverstate
I0309 05:27:50.590896  1118 solver.cpp:229] Iteration 11500, loss = 0.048767
I0309 05:27:50.590976  1118 solver.cpp:245]     Train net output #0: loss = 0.0487669 (* 1 = 0.0487669 loss)
I0309 05:27:50.591008  1118 sgd_solver.cpp:106] Iteration 11500, lr = 1e-05
I0309 05:28:30.237150  1118 solver.cpp:229] Iteration 11550, loss = 0.0718268
I0309 05:28:30.237365  1118 solver.cpp:245]     Train net output #0: loss = 0.0718267 (* 1 = 0.0718267 loss)
I0309 05:28:30.237397  1118 sgd_solver.cpp:106] Iteration 11550, lr = 1e-05
I0309 05:29:09.887269  1118 solver.cpp:229] Iteration 11600, loss = 0.0295843
I0309 05:29:09.887496  1118 solver.cpp:245]     Train net output #0: loss = 0.0295842 (* 1 = 0.0295842 loss)
I0309 05:29:09.887542  1118 sgd_solver.cpp:106] Iteration 11600, lr = 1e-05
I0309 05:29:49.530931  1118 solver.cpp:229] Iteration 11650, loss = 0.066952
I0309 05:29:49.531133  1118 solver.cpp:245]     Train net output #0: loss = 0.0669519 (* 1 = 0.0669519 loss)
I0309 05:29:49.531167  1118 sgd_solver.cpp:106] Iteration 11650, lr = 1e-05
I0309 05:30:28.379380  1118 solver.cpp:338] Iteration 11700, Testing net (#0)
I0309 05:30:29.712913  1118 solver.cpp:406]     Test net output #0: accuracy = 0.96
I0309 05:30:29.712961  1118 solver.cpp:406]     Test net output #1: loss = 0.129502 (* 1 = 0.129502 loss)
I0309 05:30:30.326203  1118 solver.cpp:229] Iteration 11700, loss = 0.0403666
I0309 05:30:30.326247  1118 solver.cpp:245]     Train net output #0: loss = 0.0403665 (* 1 = 0.0403665 loss)
I0309 05:30:30.326274  1118 sgd_solver.cpp:106] Iteration 11700, lr = 1e-05
I0309 05:31:09.963623  1118 solver.cpp:229] Iteration 11750, loss = 0.0203304
I0309 05:31:09.963826  1118 solver.cpp:245]     Train net output #0: loss = 0.0203303 (* 1 = 0.0203303 loss)
I0309 05:31:09.963860  1118 sgd_solver.cpp:106] Iteration 11750, lr = 1e-05
I0309 05:31:49.609869  1118 solver.cpp:229] Iteration 11800, loss = 0.122417
I0309 05:31:49.610074  1118 solver.cpp:245]     Train net output #0: loss = 0.122417 (* 1 = 0.122417 loss)
I0309 05:31:49.610106  1118 sgd_solver.cpp:106] Iteration 11800, lr = 1e-05
I0309 05:32:29.253674  1118 solver.cpp:229] Iteration 11850, loss = 0.058556
I0309 05:32:29.253878  1118 solver.cpp:245]     Train net output #0: loss = 0.0585559 (* 1 = 0.0585559 loss)
I0309 05:32:29.253912  1118 sgd_solver.cpp:106] Iteration 11850, lr = 1e-05
I0309 05:33:08.904356  1118 solver.cpp:229] Iteration 11900, loss = 0.071599
I0309 05:33:08.904564  1118 solver.cpp:245]     Train net output #0: loss = 0.0715989 (* 1 = 0.0715989 loss)
I0309 05:33:08.904598  1118 sgd_solver.cpp:106] Iteration 11900, lr = 1e-05
I0309 05:33:48.552182  1118 solver.cpp:229] Iteration 11950, loss = 0.0163101
I0309 05:33:48.552378  1118 solver.cpp:245]     Train net output #0: loss = 0.01631 (* 1 = 0.01631 loss)
I0309 05:33:48.552412  1118 sgd_solver.cpp:106] Iteration 11950, lr = 1e-05
I0309 05:34:27.404057  1118 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_12000.caffemodel
I0309 05:34:29.059829  1118 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_12000.solverstate
I0309 05:34:29.990656  1118 solver.cpp:338] Iteration 12000, Testing net (#0)
I0309 05:34:31.150749  1118 solver.cpp:406]     Test net output #0: accuracy = 0.96
I0309 05:34:31.150805  1118 solver.cpp:406]     Test net output #1: loss = 0.130341 (* 1 = 0.130341 loss)
I0309 05:34:31.764302  1118 solver.cpp:229] Iteration 12000, loss = 0.047054
I0309 05:34:31.764345  1118 solver.cpp:245]     Train net output #0: loss = 0.0470539 (* 1 = 0.0470539 loss)
I0309 05:34:31.764375  1118 sgd_solver.cpp:106] Iteration 12000, lr = 1e-05
I0309 05:35:11.416034  1118 solver.cpp:229] Iteration 12050, loss = 0.119699
I0309 05:35:11.416321  1118 solver.cpp:245]     Train net output #0: loss = 0.119699 (* 1 = 0.119699 loss)
I0309 05:35:11.416354  1118 sgd_solver.cpp:106] Iteration 12050, lr = 1e-05
I0309 05:35:51.066759  1118 solver.cpp:229] Iteration 12100, loss = 0.0411623
I0309 05:35:51.066967  1118 solver.cpp:245]     Train net output #0: loss = 0.0411622 (* 1 = 0.0411622 loss)
I0309 05:35:51.067000  1118 sgd_solver.cpp:106] Iteration 12100, lr = 1e-05
I0309 05:36:30.713930  1118 solver.cpp:229] Iteration 12150, loss = 0.0370186
I0309 05:36:30.714130  1118 solver.cpp:245]     Train net output #0: loss = 0.0370185 (* 1 = 0.0370185 loss)
I0309 05:36:30.714164  1118 sgd_solver.cpp:106] Iteration 12150, lr = 1e-05
I0309 05:37:10.353164  1118 solver.cpp:229] Iteration 12200, loss = 0.0781376
I0309 05:37:10.353384  1118 solver.cpp:245]     Train net output #0: loss = 0.0781375 (* 1 = 0.0781375 loss)
I0309 05:37:10.353430  1118 sgd_solver.cpp:106] Iteration 12200, lr = 1e-05
I0309 05:37:49.995478  1118 solver.cpp:229] Iteration 12250, loss = 0.12194
I0309 05:37:49.995699  1118 solver.cpp:245]     Train net output #0: loss = 0.12194 (* 1 = 0.12194 loss)
I0309 05:37:49.995733  1118 sgd_solver.cpp:106] Iteration 12250, lr = 1e-05
I0309 05:38:28.854537  1118 solver.cpp:338] Iteration 12300, Testing net (#0)
I0309 05:38:30.187294  1118 solver.cpp:406]     Test net output #0: accuracy = 0.958
I0309 05:38:30.187340  1118 solver.cpp:406]     Test net output #1: loss = 0.131251 (* 1 = 0.131251 loss)
I0309 05:38:30.799692  1118 solver.cpp:229] Iteration 12300, loss = 0.0917071
I0309 05:38:30.799738  1118 solver.cpp:245]     Train net output #0: loss = 0.091707 (* 1 = 0.091707 loss)
I0309 05:38:30.799764  1118 sgd_solver.cpp:106] Iteration 12300, lr = 1e-05
I0309 05:39:10.442252  1118 solver.cpp:229] Iteration 12350, loss = 0.103087
I0309 05:39:10.442454  1118 solver.cpp:245]     Train net output #0: loss = 0.103087 (* 1 = 0.103087 loss)
I0309 05:39:10.442487  1118 sgd_solver.cpp:106] Iteration 12350, lr = 1e-05
I0309 05:39:50.081746  1118 solver.cpp:229] Iteration 12400, loss = 0.0353058
I0309 05:39:50.081936  1118 solver.cpp:245]     Train net output #0: loss = 0.0353057 (* 1 = 0.0353057 loss)
I0309 05:39:50.081969  1118 sgd_solver.cpp:106] Iteration 12400, lr = 1e-05
I0309 05:40:29.727402  1118 solver.cpp:229] Iteration 12450, loss = 0.0772798
I0309 05:40:29.727607  1118 solver.cpp:245]     Train net output #0: loss = 0.0772798 (* 1 = 0.0772798 loss)
I0309 05:40:29.727641  1118 sgd_solver.cpp:106] Iteration 12450, lr = 1e-05
I0309 05:41:08.581218  1118 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_12500.caffemodel
I0309 05:41:10.228168  1118 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_12500.solverstate
I0309 05:41:11.772786  1118 solver.cpp:229] Iteration 12500, loss = 0.0604762
I0309 05:41:11.772871  1118 solver.cpp:245]     Train net output #0: loss = 0.0604762 (* 1 = 0.0604762 loss)
I0309 05:41:11.772903  1118 sgd_solver.cpp:106] Iteration 12500, lr = 1e-05
I0309 05:41:51.417057  1118 solver.cpp:229] Iteration 12550, loss = 0.091918
I0309 05:41:51.417347  1118 solver.cpp:245]     Train net output #0: loss = 0.0919179 (* 1 = 0.0919179 loss)
I0309 05:41:51.417382  1118 sgd_solver.cpp:106] Iteration 12550, lr = 1e-05
I0309 05:42:30.269280  1118 solver.cpp:338] Iteration 12600, Testing net (#0)
I0309 05:42:31.602995  1118 solver.cpp:406]     Test net output #0: accuracy = 0.96
I0309 05:42:31.603040  1118 solver.cpp:406]     Test net output #1: loss = 0.131444 (* 1 = 0.131444 loss)
I0309 05:42:32.215618  1118 solver.cpp:229] Iteration 12600, loss = 0.0205457
I0309 05:42:32.215662  1118 solver.cpp:245]     Train net output #0: loss = 0.0205456 (* 1 = 0.0205456 loss)
I0309 05:42:32.215688  1118 sgd_solver.cpp:106] Iteration 12600, lr = 1e-05
I0309 05:43:11.868439  1118 solver.cpp:229] Iteration 12650, loss = 0.093041
I0309 05:43:11.868747  1118 solver.cpp:245]     Train net output #0: loss = 0.0930409 (* 1 = 0.0930409 loss)
I0309 05:43:11.868782  1118 sgd_solver.cpp:106] Iteration 12650, lr = 1e-05
I0309 05:43:51.509140  1118 solver.cpp:229] Iteration 12700, loss = 0.0516468
I0309 05:43:51.509337  1118 solver.cpp:245]     Train net output #0: loss = 0.0516467 (* 1 = 0.0516467 loss)
I0309 05:43:51.509371  1118 sgd_solver.cpp:106] Iteration 12700, lr = 1e-05
I0309 05:44:31.149278  1118 solver.cpp:229] Iteration 12750, loss = 0.0414679
I0309 05:44:31.149477  1118 solver.cpp:245]     Train net output #0: loss = 0.0414678 (* 1 = 0.0414678 loss)
I0309 05:44:31.149509  1118 sgd_solver.cpp:106] Iteration 12750, lr = 1e-05
I0309 05:45:10.792769  1118 solver.cpp:229] Iteration 12800, loss = 0.0537854
I0309 05:45:10.793128  1118 solver.cpp:245]     Train net output #0: loss = 0.0537854 (* 1 = 0.0537854 loss)
I0309 05:45:10.793165  1118 sgd_solver.cpp:106] Iteration 12800, lr = 1e-05
I0309 05:45:50.438249  1118 solver.cpp:229] Iteration 12850, loss = 0.0864692
I0309 05:45:50.438601  1118 solver.cpp:245]     Train net output #0: loss = 0.0864692 (* 1 = 0.0864692 loss)
I0309 05:45:50.438637  1118 sgd_solver.cpp:106] Iteration 12850, lr = 1e-05
I0309 05:46:29.288126  1118 solver.cpp:338] Iteration 12900, Testing net (#0)
I0309 05:46:30.620820  1118 solver.cpp:406]     Test net output #0: accuracy = 0.96
I0309 05:46:30.620877  1118 solver.cpp:406]     Test net output #1: loss = 0.130296 (* 1 = 0.130296 loss)
I0309 05:46:31.233391  1118 solver.cpp:229] Iteration 12900, loss = 0.0412953
I0309 05:46:31.233543  1118 solver.cpp:245]     Train net output #0: loss = 0.0412952 (* 1 = 0.0412952 loss)
I0309 05:46:31.233579  1118 sgd_solver.cpp:106] Iteration 12900, lr = 1e-05
I0309 05:47:10.883227  1118 solver.cpp:229] Iteration 12950, loss = 0.0468764
I0309 05:47:10.883584  1118 solver.cpp:245]     Train net output #0: loss = 0.0468764 (* 1 = 0.0468764 loss)
I0309 05:47:10.883620  1118 sgd_solver.cpp:106] Iteration 12950, lr = 1e-05
I0309 05:47:49.733999  1118 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_13000.caffemodel
I0309 05:47:51.394235  1118 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_13000.solverstate
I0309 05:47:52.951210  1118 solver.cpp:229] Iteration 13000, loss = 0.0565079
I0309 05:47:52.951375  1118 solver.cpp:245]     Train net output #0: loss = 0.0565078 (* 1 = 0.0565078 loss)
I0309 05:47:52.951407  1118 sgd_solver.cpp:106] Iteration 13000, lr = 1e-05
I0309 05:48:32.593829  1118 solver.cpp:229] Iteration 13050, loss = 0.0436181
I0309 05:48:32.594168  1118 solver.cpp:245]     Train net output #0: loss = 0.043618 (* 1 = 0.043618 loss)
I0309 05:48:32.594205  1118 sgd_solver.cpp:106] Iteration 13050, lr = 1e-05
I0309 05:49:12.231910  1118 solver.cpp:229] Iteration 13100, loss = 0.0604335
I0309 05:49:12.232245  1118 solver.cpp:245]     Train net output #0: loss = 0.0604334 (* 1 = 0.0604334 loss)
I0309 05:49:12.232281  1118 sgd_solver.cpp:106] Iteration 13100, lr = 1e-05
I0309 05:49:51.870617  1118 solver.cpp:229] Iteration 13150, loss = 0.0818045
I0309 05:49:51.870970  1118 solver.cpp:245]     Train net output #0: loss = 0.0818044 (* 1 = 0.0818044 loss)
I0309 05:49:51.871007  1118 sgd_solver.cpp:106] Iteration 13150, lr = 1e-05
I0309 05:50:30.731636  1118 solver.cpp:338] Iteration 13200, Testing net (#0)
I0309 05:50:32.065501  1118 solver.cpp:406]     Test net output #0: accuracy = 0.96
I0309 05:50:32.065570  1118 solver.cpp:406]     Test net output #1: loss = 0.130026 (* 1 = 0.130026 loss)
I0309 05:50:32.676254  1118 solver.cpp:229] Iteration 13200, loss = 0.0709637
I0309 05:50:32.676398  1118 solver.cpp:245]     Train net output #0: loss = 0.0709636 (* 1 = 0.0709636 loss)
I0309 05:50:32.676429  1118 sgd_solver.cpp:106] Iteration 13200, lr = 1e-05
I0309 05:51:12.316334  1118 solver.cpp:229] Iteration 13250, loss = 0.0667417
I0309 05:51:12.316660  1118 solver.cpp:245]     Train net output #0: loss = 0.0667416 (* 1 = 0.0667416 loss)
I0309 05:51:12.316694  1118 sgd_solver.cpp:106] Iteration 13250, lr = 1e-05
I0309 05:51:51.954607  1118 solver.cpp:229] Iteration 13300, loss = 0.0558884
I0309 05:51:51.954818  1118 solver.cpp:245]     Train net output #0: loss = 0.0558883 (* 1 = 0.0558883 loss)
I0309 05:51:51.954851  1118 sgd_solver.cpp:106] Iteration 13300, lr = 1e-05
I0309 05:52:31.602680  1118 solver.cpp:229] Iteration 13350, loss = 0.0540233
I0309 05:52:31.602885  1118 solver.cpp:245]     Train net output #0: loss = 0.0540233 (* 1 = 0.0540233 loss)
I0309 05:52:31.602918  1118 sgd_solver.cpp:106] Iteration 13350, lr = 1e-05
I0309 05:53:11.256402  1118 solver.cpp:229] Iteration 13400, loss = 0.0433787
I0309 05:53:11.256628  1118 solver.cpp:245]     Train net output #0: loss = 0.0433786 (* 1 = 0.0433786 loss)
I0309 05:53:11.256662  1118 sgd_solver.cpp:106] Iteration 13400, lr = 1e-05
I0309 05:53:50.902786  1118 solver.cpp:229] Iteration 13450, loss = 0.0606948
I0309 05:53:50.902998  1118 solver.cpp:245]     Train net output #0: loss = 0.0606947 (* 1 = 0.0606947 loss)
I0309 05:53:50.903031  1118 sgd_solver.cpp:106] Iteration 13450, lr = 1e-05
I0309 05:54:29.762230  1118 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_13500.caffemodel
I0309 05:54:31.413172  1118 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_13500.solverstate
I0309 05:54:32.353484  1118 solver.cpp:338] Iteration 13500, Testing net (#0)
I0309 05:54:33.513718  1118 solver.cpp:406]     Test net output #0: accuracy = 0.962
I0309 05:54:33.513774  1118 solver.cpp:406]     Test net output #1: loss = 0.12983 (* 1 = 0.12983 loss)
I0309 05:54:34.127074  1118 solver.cpp:229] Iteration 13500, loss = 0.0772507
I0309 05:54:34.127120  1118 solver.cpp:245]     Train net output #0: loss = 0.0772506 (* 1 = 0.0772506 loss)
I0309 05:54:34.127151  1118 sgd_solver.cpp:106] Iteration 13500, lr = 1e-05
I0309 05:55:13.776010  1118 solver.cpp:229] Iteration 13550, loss = 0.0361948
I0309 05:55:13.776244  1118 solver.cpp:245]     Train net output #0: loss = 0.0361947 (* 1 = 0.0361947 loss)
I0309 05:55:13.776278  1118 sgd_solver.cpp:106] Iteration 13550, lr = 1e-05
I0309 05:55:53.422667  1118 solver.cpp:229] Iteration 13600, loss = 0.0175908
I0309 05:55:53.422865  1118 solver.cpp:245]     Train net output #0: loss = 0.0175907 (* 1 = 0.0175907 loss)
I0309 05:55:53.422899  1118 sgd_solver.cpp:106] Iteration 13600, lr = 1e-05
I0309 05:56:33.071847  1118 solver.cpp:229] Iteration 13650, loss = 0.0975579
I0309 05:56:33.072052  1118 solver.cpp:245]     Train net output #0: loss = 0.0975578 (* 1 = 0.0975578 loss)
I0309 05:56:33.072084  1118 sgd_solver.cpp:106] Iteration 13650, lr = 1e-05
I0309 05:57:12.712764  1118 solver.cpp:229] Iteration 13700, loss = 0.0298048
I0309 05:57:12.712966  1118 solver.cpp:245]     Train net output #0: loss = 0.0298047 (* 1 = 0.0298047 loss)
I0309 05:57:12.712999  1118 sgd_solver.cpp:106] Iteration 13700, lr = 1e-05
I0309 05:57:52.363302  1118 solver.cpp:229] Iteration 13750, loss = 0.0298226
I0309 05:57:52.363500  1118 solver.cpp:245]     Train net output #0: loss = 0.0298225 (* 1 = 0.0298225 loss)
I0309 05:57:52.363534  1118 sgd_solver.cpp:106] Iteration 13750, lr = 1e-05
I0309 05:58:31.230203  1118 solver.cpp:338] Iteration 13800, Testing net (#0)
I0309 05:58:32.563370  1118 solver.cpp:406]     Test net output #0: accuracy = 0.964
I0309 05:58:32.563416  1118 solver.cpp:406]     Test net output #1: loss = 0.130017 (* 1 = 0.130017 loss)
I0309 05:58:33.175735  1118 solver.cpp:229] Iteration 13800, loss = 0.0800292
I0309 05:58:33.175781  1118 solver.cpp:245]     Train net output #0: loss = 0.080029 (* 1 = 0.080029 loss)
I0309 05:58:33.175807  1118 sgd_solver.cpp:106] Iteration 13800, lr = 1e-05
I0309 05:59:12.826094  1118 solver.cpp:229] Iteration 13850, loss = 0.0433837
I0309 05:59:12.826304  1118 solver.cpp:245]     Train net output #0: loss = 0.0433836 (* 1 = 0.0433836 loss)
I0309 05:59:12.826338  1118 sgd_solver.cpp:106] Iteration 13850, lr = 1e-05
I0309 05:59:52.475679  1118 solver.cpp:229] Iteration 13900, loss = 0.0810236
I0309 05:59:52.476972  1118 solver.cpp:245]     Train net output #0: loss = 0.0810235 (* 1 = 0.0810235 loss)
I0309 05:59:52.477007  1118 sgd_solver.cpp:106] Iteration 13900, lr = 1e-05
I0309 06:00:32.128744  1118 solver.cpp:229] Iteration 13950, loss = 0.065584
I0309 06:00:32.129029  1118 solver.cpp:245]     Train net output #0: loss = 0.0655839 (* 1 = 0.0655839 loss)
I0309 06:00:32.129063  1118 sgd_solver.cpp:106] Iteration 13950, lr = 1e-05
I0309 06:01:10.990998  1118 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_14000.caffemodel
I0309 06:01:12.640724  1118 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_14000.solverstate
I0309 06:01:14.193060  1118 solver.cpp:229] Iteration 14000, loss = 0.0320602
I0309 06:01:14.193148  1118 solver.cpp:245]     Train net output #0: loss = 0.0320601 (* 1 = 0.0320601 loss)
I0309 06:01:14.193179  1118 sgd_solver.cpp:106] Iteration 14000, lr = 1e-05
I0309 06:01:53.839474  1118 solver.cpp:229] Iteration 14050, loss = 0.0289796
I0309 06:01:53.839697  1118 solver.cpp:245]     Train net output #0: loss = 0.0289795 (* 1 = 0.0289795 loss)
I0309 06:01:53.839731  1118 sgd_solver.cpp:106] Iteration 14050, lr = 1e-05
I0309 06:02:32.700132  1118 solver.cpp:338] Iteration 14100, Testing net (#0)
I0309 06:02:34.033313  1118 solver.cpp:406]     Test net output #0: accuracy = 0.964
I0309 06:02:34.033359  1118 solver.cpp:406]     Test net output #1: loss = 0.130111 (* 1 = 0.130111 loss)
I0309 06:02:34.646713  1118 solver.cpp:229] Iteration 14100, loss = 0.0232277
I0309 06:02:34.646757  1118 solver.cpp:245]     Train net output #0: loss = 0.0232276 (* 1 = 0.0232276 loss)
I0309 06:02:34.646783  1118 sgd_solver.cpp:106] Iteration 14100, lr = 1e-05
I0309 06:03:14.299185  1118 solver.cpp:229] Iteration 14150, loss = 0.0835299
I0309 06:03:14.299396  1118 solver.cpp:245]     Train net output #0: loss = 0.0835298 (* 1 = 0.0835298 loss)
I0309 06:03:14.299429  1118 sgd_solver.cpp:106] Iteration 14150, lr = 1e-05
I0309 06:03:53.950673  1118 solver.cpp:229] Iteration 14200, loss = 0.0786695
I0309 06:03:53.950883  1118 solver.cpp:245]     Train net output #0: loss = 0.0786693 (* 1 = 0.0786693 loss)
I0309 06:03:53.950917  1118 sgd_solver.cpp:106] Iteration 14200, lr = 1e-05
I0309 06:04:33.608031  1118 solver.cpp:229] Iteration 14250, loss = 0.0451383
I0309 06:04:33.608227  1118 solver.cpp:245]     Train net output #0: loss = 0.0451381 (* 1 = 0.0451381 loss)
I0309 06:04:33.608259  1118 sgd_solver.cpp:106] Iteration 14250, lr = 1e-05
I0309 06:05:13.257467  1118 solver.cpp:229] Iteration 14300, loss = 0.0372935
I0309 06:05:13.257657  1118 solver.cpp:245]     Train net output #0: loss = 0.0372933 (* 1 = 0.0372933 loss)
I0309 06:05:13.257689  1118 sgd_solver.cpp:106] Iteration 14300, lr = 1e-05
I0309 06:05:52.911622  1118 solver.cpp:229] Iteration 14350, loss = 0.0284383
I0309 06:05:52.911828  1118 solver.cpp:245]     Train net output #0: loss = 0.0284382 (* 1 = 0.0284382 loss)
I0309 06:05:52.911860  1118 sgd_solver.cpp:106] Iteration 14350, lr = 1e-05
I0309 06:06:31.778283  1118 solver.cpp:338] Iteration 14400, Testing net (#0)
I0309 06:06:33.112596  1118 solver.cpp:406]     Test net output #0: accuracy = 0.958
I0309 06:06:33.112643  1118 solver.cpp:406]     Test net output #1: loss = 0.129988 (* 1 = 0.129988 loss)
I0309 06:06:33.724588  1118 solver.cpp:229] Iteration 14400, loss = 0.077573
I0309 06:06:33.724633  1118 solver.cpp:245]     Train net output #0: loss = 0.0775728 (* 1 = 0.0775728 loss)
I0309 06:06:33.724660  1118 sgd_solver.cpp:106] Iteration 14400, lr = 1e-05
I0309 06:07:13.384393  1118 solver.cpp:229] Iteration 14450, loss = 0.0774931
I0309 06:07:13.384608  1118 solver.cpp:245]     Train net output #0: loss = 0.0774929 (* 1 = 0.0774929 loss)
I0309 06:07:13.384640  1118 sgd_solver.cpp:106] Iteration 14450, lr = 1e-05
I0309 06:07:52.241691  1118 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_14500.caffemodel
I0309 06:07:53.888183  1118 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_14500.solverstate
I0309 06:07:55.436238  1118 solver.cpp:229] Iteration 14500, loss = 0.0226001
I0309 06:07:55.436321  1118 solver.cpp:245]     Train net output #0: loss = 0.0225999 (* 1 = 0.0225999 loss)
I0309 06:07:55.436353  1118 sgd_solver.cpp:106] Iteration 14500, lr = 1e-05
I0309 06:08:35.097784  1118 solver.cpp:229] Iteration 14550, loss = 0.0490243
I0309 06:08:35.098016  1118 solver.cpp:245]     Train net output #0: loss = 0.0490241 (* 1 = 0.0490241 loss)
I0309 06:08:35.098048  1118 sgd_solver.cpp:106] Iteration 14550, lr = 1e-05
I0309 06:09:14.744849  1118 solver.cpp:229] Iteration 14600, loss = 0.0349473
I0309 06:09:14.745061  1118 solver.cpp:245]     Train net output #0: loss = 0.0349472 (* 1 = 0.0349472 loss)
I0309 06:09:14.745095  1118 sgd_solver.cpp:106] Iteration 14600, lr = 1e-05
I0309 06:09:54.394263  1118 solver.cpp:229] Iteration 14650, loss = 0.0587525
I0309 06:09:54.394469  1118 solver.cpp:245]     Train net output #0: loss = 0.0587524 (* 1 = 0.0587524 loss)
I0309 06:09:54.394501  1118 sgd_solver.cpp:106] Iteration 14650, lr = 1e-05
I0309 06:10:33.259948  1118 solver.cpp:338] Iteration 14700, Testing net (#0)
I0309 06:10:34.593225  1118 solver.cpp:406]     Test net output #0: accuracy = 0.958
I0309 06:10:34.593278  1118 solver.cpp:406]     Test net output #1: loss = 0.130055 (* 1 = 0.130055 loss)
I0309 06:10:35.204665  1118 solver.cpp:229] Iteration 14700, loss = 0.0360685
I0309 06:10:35.204710  1118 solver.cpp:245]     Train net output #0: loss = 0.0360684 (* 1 = 0.0360684 loss)
I0309 06:10:35.204737  1118 sgd_solver.cpp:106] Iteration 14700, lr = 1e-05
I0309 06:11:14.853466  1118 solver.cpp:229] Iteration 14750, loss = 0.152064
I0309 06:11:14.853680  1118 solver.cpp:245]     Train net output #0: loss = 0.152064 (* 1 = 0.152064 loss)
I0309 06:11:14.853713  1118 sgd_solver.cpp:106] Iteration 14750, lr = 1e-05
I0309 06:11:54.500660  1118 solver.cpp:229] Iteration 14800, loss = 0.0539099
I0309 06:11:54.500867  1118 solver.cpp:245]     Train net output #0: loss = 0.0539097 (* 1 = 0.0539097 loss)
I0309 06:11:54.500900  1118 sgd_solver.cpp:106] Iteration 14800, lr = 1e-05
I0309 06:12:34.146356  1118 solver.cpp:229] Iteration 14850, loss = 0.0625594
I0309 06:12:34.146570  1118 solver.cpp:245]     Train net output #0: loss = 0.0625592 (* 1 = 0.0625592 loss)
I0309 06:12:34.146603  1118 sgd_solver.cpp:106] Iteration 14850, lr = 1e-05
I0309 06:13:13.787431  1118 solver.cpp:229] Iteration 14900, loss = 0.0501583
I0309 06:13:13.787642  1118 solver.cpp:245]     Train net output #0: loss = 0.0501581 (* 1 = 0.0501581 loss)
I0309 06:13:13.787675  1118 sgd_solver.cpp:106] Iteration 14900, lr = 1e-05
I0309 06:13:53.435144  1118 solver.cpp:229] Iteration 14950, loss = 0.0844992
I0309 06:13:53.435353  1118 solver.cpp:245]     Train net output #0: loss = 0.0844991 (* 1 = 0.0844991 loss)
I0309 06:13:53.435386  1118 sgd_solver.cpp:106] Iteration 14950, lr = 1e-05
I0309 06:14:32.297008  1118 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_15000.caffemodel
I0309 06:14:33.939266  1118 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_15000.solverstate
I0309 06:14:34.869060  1118 solver.cpp:338] Iteration 15000, Testing net (#0)
I0309 06:14:36.029346  1118 solver.cpp:406]     Test net output #0: accuracy = 0.958
I0309 06:14:36.029402  1118 solver.cpp:406]     Test net output #1: loss = 0.129451 (* 1 = 0.129451 loss)
I0309 06:14:36.641440  1118 solver.cpp:229] Iteration 15000, loss = 0.0521647
I0309 06:14:36.641484  1118 solver.cpp:245]     Train net output #0: loss = 0.0521646 (* 1 = 0.0521646 loss)
I0309 06:14:36.641515  1118 sgd_solver.cpp:106] Iteration 15000, lr = 1e-05
I0309 06:15:16.298475  1118 solver.cpp:229] Iteration 15050, loss = 0.0435915
I0309 06:15:16.298763  1118 solver.cpp:245]     Train net output #0: loss = 0.0435913 (* 1 = 0.0435913 loss)
I0309 06:15:16.298796  1118 sgd_solver.cpp:106] Iteration 15050, lr = 1e-05
I0309 06:15:55.958302  1118 solver.cpp:229] Iteration 15100, loss = 0.0728093
I0309 06:15:55.958508  1118 solver.cpp:245]     Train net output #0: loss = 0.0728091 (* 1 = 0.0728091 loss)
I0309 06:15:55.958541  1118 sgd_solver.cpp:106] Iteration 15100, lr = 1e-05
I0309 06:16:35.617763  1118 solver.cpp:229] Iteration 15150, loss = 0.0482075
I0309 06:16:35.617985  1118 solver.cpp:245]     Train net output #0: loss = 0.0482074 (* 1 = 0.0482074 loss)
I0309 06:16:35.618018  1118 sgd_solver.cpp:106] Iteration 15150, lr = 1e-05
I0309 06:17:15.254797  1118 solver.cpp:229] Iteration 15200, loss = 0.119812
I0309 06:17:15.255018  1118 solver.cpp:245]     Train net output #0: loss = 0.119812 (* 1 = 0.119812 loss)
I0309 06:17:15.255051  1118 sgd_solver.cpp:106] Iteration 15200, lr = 1e-05
I0309 06:17:54.905222  1118 solver.cpp:229] Iteration 15250, loss = 0.0486493
I0309 06:17:54.905427  1118 solver.cpp:245]     Train net output #0: loss = 0.0486492 (* 1 = 0.0486492 loss)
I0309 06:17:54.905460  1118 sgd_solver.cpp:106] Iteration 15250, lr = 1e-05
I0309 06:18:33.768414  1118 solver.cpp:338] Iteration 15300, Testing net (#0)
I0309 06:18:35.102259  1118 solver.cpp:406]     Test net output #0: accuracy = 0.962
I0309 06:18:35.102305  1118 solver.cpp:406]     Test net output #1: loss = 0.128324 (* 1 = 0.128324 loss)
I0309 06:18:35.713997  1118 solver.cpp:229] Iteration 15300, loss = 0.0765351
I0309 06:18:35.714042  1118 solver.cpp:245]     Train net output #0: loss = 0.0765349 (* 1 = 0.0765349 loss)
I0309 06:18:35.714068  1118 sgd_solver.cpp:106] Iteration 15300, lr = 1e-05
I0309 06:19:15.361435  1118 solver.cpp:229] Iteration 15350, loss = 0.0335779
I0309 06:19:15.361652  1118 solver.cpp:245]     Train net output #0: loss = 0.0335778 (* 1 = 0.0335778 loss)
I0309 06:19:15.361686  1118 sgd_solver.cpp:106] Iteration 15350, lr = 1e-05
I0309 06:19:55.007877  1118 solver.cpp:229] Iteration 15400, loss = 0.0312241
I0309 06:19:55.008083  1118 solver.cpp:245]     Train net output #0: loss = 0.0312239 (* 1 = 0.0312239 loss)
I0309 06:19:55.008117  1118 sgd_solver.cpp:106] Iteration 15400, lr = 1e-05
I0309 06:20:34.653200  1118 solver.cpp:229] Iteration 15450, loss = 0.0619259
I0309 06:20:34.653406  1118 solver.cpp:245]     Train net output #0: loss = 0.0619258 (* 1 = 0.0619258 loss)
I0309 06:20:34.653439  1118 sgd_solver.cpp:106] Iteration 15450, lr = 1e-05
I0309 06:21:13.513561  1118 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_15500.caffemodel
I0309 06:21:15.155829  1118 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_15500.solverstate
I0309 06:21:16.695600  1118 solver.cpp:229] Iteration 15500, loss = 0.0482976
I0309 06:21:16.695680  1118 solver.cpp:245]     Train net output #0: loss = 0.0482975 (* 1 = 0.0482975 loss)
I0309 06:21:16.695711  1118 sgd_solver.cpp:106] Iteration 15500, lr = 1e-05
I0309 06:21:56.341895  1118 solver.cpp:229] Iteration 15550, loss = 0.0794901
I0309 06:21:56.342131  1118 solver.cpp:245]     Train net output #0: loss = 0.0794899 (* 1 = 0.0794899 loss)
I0309 06:21:56.342164  1118 sgd_solver.cpp:106] Iteration 15550, lr = 1e-05
I0309 06:22:35.201282  1118 solver.cpp:338] Iteration 15600, Testing net (#0)
I0309 06:22:36.534796  1118 solver.cpp:406]     Test net output #0: accuracy = 0.96
I0309 06:22:36.534842  1118 solver.cpp:406]     Test net output #1: loss = 0.128436 (* 1 = 0.128436 loss)
I0309 06:22:37.147148  1118 solver.cpp:229] Iteration 15600, loss = 0.0753471
I0309 06:22:37.147202  1118 solver.cpp:245]     Train net output #0: loss = 0.0753469 (* 1 = 0.0753469 loss)
I0309 06:22:37.147231  1118 sgd_solver.cpp:106] Iteration 15600, lr = 1e-05
I0309 06:23:16.786279  1118 solver.cpp:229] Iteration 15650, loss = 0.0480324
I0309 06:23:16.786473  1118 solver.cpp:245]     Train net output #0: loss = 0.0480322 (* 1 = 0.0480322 loss)
I0309 06:23:16.786505  1118 sgd_solver.cpp:106] Iteration 15650, lr = 1e-05
I0309 06:23:56.442288  1118 solver.cpp:229] Iteration 15700, loss = 0.0396756
I0309 06:23:56.442494  1118 solver.cpp:245]     Train net output #0: loss = 0.0396754 (* 1 = 0.0396754 loss)
I0309 06:23:56.442528  1118 sgd_solver.cpp:106] Iteration 15700, lr = 1e-05
I0309 06:24:36.090804  1118 solver.cpp:229] Iteration 15750, loss = 0.0763919
I0309 06:24:36.091001  1118 solver.cpp:245]     Train net output #0: loss = 0.0763917 (* 1 = 0.0763917 loss)
I0309 06:24:36.091033  1118 sgd_solver.cpp:106] Iteration 15750, lr = 1e-05
I0309 06:25:15.737696  1118 solver.cpp:229] Iteration 15800, loss = 0.0448189
I0309 06:25:15.737920  1118 solver.cpp:245]     Train net output #0: loss = 0.0448187 (* 1 = 0.0448187 loss)
I0309 06:25:15.737953  1118 sgd_solver.cpp:106] Iteration 15800, lr = 1e-05
I0309 06:25:55.387286  1118 solver.cpp:229] Iteration 15850, loss = 0.0397302
I0309 06:25:55.387491  1118 solver.cpp:245]     Train net output #0: loss = 0.0397301 (* 1 = 0.0397301 loss)
I0309 06:25:55.387524  1118 sgd_solver.cpp:106] Iteration 15850, lr = 1e-05
I0309 06:26:34.252799  1118 solver.cpp:338] Iteration 15900, Testing net (#0)
I0309 06:26:35.586125  1118 solver.cpp:406]     Test net output #0: accuracy = 0.96
I0309 06:26:35.586170  1118 solver.cpp:406]     Test net output #1: loss = 0.128153 (* 1 = 0.128153 loss)
I0309 06:26:36.196244  1118 solver.cpp:229] Iteration 15900, loss = 0.0499164
I0309 06:26:36.196290  1118 solver.cpp:245]     Train net output #0: loss = 0.0499163 (* 1 = 0.0499163 loss)
I0309 06:26:36.196316  1118 sgd_solver.cpp:106] Iteration 15900, lr = 1e-05
I0309 06:27:15.840579  1118 solver.cpp:229] Iteration 15950, loss = 0.0265176
I0309 06:27:15.840786  1118 solver.cpp:245]     Train net output #0: loss = 0.0265174 (* 1 = 0.0265174 loss)
I0309 06:27:15.840819  1118 sgd_solver.cpp:106] Iteration 15950, lr = 1e-05
I0309 06:27:54.705423  1118 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_16000.caffemodel
I0309 06:27:56.352298  1118 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_16000.solverstate
I0309 06:27:57.892395  1118 solver.cpp:229] Iteration 16000, loss = 0.0820018
I0309 06:27:57.892477  1118 solver.cpp:245]     Train net output #0: loss = 0.0820016 (* 1 = 0.0820016 loss)
I0309 06:27:57.892509  1118 sgd_solver.cpp:106] Iteration 16000, lr = 1e-05
I0309 06:28:37.533243  1118 solver.cpp:229] Iteration 16050, loss = 0.0457064
I0309 06:28:37.533469  1118 solver.cpp:245]     Train net output #0: loss = 0.0457062 (* 1 = 0.0457062 loss)
I0309 06:28:37.533502  1118 sgd_solver.cpp:106] Iteration 16050, lr = 1e-05
I0309 06:29:17.175412  1118 solver.cpp:229] Iteration 16100, loss = 0.0331059
I0309 06:29:17.175622  1118 solver.cpp:245]     Train net output #0: loss = 0.0331058 (* 1 = 0.0331058 loss)
I0309 06:29:17.175657  1118 sgd_solver.cpp:106] Iteration 16100, lr = 1e-05
I0309 06:29:56.814779  1118 solver.cpp:229] Iteration 16150, loss = 0.0609085
I0309 06:29:56.814976  1118 solver.cpp:245]     Train net output #0: loss = 0.0609084 (* 1 = 0.0609084 loss)
I0309 06:29:56.815009  1118 sgd_solver.cpp:106] Iteration 16150, lr = 1e-05
I0309 06:30:35.673105  1118 solver.cpp:338] Iteration 16200, Testing net (#0)
I0309 06:30:37.006348  1118 solver.cpp:406]     Test net output #0: accuracy = 0.962
I0309 06:30:37.006394  1118 solver.cpp:406]     Test net output #1: loss = 0.128234 (* 1 = 0.128234 loss)
I0309 06:30:37.618011  1118 solver.cpp:229] Iteration 16200, loss = 0.0365503
I0309 06:30:37.618055  1118 solver.cpp:245]     Train net output #0: loss = 0.0365502 (* 1 = 0.0365502 loss)
I0309 06:30:37.618083  1118 sgd_solver.cpp:106] Iteration 16200, lr = 1e-05
I0309 06:31:17.274176  1118 solver.cpp:229] Iteration 16250, loss = 0.0560478
I0309 06:31:17.274370  1118 solver.cpp:245]     Train net output #0: loss = 0.0560476 (* 1 = 0.0560476 loss)
I0309 06:31:17.274404  1118 sgd_solver.cpp:106] Iteration 16250, lr = 1e-05
I0309 06:31:56.924999  1118 solver.cpp:229] Iteration 16300, loss = 0.0485383
I0309 06:31:56.925210  1118 solver.cpp:245]     Train net output #0: loss = 0.0485381 (* 1 = 0.0485381 loss)
I0309 06:31:56.925245  1118 sgd_solver.cpp:106] Iteration 16300, lr = 1e-05
I0309 06:32:36.574465  1118 solver.cpp:229] Iteration 16350, loss = 0.080085
I0309 06:32:36.574656  1118 solver.cpp:245]     Train net output #0: loss = 0.0800849 (* 1 = 0.0800849 loss)
I0309 06:32:36.574689  1118 sgd_solver.cpp:106] Iteration 16350, lr = 1e-05
I0309 06:33:16.222033  1118 solver.cpp:229] Iteration 16400, loss = 0.0271566
I0309 06:33:16.222242  1118 solver.cpp:245]     Train net output #0: loss = 0.0271565 (* 1 = 0.0271565 loss)
I0309 06:33:16.222275  1118 sgd_solver.cpp:106] Iteration 16400, lr = 1e-05
I0309 06:33:55.863163  1118 solver.cpp:229] Iteration 16450, loss = 0.0405661
I0309 06:33:55.863447  1118 solver.cpp:245]     Train net output #0: loss = 0.040566 (* 1 = 0.040566 loss)
I0309 06:33:55.863481  1118 sgd_solver.cpp:106] Iteration 16450, lr = 1e-05
I0309 06:34:34.716166  1118 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_16500.caffemodel
I0309 06:34:36.359894  1118 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_16500.solverstate
I0309 06:34:37.295511  1118 solver.cpp:338] Iteration 16500, Testing net (#0)
I0309 06:34:38.455173  1118 solver.cpp:406]     Test net output #0: accuracy = 0.962
I0309 06:34:38.455230  1118 solver.cpp:406]     Test net output #1: loss = 0.129048 (* 1 = 0.129048 loss)
I0309 06:34:39.067359  1118 solver.cpp:229] Iteration 16500, loss = 0.013527
I0309 06:34:39.067404  1118 solver.cpp:245]     Train net output #0: loss = 0.0135269 (* 1 = 0.0135269 loss)
I0309 06:34:39.067432  1118 sgd_solver.cpp:106] Iteration 16500, lr = 1e-05
I0309 06:35:18.702178  1118 solver.cpp:229] Iteration 16550, loss = 0.0345064
I0309 06:35:18.702407  1118 solver.cpp:245]     Train net output #0: loss = 0.0345063 (* 1 = 0.0345063 loss)
I0309 06:35:18.702440  1118 sgd_solver.cpp:106] Iteration 16550, lr = 1e-05
I0309 06:35:58.347851  1118 solver.cpp:229] Iteration 16600, loss = 0.0936912
I0309 06:35:58.348055  1118 solver.cpp:245]     Train net output #0: loss = 0.093691 (* 1 = 0.093691 loss)
I0309 06:35:58.348088  1118 sgd_solver.cpp:106] Iteration 16600, lr = 1e-05
I0309 06:36:37.987854  1118 solver.cpp:229] Iteration 16650, loss = 0.0600839
I0309 06:36:37.988054  1118 solver.cpp:245]     Train net output #0: loss = 0.0600838 (* 1 = 0.0600838 loss)
I0309 06:36:37.988088  1118 sgd_solver.cpp:106] Iteration 16650, lr = 1e-05
I0309 06:37:17.633092  1118 solver.cpp:229] Iteration 16700, loss = 0.0458149
I0309 06:37:17.633297  1118 solver.cpp:245]     Train net output #0: loss = 0.0458147 (* 1 = 0.0458147 loss)
I0309 06:37:17.633330  1118 sgd_solver.cpp:106] Iteration 16700, lr = 1e-05
I0309 06:37:57.274785  1118 solver.cpp:229] Iteration 16750, loss = 0.0504178
I0309 06:37:57.274992  1118 solver.cpp:245]     Train net output #0: loss = 0.0504176 (* 1 = 0.0504176 loss)
I0309 06:37:57.275025  1118 sgd_solver.cpp:106] Iteration 16750, lr = 1e-05
I0309 06:38:36.137763  1118 solver.cpp:338] Iteration 16800, Testing net (#0)
I0309 06:38:37.471557  1118 solver.cpp:406]     Test net output #0: accuracy = 0.96
I0309 06:38:37.471601  1118 solver.cpp:406]     Test net output #1: loss = 0.129137 (* 1 = 0.129137 loss)
I0309 06:38:38.084087  1118 solver.cpp:229] Iteration 16800, loss = 0.0313386
I0309 06:38:38.084131  1118 solver.cpp:245]     Train net output #0: loss = 0.0313384 (* 1 = 0.0313384 loss)
I0309 06:38:38.084157  1118 sgd_solver.cpp:106] Iteration 16800, lr = 1e-05
I0309 06:39:17.734680  1118 solver.cpp:229] Iteration 16850, loss = 0.132595
I0309 06:39:17.734882  1118 solver.cpp:245]     Train net output #0: loss = 0.132595 (* 1 = 0.132595 loss)
I0309 06:39:17.734915  1118 sgd_solver.cpp:106] Iteration 16850, lr = 1e-05
I0309 06:39:57.380558  1118 solver.cpp:229] Iteration 16900, loss = 0.0605604
I0309 06:39:57.380758  1118 solver.cpp:245]     Train net output #0: loss = 0.0605602 (* 1 = 0.0605602 loss)
I0309 06:39:57.380790  1118 sgd_solver.cpp:106] Iteration 16900, lr = 1e-05
I0309 06:40:37.031765  1118 solver.cpp:229] Iteration 16950, loss = 0.0459501
I0309 06:40:37.032109  1118 solver.cpp:245]     Train net output #0: loss = 0.0459499 (* 1 = 0.0459499 loss)
I0309 06:40:37.032145  1118 sgd_solver.cpp:106] Iteration 16950, lr = 1e-05
I0309 06:41:15.899554  1118 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_17000.caffemodel
I0309 06:41:17.540767  1118 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_17000.solverstate
I0309 06:41:19.078297  1118 solver.cpp:229] Iteration 17000, loss = 0.117477
I0309 06:41:19.078462  1118 solver.cpp:245]     Train net output #0: loss = 0.117477 (* 1 = 0.117477 loss)
I0309 06:41:19.078495  1118 sgd_solver.cpp:106] Iteration 17000, lr = 1e-05
I0309 06:41:58.716519  1118 solver.cpp:229] Iteration 17050, loss = 0.0583693
I0309 06:41:58.716871  1118 solver.cpp:245]     Train net output #0: loss = 0.0583691 (* 1 = 0.0583691 loss)
I0309 06:41:58.716908  1118 sgd_solver.cpp:106] Iteration 17050, lr = 1e-05
I0309 06:42:37.575554  1118 solver.cpp:338] Iteration 17100, Testing net (#0)
I0309 06:42:38.908710  1118 solver.cpp:406]     Test net output #0: accuracy = 0.962
I0309 06:42:38.908766  1118 solver.cpp:406]     Test net output #1: loss = 0.126407 (* 1 = 0.126407 loss)
I0309 06:42:39.519979  1118 solver.cpp:229] Iteration 17100, loss = 0.0577046
I0309 06:42:39.520136  1118 solver.cpp:245]     Train net output #0: loss = 0.0577044 (* 1 = 0.0577044 loss)
I0309 06:42:39.520169  1118 sgd_solver.cpp:106] Iteration 17100, lr = 1e-05
I0309 06:43:19.174753  1118 solver.cpp:229] Iteration 17150, loss = 0.034544
I0309 06:43:19.175107  1118 solver.cpp:245]     Train net output #0: loss = 0.0345438 (* 1 = 0.0345438 loss)
I0309 06:43:19.175143  1118 sgd_solver.cpp:106] Iteration 17150, lr = 1e-05
I0309 06:43:58.826165  1118 solver.cpp:229] Iteration 17200, loss = 0.0881977
I0309 06:43:58.826521  1118 solver.cpp:245]     Train net output #0: loss = 0.0881975 (* 1 = 0.0881975 loss)
I0309 06:43:58.826563  1118 sgd_solver.cpp:106] Iteration 17200, lr = 1e-05
I0309 06:44:38.477505  1118 solver.cpp:229] Iteration 17250, loss = 0.0457875
I0309 06:44:38.477843  1118 solver.cpp:245]     Train net output #0: loss = 0.0457873 (* 1 = 0.0457873 loss)
I0309 06:44:38.477879  1118 sgd_solver.cpp:106] Iteration 17250, lr = 1e-05
I0309 06:45:18.130257  1118 solver.cpp:229] Iteration 17300, loss = 0.084973
I0309 06:45:18.130631  1118 solver.cpp:245]     Train net output #0: loss = 0.0849728 (* 1 = 0.0849728 loss)
I0309 06:45:18.130681  1118 sgd_solver.cpp:106] Iteration 17300, lr = 1e-05
I0309 06:45:57.788486  1118 solver.cpp:229] Iteration 17350, loss = 0.0958157
I0309 06:45:57.788833  1118 solver.cpp:245]     Train net output #0: loss = 0.0958155 (* 1 = 0.0958155 loss)
I0309 06:45:57.788871  1118 sgd_solver.cpp:106] Iteration 17350, lr = 1e-05
I0309 06:46:36.661341  1118 solver.cpp:338] Iteration 17400, Testing net (#0)
I0309 06:46:37.994405  1118 solver.cpp:406]     Test net output #0: accuracy = 0.96
I0309 06:46:37.994459  1118 solver.cpp:406]     Test net output #1: loss = 0.127718 (* 1 = 0.127718 loss)
I0309 06:46:38.607806  1118 solver.cpp:229] Iteration 17400, loss = 0.0640105
I0309 06:46:38.607959  1118 solver.cpp:245]     Train net output #0: loss = 0.0640104 (* 1 = 0.0640104 loss)
I0309 06:46:38.607990  1118 sgd_solver.cpp:106] Iteration 17400, lr = 1e-05
I0309 06:47:18.258790  1118 solver.cpp:229] Iteration 17450, loss = 0.0395508
I0309 06:47:18.259119  1118 solver.cpp:245]     Train net output #0: loss = 0.0395507 (* 1 = 0.0395507 loss)
I0309 06:47:18.259156  1118 sgd_solver.cpp:106] Iteration 17450, lr = 1e-05
I0309 06:47:57.122514  1118 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_17500.caffemodel
I0309 06:47:58.772948  1118 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_17500.solverstate
I0309 06:48:00.316278  1118 solver.cpp:229] Iteration 17500, loss = 0.0997579
I0309 06:48:00.316438  1118 solver.cpp:245]     Train net output #0: loss = 0.0997577 (* 1 = 0.0997577 loss)
I0309 06:48:00.316470  1118 sgd_solver.cpp:106] Iteration 17500, lr = 1e-05
I0309 06:48:39.961061  1118 solver.cpp:229] Iteration 17550, loss = 0.0603093
I0309 06:48:39.961434  1118 solver.cpp:245]     Train net output #0: loss = 0.0603091 (* 1 = 0.0603091 loss)
I0309 06:48:39.961472  1118 sgd_solver.cpp:106] Iteration 17550, lr = 1e-05
I0309 06:49:19.610960  1118 solver.cpp:229] Iteration 17600, loss = 0.0673423
I0309 06:49:19.611320  1118 solver.cpp:245]     Train net output #0: loss = 0.0673421 (* 1 = 0.0673421 loss)
I0309 06:49:19.611357  1118 sgd_solver.cpp:106] Iteration 17600, lr = 1e-05
I0309 06:49:59.265210  1118 solver.cpp:229] Iteration 17650, loss = 0.0227157
I0309 06:49:59.265555  1118 solver.cpp:245]     Train net output #0: loss = 0.0227155 (* 1 = 0.0227155 loss)
I0309 06:49:59.265593  1118 sgd_solver.cpp:106] Iteration 17650, lr = 1e-05
I0309 06:50:38.131045  1118 solver.cpp:338] Iteration 17700, Testing net (#0)
I0309 06:50:39.463754  1118 solver.cpp:406]     Test net output #0: accuracy = 0.958
I0309 06:50:39.463811  1118 solver.cpp:406]     Test net output #1: loss = 0.128237 (* 1 = 0.128237 loss)
I0309 06:50:40.077005  1118 solver.cpp:229] Iteration 17700, loss = 0.113738
I0309 06:50:40.077162  1118 solver.cpp:245]     Train net output #0: loss = 0.113738 (* 1 = 0.113738 loss)
I0309 06:50:40.077191  1118 sgd_solver.cpp:106] Iteration 17700, lr = 1e-05
I0309 06:51:19.746042  1118 solver.cpp:229] Iteration 17750, loss = 0.0444836
I0309 06:51:19.746356  1118 solver.cpp:245]     Train net output #0: loss = 0.0444834 (* 1 = 0.0444834 loss)
I0309 06:51:19.746389  1118 sgd_solver.cpp:106] Iteration 17750, lr = 1e-05
I0309 06:51:59.397414  1118 solver.cpp:229] Iteration 17800, loss = 0.0859465
I0309 06:51:59.397626  1118 solver.cpp:245]     Train net output #0: loss = 0.0859463 (* 1 = 0.0859463 loss)
I0309 06:51:59.397660  1118 sgd_solver.cpp:106] Iteration 17800, lr = 1e-05
I0309 06:52:39.056874  1118 solver.cpp:229] Iteration 17850, loss = 0.0256476
I0309 06:52:39.057076  1118 solver.cpp:245]     Train net output #0: loss = 0.0256474 (* 1 = 0.0256474 loss)
I0309 06:52:39.057109  1118 sgd_solver.cpp:106] Iteration 17850, lr = 1e-05
I0309 06:53:18.706312  1118 solver.cpp:229] Iteration 17900, loss = 0.0464173
I0309 06:53:18.706504  1118 solver.cpp:245]     Train net output #0: loss = 0.0464171 (* 1 = 0.0464171 loss)
I0309 06:53:18.706537  1118 sgd_solver.cpp:106] Iteration 17900, lr = 1e-05
I0309 06:53:58.356789  1118 solver.cpp:229] Iteration 17950, loss = 0.0224544
I0309 06:53:58.356992  1118 solver.cpp:245]     Train net output #0: loss = 0.0224542 (* 1 = 0.0224542 loss)
I0309 06:53:58.357025  1118 sgd_solver.cpp:106] Iteration 17950, lr = 1e-05
I0309 06:54:37.216809  1118 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_18000.caffemodel
I0309 06:54:38.863698  1118 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_18000.solverstate
I0309 06:54:39.800817  1118 solver.cpp:338] Iteration 18000, Testing net (#0)
I0309 06:54:40.960450  1118 solver.cpp:406]     Test net output #0: accuracy = 0.962
I0309 06:54:40.960506  1118 solver.cpp:406]     Test net output #1: loss = 0.128857 (* 1 = 0.128857 loss)
I0309 06:54:41.574434  1118 solver.cpp:229] Iteration 18000, loss = 0.0402826
I0309 06:54:41.574481  1118 solver.cpp:245]     Train net output #0: loss = 0.0402824 (* 1 = 0.0402824 loss)
I0309 06:54:41.574512  1118 sgd_solver.cpp:106] Iteration 18000, lr = 1e-05
I0309 06:55:21.222643  1118 solver.cpp:229] Iteration 18050, loss = 0.0435154
I0309 06:55:21.222863  1118 solver.cpp:245]     Train net output #0: loss = 0.0435153 (* 1 = 0.0435153 loss)
I0309 06:55:21.222897  1118 sgd_solver.cpp:106] Iteration 18050, lr = 1e-05
I0309 06:56:00.879441  1118 solver.cpp:229] Iteration 18100, loss = 0.0364489
I0309 06:56:00.879797  1118 solver.cpp:245]     Train net output #0: loss = 0.0364487 (* 1 = 0.0364487 loss)
I0309 06:56:00.879833  1118 sgd_solver.cpp:106] Iteration 18100, lr = 1e-05
I0309 06:56:40.521631  1118 solver.cpp:229] Iteration 18150, loss = 0.0801466
I0309 06:56:40.521857  1118 solver.cpp:245]     Train net output #0: loss = 0.0801464 (* 1 = 0.0801464 loss)
I0309 06:56:40.521889  1118 sgd_solver.cpp:106] Iteration 18150, lr = 1e-05
I0309 06:57:20.170123  1118 solver.cpp:229] Iteration 18200, loss = 0.0819631
I0309 06:57:20.170341  1118 solver.cpp:245]     Train net output #0: loss = 0.0819629 (* 1 = 0.0819629 loss)
I0309 06:57:20.170374  1118 sgd_solver.cpp:106] Iteration 18200, lr = 1e-05
I0309 06:57:59.821300  1118 solver.cpp:229] Iteration 18250, loss = 0.0227956
I0309 06:57:59.821506  1118 solver.cpp:245]     Train net output #0: loss = 0.0227954 (* 1 = 0.0227954 loss)
I0309 06:57:59.821537  1118 sgd_solver.cpp:106] Iteration 18250, lr = 1e-05
I0309 06:58:38.673336  1118 solver.cpp:338] Iteration 18300, Testing net (#0)
I0309 06:58:40.005985  1118 solver.cpp:406]     Test net output #0: accuracy = 0.958
I0309 06:58:40.006029  1118 solver.cpp:406]     Test net output #1: loss = 0.126019 (* 1 = 0.126019 loss)
I0309 06:58:40.619840  1118 solver.cpp:229] Iteration 18300, loss = 0.0241675
I0309 06:58:40.619884  1118 solver.cpp:245]     Train net output #0: loss = 0.0241673 (* 1 = 0.0241673 loss)
I0309 06:58:40.619910  1118 sgd_solver.cpp:106] Iteration 18300, lr = 1e-05
I0309 06:59:20.266788  1118 solver.cpp:229] Iteration 18350, loss = 0.0362066
I0309 06:59:20.266986  1118 solver.cpp:245]     Train net output #0: loss = 0.0362064 (* 1 = 0.0362064 loss)
I0309 06:59:20.267019  1118 sgd_solver.cpp:106] Iteration 18350, lr = 1e-05
I0309 06:59:59.910892  1118 solver.cpp:229] Iteration 18400, loss = 0.0419609
I0309 06:59:59.911087  1118 solver.cpp:245]     Train net output #0: loss = 0.0419607 (* 1 = 0.0419607 loss)
I0309 06:59:59.911120  1118 sgd_solver.cpp:106] Iteration 18400, lr = 1e-05
I0309 07:00:39.567822  1118 solver.cpp:229] Iteration 18450, loss = 0.0778831
I0309 07:00:39.568092  1118 solver.cpp:245]     Train net output #0: loss = 0.0778829 (* 1 = 0.0778829 loss)
I0309 07:00:39.568125  1118 sgd_solver.cpp:106] Iteration 18450, lr = 1e-05
I0309 07:01:18.428395  1118 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_18500.caffemodel
I0309 07:01:20.075664  1118 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_18500.solverstate
I0309 07:01:21.622639  1118 solver.cpp:229] Iteration 18500, loss = 0.0550467
I0309 07:01:21.622722  1118 solver.cpp:245]     Train net output #0: loss = 0.0550465 (* 1 = 0.0550465 loss)
I0309 07:01:21.622755  1118 sgd_solver.cpp:106] Iteration 18500, lr = 1e-05
I0309 07:02:01.281395  1118 solver.cpp:229] Iteration 18550, loss = 0.0423605
I0309 07:02:01.281625  1118 solver.cpp:245]     Train net output #0: loss = 0.0423603 (* 1 = 0.0423603 loss)
I0309 07:02:01.281658  1118 sgd_solver.cpp:106] Iteration 18550, lr = 1e-05
I0309 07:02:40.144107  1118 solver.cpp:338] Iteration 18600, Testing net (#0)
I0309 07:02:41.477080  1118 solver.cpp:406]     Test net output #0: accuracy = 0.958
I0309 07:02:41.477125  1118 solver.cpp:406]     Test net output #1: loss = 0.128501 (* 1 = 0.128501 loss)
I0309 07:02:42.088505  1118 solver.cpp:229] Iteration 18600, loss = 0.0275341
I0309 07:02:42.088554  1118 solver.cpp:245]     Train net output #0: loss = 0.0275339 (* 1 = 0.0275339 loss)
I0309 07:02:42.088582  1118 sgd_solver.cpp:106] Iteration 18600, lr = 1e-05
I0309 07:03:21.741235  1118 solver.cpp:229] Iteration 18650, loss = 0.0381047
I0309 07:03:21.741443  1118 solver.cpp:245]     Train net output #0: loss = 0.0381044 (* 1 = 0.0381044 loss)
I0309 07:03:21.741477  1118 sgd_solver.cpp:106] Iteration 18650, lr = 1e-05
I0309 07:04:01.388429  1118 solver.cpp:229] Iteration 18700, loss = 0.0798192
I0309 07:04:01.388633  1118 solver.cpp:245]     Train net output #0: loss = 0.0798189 (* 1 = 0.0798189 loss)
I0309 07:04:01.388667  1118 sgd_solver.cpp:106] Iteration 18700, lr = 1e-05
I0309 07:04:41.031764  1118 solver.cpp:229] Iteration 18750, loss = 0.075818
I0309 07:04:41.031986  1118 solver.cpp:245]     Train net output #0: loss = 0.0758178 (* 1 = 0.0758178 loss)
I0309 07:04:41.032019  1118 sgd_solver.cpp:106] Iteration 18750, lr = 1e-05
I0309 07:05:20.681535  1118 solver.cpp:229] Iteration 18800, loss = 0.0216876
I0309 07:05:20.681740  1118 solver.cpp:245]     Train net output #0: loss = 0.0216874 (* 1 = 0.0216874 loss)
I0309 07:05:20.681774  1118 sgd_solver.cpp:106] Iteration 18800, lr = 1e-05
I0309 07:06:00.334818  1118 solver.cpp:229] Iteration 18850, loss = 0.0474048
I0309 07:06:00.335018  1118 solver.cpp:245]     Train net output #0: loss = 0.0474045 (* 1 = 0.0474045 loss)
I0309 07:06:00.335052  1118 sgd_solver.cpp:106] Iteration 18850, lr = 1e-05
I0309 07:06:39.204738  1118 solver.cpp:338] Iteration 18900, Testing net (#0)
I0309 07:06:40.538430  1118 solver.cpp:406]     Test net output #0: accuracy = 0.958
I0309 07:06:40.538475  1118 solver.cpp:406]     Test net output #1: loss = 0.127512 (* 1 = 0.127512 loss)
I0309 07:06:41.150837  1118 solver.cpp:229] Iteration 18900, loss = 0.0584076
I0309 07:06:41.150882  1118 solver.cpp:245]     Train net output #0: loss = 0.0584074 (* 1 = 0.0584074 loss)
I0309 07:06:41.150907  1118 sgd_solver.cpp:106] Iteration 18900, lr = 1e-05
I0309 07:07:20.806145  1118 solver.cpp:229] Iteration 18950, loss = 0.0435599
I0309 07:07:20.806339  1118 solver.cpp:245]     Train net output #0: loss = 0.0435597 (* 1 = 0.0435597 loss)
I0309 07:07:20.806371  1118 sgd_solver.cpp:106] Iteration 18950, lr = 1e-05
I0309 07:07:59.664602  1118 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_19000.caffemodel
I0309 07:08:01.309494  1118 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_19000.solverstate
I0309 07:08:02.858537  1118 solver.cpp:229] Iteration 19000, loss = 0.0369572
I0309 07:08:02.858619  1118 solver.cpp:245]     Train net output #0: loss = 0.036957 (* 1 = 0.036957 loss)
I0309 07:08:02.858650  1118 sgd_solver.cpp:106] Iteration 19000, lr = 1e-05
I0309 07:08:42.510965  1118 solver.cpp:229] Iteration 19050, loss = 0.0418125
I0309 07:08:42.511174  1118 solver.cpp:245]     Train net output #0: loss = 0.0418123 (* 1 = 0.0418123 loss)
I0309 07:08:42.511207  1118 sgd_solver.cpp:106] Iteration 19050, lr = 1e-05
I0309 07:09:22.157265  1118 solver.cpp:229] Iteration 19100, loss = 0.0258521
I0309 07:09:22.157472  1118 solver.cpp:245]     Train net output #0: loss = 0.025852 (* 1 = 0.025852 loss)
I0309 07:09:22.157506  1118 sgd_solver.cpp:106] Iteration 19100, lr = 1e-05
I0309 07:10:01.803165  1118 solver.cpp:229] Iteration 19150, loss = 0.0470904
I0309 07:10:01.803375  1118 solver.cpp:245]     Train net output #0: loss = 0.0470903 (* 1 = 0.0470903 loss)
I0309 07:10:01.803407  1118 sgd_solver.cpp:106] Iteration 19150, lr = 1e-05
I0309 07:10:40.668157  1118 solver.cpp:338] Iteration 19200, Testing net (#0)
I0309 07:10:42.001173  1118 solver.cpp:406]     Test net output #0: accuracy = 0.962
I0309 07:10:42.001219  1118 solver.cpp:406]     Test net output #1: loss = 0.1264 (* 1 = 0.1264 loss)
I0309 07:10:42.613448  1118 solver.cpp:229] Iteration 19200, loss = 0.0917053
I0309 07:10:42.613492  1118 solver.cpp:245]     Train net output #0: loss = 0.0917051 (* 1 = 0.0917051 loss)
I0309 07:10:42.613518  1118 sgd_solver.cpp:106] Iteration 19200, lr = 1e-05
I0309 07:11:22.251502  1118 solver.cpp:229] Iteration 19250, loss = 0.0578215
I0309 07:11:22.251708  1118 solver.cpp:245]     Train net output #0: loss = 0.0578213 (* 1 = 0.0578213 loss)
I0309 07:11:22.251741  1118 sgd_solver.cpp:106] Iteration 19250, lr = 1e-05
I0309 07:12:01.888747  1118 solver.cpp:229] Iteration 19300, loss = 0.0705895
I0309 07:12:01.888945  1118 solver.cpp:245]     Train net output #0: loss = 0.0705893 (* 1 = 0.0705893 loss)
I0309 07:12:01.888978  1118 sgd_solver.cpp:106] Iteration 19300, lr = 1e-05
I0309 07:12:41.532353  1118 solver.cpp:229] Iteration 19350, loss = 0.0330316
I0309 07:12:41.532574  1118 solver.cpp:245]     Train net output #0: loss = 0.0330315 (* 1 = 0.0330315 loss)
I0309 07:12:41.532621  1118 sgd_solver.cpp:106] Iteration 19350, lr = 1e-05
I0309 07:13:21.184314  1118 solver.cpp:229] Iteration 19400, loss = 0.0832575
I0309 07:13:21.184528  1118 solver.cpp:245]     Train net output #0: loss = 0.0832573 (* 1 = 0.0832573 loss)
I0309 07:13:21.184566  1118 sgd_solver.cpp:106] Iteration 19400, lr = 1e-05
I0309 07:14:00.823873  1118 solver.cpp:229] Iteration 19450, loss = 0.0313908
I0309 07:14:00.824066  1118 solver.cpp:245]     Train net output #0: loss = 0.0313907 (* 1 = 0.0313907 loss)
I0309 07:14:00.824100  1118 sgd_solver.cpp:106] Iteration 19450, lr = 1e-05
I0309 07:14:39.668263  1118 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_19500.caffemodel
I0309 07:14:41.310916  1118 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_19500.solverstate
I0309 07:14:42.245270  1118 solver.cpp:338] Iteration 19500, Testing net (#0)
I0309 07:14:43.405067  1118 solver.cpp:406]     Test net output #0: accuracy = 0.96
I0309 07:14:43.405123  1118 solver.cpp:406]     Test net output #1: loss = 0.12667 (* 1 = 0.12667 loss)
I0309 07:14:44.016396  1118 solver.cpp:229] Iteration 19500, loss = 0.0492813
I0309 07:14:44.016439  1118 solver.cpp:245]     Train net output #0: loss = 0.0492811 (* 1 = 0.0492811 loss)
I0309 07:14:44.016469  1118 sgd_solver.cpp:106] Iteration 19500, lr = 1e-05
I0309 07:15:23.656245  1118 solver.cpp:229] Iteration 19550, loss = 0.0325874
I0309 07:15:23.656519  1118 solver.cpp:245]     Train net output #0: loss = 0.0325872 (* 1 = 0.0325872 loss)
I0309 07:15:23.656558  1118 sgd_solver.cpp:106] Iteration 19550, lr = 1e-05
I0309 07:16:03.296943  1118 solver.cpp:229] Iteration 19600, loss = 0.0934347
I0309 07:16:03.297159  1118 solver.cpp:245]     Train net output #0: loss = 0.0934346 (* 1 = 0.0934346 loss)
I0309 07:16:03.297194  1118 sgd_solver.cpp:106] Iteration 19600, lr = 1e-05
I0309 07:16:42.940711  1118 solver.cpp:229] Iteration 19650, loss = 0.0339954
I0309 07:16:42.940915  1118 solver.cpp:245]     Train net output #0: loss = 0.0339953 (* 1 = 0.0339953 loss)
I0309 07:16:42.940949  1118 sgd_solver.cpp:106] Iteration 19650, lr = 1e-05
I0309 07:17:22.591786  1118 solver.cpp:229] Iteration 19700, loss = 0.0691003
I0309 07:17:22.591977  1118 solver.cpp:245]     Train net output #0: loss = 0.0691002 (* 1 = 0.0691002 loss)
I0309 07:17:22.592011  1118 sgd_solver.cpp:106] Iteration 19700, lr = 1e-05
I0309 07:18:02.241070  1118 solver.cpp:229] Iteration 19750, loss = 0.0558763
I0309 07:18:02.241256  1118 solver.cpp:245]     Train net output #0: loss = 0.0558762 (* 1 = 0.0558762 loss)
I0309 07:18:02.241291  1118 sgd_solver.cpp:106] Iteration 19750, lr = 1e-05
I0309 07:18:41.082494  1118 solver.cpp:338] Iteration 19800, Testing net (#0)
I0309 07:18:42.416689  1118 solver.cpp:406]     Test net output #0: accuracy = 0.962
I0309 07:18:42.416734  1118 solver.cpp:406]     Test net output #1: loss = 0.126535 (* 1 = 0.126535 loss)
I0309 07:18:43.028359  1118 solver.cpp:229] Iteration 19800, loss = 0.0685079
I0309 07:18:43.028403  1118 solver.cpp:245]     Train net output #0: loss = 0.0685077 (* 1 = 0.0685077 loss)
I0309 07:18:43.028429  1118 sgd_solver.cpp:106] Iteration 19800, lr = 1e-05
I0309 07:19:22.662089  1118 solver.cpp:229] Iteration 19850, loss = 0.0936867
I0309 07:19:22.662281  1118 solver.cpp:245]     Train net output #0: loss = 0.0936866 (* 1 = 0.0936866 loss)
I0309 07:19:22.662313  1118 sgd_solver.cpp:106] Iteration 19850, lr = 1e-05
I0309 07:20:02.312963  1118 solver.cpp:229] Iteration 19900, loss = 0.0403759
I0309 07:20:02.313170  1118 solver.cpp:245]     Train net output #0: loss = 0.0403758 (* 1 = 0.0403758 loss)
I0309 07:20:02.313204  1118 sgd_solver.cpp:106] Iteration 19900, lr = 1e-05
I0309 07:20:41.965227  1118 solver.cpp:229] Iteration 19950, loss = 0.0913618
I0309 07:20:41.965447  1118 solver.cpp:245]     Train net output #0: loss = 0.0913617 (* 1 = 0.0913617 loss)
I0309 07:20:41.965494  1118 sgd_solver.cpp:106] Iteration 19950, lr = 1e-05
I0309 07:21:20.819442  1118 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_20000.caffemodel
I0309 07:21:22.627887  1118 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_20000.solverstate
I0309 07:21:24.176558  1118 solver.cpp:229] Iteration 20000, loss = 0.0217079
I0309 07:21:24.176646  1118 solver.cpp:245]     Train net output #0: loss = 0.0217077 (* 1 = 0.0217077 loss)
I0309 07:21:24.176678  1118 sgd_solver.cpp:106] Iteration 20000, lr = 1e-06
I0309 07:22:03.812804  1118 solver.cpp:229] Iteration 20050, loss = 0.0313374
I0309 07:22:03.813030  1118 solver.cpp:245]     Train net output #0: loss = 0.0313373 (* 1 = 0.0313373 loss)
I0309 07:22:03.813062  1118 sgd_solver.cpp:106] Iteration 20050, lr = 1e-06
I0309 07:22:42.668035  1118 solver.cpp:338] Iteration 20100, Testing net (#0)
I0309 07:22:44.001497  1118 solver.cpp:406]     Test net output #0: accuracy = 0.96
I0309 07:22:44.001548  1118 solver.cpp:406]     Test net output #1: loss = 0.126838 (* 1 = 0.126838 loss)
I0309 07:22:44.613384  1118 solver.cpp:229] Iteration 20100, loss = 0.122876
I0309 07:22:44.613427  1118 solver.cpp:245]     Train net output #0: loss = 0.122876 (* 1 = 0.122876 loss)
I0309 07:22:44.613453  1118 sgd_solver.cpp:106] Iteration 20100, lr = 1e-06
I0309 07:23:24.259322  1118 solver.cpp:229] Iteration 20150, loss = 0.0363789
I0309 07:23:24.259519  1118 solver.cpp:245]     Train net output #0: loss = 0.0363787 (* 1 = 0.0363787 loss)
I0309 07:23:24.259558  1118 sgd_solver.cpp:106] Iteration 20150, lr = 1e-06
I0309 07:24:03.896962  1118 solver.cpp:229] Iteration 20200, loss = 0.0783123
I0309 07:24:03.897160  1118 solver.cpp:245]     Train net output #0: loss = 0.0783121 (* 1 = 0.0783121 loss)
I0309 07:24:03.897192  1118 sgd_solver.cpp:106] Iteration 20200, lr = 1e-06
I0309 07:24:43.536387  1118 solver.cpp:229] Iteration 20250, loss = 0.0350166
I0309 07:24:43.536593  1118 solver.cpp:245]     Train net output #0: loss = 0.0350165 (* 1 = 0.0350165 loss)
I0309 07:24:43.536626  1118 sgd_solver.cpp:106] Iteration 20250, lr = 1e-06
I0309 07:25:23.182490  1118 solver.cpp:229] Iteration 20300, loss = 0.0381821
I0309 07:25:23.182710  1118 solver.cpp:245]     Train net output #0: loss = 0.038182 (* 1 = 0.038182 loss)
I0309 07:25:23.182744  1118 sgd_solver.cpp:106] Iteration 20300, lr = 1e-06
I0309 07:26:02.827215  1118 solver.cpp:229] Iteration 20350, loss = 0.0109398
I0309 07:26:02.827414  1118 solver.cpp:245]     Train net output #0: loss = 0.0109396 (* 1 = 0.0109396 loss)
I0309 07:26:02.827447  1118 sgd_solver.cpp:106] Iteration 20350, lr = 1e-06
I0309 07:26:41.687958  1118 solver.cpp:338] Iteration 20400, Testing net (#0)
I0309 07:26:43.021523  1118 solver.cpp:406]     Test net output #0: accuracy = 0.96
I0309 07:26:43.021582  1118 solver.cpp:406]     Test net output #1: loss = 0.126849 (* 1 = 0.126849 loss)
I0309 07:26:43.635244  1118 solver.cpp:229] Iteration 20400, loss = 0.0273303
I0309 07:26:43.635289  1118 solver.cpp:245]     Train net output #0: loss = 0.0273301 (* 1 = 0.0273301 loss)
I0309 07:26:43.635315  1118 sgd_solver.cpp:106] Iteration 20400, lr = 1e-06
I0309 07:27:23.292637  1118 solver.cpp:229] Iteration 20450, loss = 0.042118
I0309 07:27:23.292845  1118 solver.cpp:245]     Train net output #0: loss = 0.0421178 (* 1 = 0.0421178 loss)
I0309 07:27:23.292878  1118 sgd_solver.cpp:106] Iteration 20450, lr = 1e-06
I0309 07:28:02.154196  1118 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_20500.caffemodel
I0309 07:28:03.802186  1118 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_20500.solverstate
I0309 07:28:05.353787  1118 solver.cpp:229] Iteration 20500, loss = 0.0498858
I0309 07:28:05.353884  1118 solver.cpp:245]     Train net output #0: loss = 0.0498857 (* 1 = 0.0498857 loss)
I0309 07:28:05.353917  1118 sgd_solver.cpp:106] Iteration 20500, lr = 1e-06
I0309 07:28:45.001850  1118 solver.cpp:229] Iteration 20550, loss = 0.036221
I0309 07:28:45.002084  1118 solver.cpp:245]     Train net output #0: loss = 0.0362208 (* 1 = 0.0362208 loss)
I0309 07:28:45.002118  1118 sgd_solver.cpp:106] Iteration 20550, lr = 1e-06
I0309 07:29:24.642151  1118 solver.cpp:229] Iteration 20600, loss = 0.124351
I0309 07:29:24.642362  1118 solver.cpp:245]     Train net output #0: loss = 0.124351 (* 1 = 0.124351 loss)
I0309 07:29:24.642395  1118 sgd_solver.cpp:106] Iteration 20600, lr = 1e-06
I0309 07:30:04.284495  1118 solver.cpp:229] Iteration 20650, loss = 0.0114114
I0309 07:30:04.284718  1118 solver.cpp:245]     Train net output #0: loss = 0.0114112 (* 1 = 0.0114112 loss)
I0309 07:30:04.284752  1118 sgd_solver.cpp:106] Iteration 20650, lr = 1e-06
I0309 07:30:43.149893  1118 solver.cpp:338] Iteration 20700, Testing net (#0)
I0309 07:30:44.482507  1118 solver.cpp:406]     Test net output #0: accuracy = 0.96
I0309 07:30:44.482556  1118 solver.cpp:406]     Test net output #1: loss = 0.126828 (* 1 = 0.126828 loss)
I0309 07:30:45.095717  1118 solver.cpp:229] Iteration 20700, loss = 0.0365876
I0309 07:30:45.095762  1118 solver.cpp:245]     Train net output #0: loss = 0.0365875 (* 1 = 0.0365875 loss)
I0309 07:30:45.095788  1118 sgd_solver.cpp:106] Iteration 20700, lr = 1e-06
I0309 07:31:24.741021  1118 solver.cpp:229] Iteration 20750, loss = 0.0495434
I0309 07:31:24.741235  1118 solver.cpp:245]     Train net output #0: loss = 0.0495433 (* 1 = 0.0495433 loss)
I0309 07:31:24.741268  1118 sgd_solver.cpp:106] Iteration 20750, lr = 1e-06
I0309 07:32:04.390311  1118 solver.cpp:229] Iteration 20800, loss = 0.024949
I0309 07:32:04.390518  1118 solver.cpp:245]     Train net output #0: loss = 0.0249489 (* 1 = 0.0249489 loss)
I0309 07:32:04.390558  1118 sgd_solver.cpp:106] Iteration 20800, lr = 1e-06
I0309 07:32:44.043107  1118 solver.cpp:229] Iteration 20850, loss = 0.0489808
I0309 07:32:44.043311  1118 solver.cpp:245]     Train net output #0: loss = 0.0489806 (* 1 = 0.0489806 loss)
I0309 07:32:44.043344  1118 sgd_solver.cpp:106] Iteration 20850, lr = 1e-06
I0309 07:33:23.693260  1118 solver.cpp:229] Iteration 20900, loss = 0.0450359
I0309 07:33:23.693560  1118 solver.cpp:245]     Train net output #0: loss = 0.0450358 (* 1 = 0.0450358 loss)
I0309 07:33:23.693594  1118 sgd_solver.cpp:106] Iteration 20900, lr = 1e-06
I0309 07:34:03.340112  1118 solver.cpp:229] Iteration 20950, loss = 0.0415576
I0309 07:34:03.340320  1118 solver.cpp:245]     Train net output #0: loss = 0.0415574 (* 1 = 0.0415574 loss)
I0309 07:34:03.340354  1118 sgd_solver.cpp:106] Iteration 20950, lr = 1e-06
I0309 07:34:42.211737  1118 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_21000.caffemodel
I0309 07:34:43.860494  1118 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_21000.solverstate
I0309 07:34:44.803508  1118 solver.cpp:338] Iteration 21000, Testing net (#0)
I0309 07:34:45.963093  1118 solver.cpp:406]     Test net output #0: accuracy = 0.96
I0309 07:34:45.963148  1118 solver.cpp:406]     Test net output #1: loss = 0.126693 (* 1 = 0.126693 loss)
I0309 07:34:46.575655  1118 solver.cpp:229] Iteration 21000, loss = 0.0369542
I0309 07:34:46.575700  1118 solver.cpp:245]     Train net output #0: loss = 0.036954 (* 1 = 0.036954 loss)
I0309 07:34:46.575731  1118 sgd_solver.cpp:106] Iteration 21000, lr = 1e-06
I0309 07:35:26.221868  1118 solver.cpp:229] Iteration 21050, loss = 0.0459133
I0309 07:35:26.222093  1118 solver.cpp:245]     Train net output #0: loss = 0.0459132 (* 1 = 0.0459132 loss)
I0309 07:35:26.222126  1118 sgd_solver.cpp:106] Iteration 21050, lr = 1e-06
I0309 07:36:05.875248  1118 solver.cpp:229] Iteration 21100, loss = 0.0628305
I0309 07:36:05.875473  1118 solver.cpp:245]     Train net output #0: loss = 0.0628304 (* 1 = 0.0628304 loss)
I0309 07:36:05.875517  1118 sgd_solver.cpp:106] Iteration 21100, lr = 1e-06
I0309 07:36:45.524492  1118 solver.cpp:229] Iteration 21150, loss = 0.0953116
I0309 07:36:45.524710  1118 solver.cpp:245]     Train net output #0: loss = 0.0953115 (* 1 = 0.0953115 loss)
I0309 07:36:45.524744  1118 sgd_solver.cpp:106] Iteration 21150, lr = 1e-06
I0309 07:37:25.167515  1118 solver.cpp:229] Iteration 21200, loss = 0.0676436
I0309 07:37:25.167737  1118 solver.cpp:245]     Train net output #0: loss = 0.0676434 (* 1 = 0.0676434 loss)
I0309 07:37:25.167770  1118 sgd_solver.cpp:106] Iteration 21200, lr = 1e-06
I0309 07:38:04.803149  1118 solver.cpp:229] Iteration 21250, loss = 0.0770099
I0309 07:38:04.803342  1118 solver.cpp:245]     Train net output #0: loss = 0.0770097 (* 1 = 0.0770097 loss)
I0309 07:38:04.803375  1118 sgd_solver.cpp:106] Iteration 21250, lr = 1e-06
I0309 07:38:43.673907  1118 solver.cpp:338] Iteration 21300, Testing net (#0)
I0309 07:38:45.007688  1118 solver.cpp:406]     Test net output #0: accuracy = 0.96
I0309 07:38:45.007731  1118 solver.cpp:406]     Test net output #1: loss = 0.126692 (* 1 = 0.126692 loss)
I0309 07:38:45.620064  1118 solver.cpp:229] Iteration 21300, loss = 0.0316719
I0309 07:38:45.620106  1118 solver.cpp:245]     Train net output #0: loss = 0.0316717 (* 1 = 0.0316717 loss)
I0309 07:38:45.620132  1118 sgd_solver.cpp:106] Iteration 21300, lr = 1e-06
I0309 07:39:25.273044  1118 solver.cpp:229] Iteration 21350, loss = 0.0508825
I0309 07:39:25.273375  1118 solver.cpp:245]     Train net output #0: loss = 0.0508823 (* 1 = 0.0508823 loss)
I0309 07:39:25.273411  1118 sgd_solver.cpp:106] Iteration 21350, lr = 1e-06
I0309 07:40:04.914530  1118 solver.cpp:229] Iteration 21400, loss = 0.0501956
I0309 07:40:04.914746  1118 solver.cpp:245]     Train net output #0: loss = 0.0501954 (* 1 = 0.0501954 loss)
I0309 07:40:04.914779  1118 sgd_solver.cpp:106] Iteration 21400, lr = 1e-06
I0309 07:40:44.555922  1118 solver.cpp:229] Iteration 21450, loss = 0.0742983
I0309 07:40:44.556118  1118 solver.cpp:245]     Train net output #0: loss = 0.0742982 (* 1 = 0.0742982 loss)
I0309 07:40:44.556151  1118 sgd_solver.cpp:106] Iteration 21450, lr = 1e-06
I0309 07:41:23.419100  1118 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_21500.caffemodel
I0309 07:41:25.063036  1118 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_21500.solverstate
I0309 07:41:26.604513  1118 solver.cpp:229] Iteration 21500, loss = 0.0297926
I0309 07:41:26.604598  1118 solver.cpp:245]     Train net output #0: loss = 0.0297924 (* 1 = 0.0297924 loss)
I0309 07:41:26.604629  1118 sgd_solver.cpp:106] Iteration 21500, lr = 1e-06
I0309 07:42:06.255630  1118 solver.cpp:229] Iteration 21550, loss = 0.0824308
I0309 07:42:06.255849  1118 solver.cpp:245]     Train net output #0: loss = 0.0824307 (* 1 = 0.0824307 loss)
I0309 07:42:06.255882  1118 sgd_solver.cpp:106] Iteration 21550, lr = 1e-06
I0309 07:42:45.113562  1118 solver.cpp:338] Iteration 21600, Testing net (#0)
I0309 07:42:46.447294  1118 solver.cpp:406]     Test net output #0: accuracy = 0.96
I0309 07:42:46.447340  1118 solver.cpp:406]     Test net output #1: loss = 0.126742 (* 1 = 0.126742 loss)
I0309 07:42:47.059993  1118 solver.cpp:229] Iteration 21600, loss = 0.0303223
I0309 07:42:47.060036  1118 solver.cpp:245]     Train net output #0: loss = 0.0303221 (* 1 = 0.0303221 loss)
I0309 07:42:47.060062  1118 sgd_solver.cpp:106] Iteration 21600, lr = 1e-06
I0309 07:43:26.694974  1118 solver.cpp:229] Iteration 21650, loss = 0.0808
I0309 07:43:26.695132  1118 solver.cpp:245]     Train net output #0: loss = 0.0807998 (* 1 = 0.0807998 loss)
I0309 07:43:26.695165  1118 sgd_solver.cpp:106] Iteration 21650, lr = 1e-06
I0309 07:44:06.334628  1118 solver.cpp:229] Iteration 21700, loss = 0.0346206
I0309 07:44:06.334851  1118 solver.cpp:245]     Train net output #0: loss = 0.0346204 (* 1 = 0.0346204 loss)
I0309 07:44:06.334897  1118 sgd_solver.cpp:106] Iteration 21700, lr = 1e-06
I0309 07:44:45.977708  1118 solver.cpp:229] Iteration 21750, loss = 0.0450277
I0309 07:44:45.977918  1118 solver.cpp:245]     Train net output #0: loss = 0.0450276 (* 1 = 0.0450276 loss)
I0309 07:44:45.977952  1118 sgd_solver.cpp:106] Iteration 21750, lr = 1e-06
I0309 07:45:25.624279  1118 solver.cpp:229] Iteration 21800, loss = 0.0530156
I0309 07:45:25.624505  1118 solver.cpp:245]     Train net output #0: loss = 0.0530154 (* 1 = 0.0530154 loss)
I0309 07:45:25.624537  1118 sgd_solver.cpp:106] Iteration 21800, lr = 1e-06
I0309 07:46:05.268149  1118 solver.cpp:229] Iteration 21850, loss = 0.0923665
I0309 07:46:05.268354  1118 solver.cpp:245]     Train net output #0: loss = 0.0923664 (* 1 = 0.0923664 loss)
I0309 07:46:05.268388  1118 sgd_solver.cpp:106] Iteration 21850, lr = 1e-06
I0309 07:46:44.121796  1118 solver.cpp:338] Iteration 21900, Testing net (#0)
I0309 07:46:45.455515  1118 solver.cpp:406]     Test net output #0: accuracy = 0.96
I0309 07:46:45.455564  1118 solver.cpp:406]     Test net output #1: loss = 0.126716 (* 1 = 0.126716 loss)
I0309 07:46:46.067567  1118 solver.cpp:229] Iteration 21900, loss = 0.042467
I0309 07:46:46.067611  1118 solver.cpp:245]     Train net output #0: loss = 0.0424668 (* 1 = 0.0424668 loss)
I0309 07:46:46.067637  1118 sgd_solver.cpp:106] Iteration 21900, lr = 1e-06
I0309 07:47:25.709836  1118 solver.cpp:229] Iteration 21950, loss = 0.0582022
I0309 07:47:25.710043  1118 solver.cpp:245]     Train net output #0: loss = 0.058202 (* 1 = 0.058202 loss)
I0309 07:47:25.710078  1118 sgd_solver.cpp:106] Iteration 21950, lr = 1e-06
I0309 07:48:04.559877  1118 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_22000.caffemodel
I0309 07:48:06.206466  1118 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_22000.solverstate
I0309 07:48:07.750690  1118 solver.cpp:229] Iteration 22000, loss = 0.0370007
I0309 07:48:07.750776  1118 solver.cpp:245]     Train net output #0: loss = 0.0370005 (* 1 = 0.0370005 loss)
I0309 07:48:07.750808  1118 sgd_solver.cpp:106] Iteration 22000, lr = 1e-06
I0309 07:48:47.401602  1118 solver.cpp:229] Iteration 22050, loss = 0.0598581
I0309 07:48:47.401829  1118 solver.cpp:245]     Train net output #0: loss = 0.059858 (* 1 = 0.059858 loss)
I0309 07:48:47.401862  1118 sgd_solver.cpp:106] Iteration 22050, lr = 1e-06
I0309 07:49:27.035902  1118 solver.cpp:229] Iteration 22100, loss = 0.0589322
I0309 07:49:27.036109  1118 solver.cpp:245]     Train net output #0: loss = 0.058932 (* 1 = 0.058932 loss)
I0309 07:49:27.036142  1118 sgd_solver.cpp:106] Iteration 22100, lr = 1e-06
I0309 07:50:06.685848  1118 solver.cpp:229] Iteration 22150, loss = 0.0389253
I0309 07:50:06.686017  1118 solver.cpp:245]     Train net output #0: loss = 0.0389252 (* 1 = 0.0389252 loss)
I0309 07:50:06.686051  1118 sgd_solver.cpp:106] Iteration 22150, lr = 1e-06
I0309 07:50:45.538553  1118 solver.cpp:338] Iteration 22200, Testing net (#0)
I0309 07:50:46.872221  1118 solver.cpp:406]     Test net output #0: accuracy = 0.96
I0309 07:50:46.872267  1118 solver.cpp:406]     Test net output #1: loss = 0.126769 (* 1 = 0.126769 loss)
I0309 07:50:47.484643  1118 solver.cpp:229] Iteration 22200, loss = 0.0533745
I0309 07:50:47.484688  1118 solver.cpp:245]     Train net output #0: loss = 0.0533744 (* 1 = 0.0533744 loss)
I0309 07:50:47.484714  1118 sgd_solver.cpp:106] Iteration 22200, lr = 1e-06
I0309 07:51:27.122788  1118 solver.cpp:229] Iteration 22250, loss = 0.0853711
I0309 07:51:27.122995  1118 solver.cpp:245]     Train net output #0: loss = 0.085371 (* 1 = 0.085371 loss)
I0309 07:51:27.123028  1118 sgd_solver.cpp:106] Iteration 22250, lr = 1e-06
I0309 07:52:06.772557  1118 solver.cpp:229] Iteration 22300, loss = 0.107378
I0309 07:52:06.772774  1118 solver.cpp:245]     Train net output #0: loss = 0.107378 (* 1 = 0.107378 loss)
I0309 07:52:06.772820  1118 sgd_solver.cpp:106] Iteration 22300, lr = 1e-06
I0309 07:52:46.430454  1118 solver.cpp:229] Iteration 22350, loss = 0.0958163
I0309 07:52:46.430663  1118 solver.cpp:245]     Train net output #0: loss = 0.0958162 (* 1 = 0.0958162 loss)
I0309 07:52:46.430696  1118 sgd_solver.cpp:106] Iteration 22350, lr = 1e-06
I0309 07:53:26.079599  1118 solver.cpp:229] Iteration 22400, loss = 0.0594124
I0309 07:53:26.079787  1118 solver.cpp:245]     Train net output #0: loss = 0.0594122 (* 1 = 0.0594122 loss)
I0309 07:53:26.079820  1118 sgd_solver.cpp:106] Iteration 22400, lr = 1e-06
I0309 07:54:05.718613  1118 solver.cpp:229] Iteration 22450, loss = 0.0314011
I0309 07:54:05.718816  1118 solver.cpp:245]     Train net output #0: loss = 0.031401 (* 1 = 0.031401 loss)
I0309 07:54:05.718849  1118 sgd_solver.cpp:106] Iteration 22450, lr = 1e-06
I0309 07:54:44.577298  1118 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_22500.caffemodel
I0309 07:54:46.225550  1118 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_22500.solverstate
I0309 07:54:47.155203  1118 solver.cpp:338] Iteration 22500, Testing net (#0)
I0309 07:54:48.315816  1118 solver.cpp:406]     Test net output #0: accuracy = 0.96
I0309 07:54:48.315872  1118 solver.cpp:406]     Test net output #1: loss = 0.126737 (* 1 = 0.126737 loss)
I0309 07:54:48.928545  1118 solver.cpp:229] Iteration 22500, loss = 0.0293183
I0309 07:54:48.928591  1118 solver.cpp:245]     Train net output #0: loss = 0.0293182 (* 1 = 0.0293182 loss)
I0309 07:54:48.928622  1118 sgd_solver.cpp:106] Iteration 22500, lr = 1e-06
I0309 07:55:28.579627  1118 solver.cpp:229] Iteration 22550, loss = 0.0444609
I0309 07:55:28.579845  1118 solver.cpp:245]     Train net output #0: loss = 0.0444608 (* 1 = 0.0444608 loss)
I0309 07:55:28.579879  1118 sgd_solver.cpp:106] Iteration 22550, lr = 1e-06
I0309 07:56:08.229517  1118 solver.cpp:229] Iteration 22600, loss = 0.100979
I0309 07:56:08.229720  1118 solver.cpp:245]     Train net output #0: loss = 0.100979 (* 1 = 0.100979 loss)
I0309 07:56:08.229753  1118 sgd_solver.cpp:106] Iteration 22600, lr = 1e-06
I0309 07:56:47.874136  1118 solver.cpp:229] Iteration 22650, loss = 0.0313761
I0309 07:56:47.874330  1118 solver.cpp:245]     Train net output #0: loss = 0.0313759 (* 1 = 0.0313759 loss)
I0309 07:56:47.874362  1118 sgd_solver.cpp:106] Iteration 22650, lr = 1e-06
I0309 07:57:27.523576  1118 solver.cpp:229] Iteration 22700, loss = 0.0483824
I0309 07:57:27.523763  1118 solver.cpp:245]     Train net output #0: loss = 0.0483823 (* 1 = 0.0483823 loss)
I0309 07:57:27.523797  1118 sgd_solver.cpp:106] Iteration 22700, lr = 1e-06
I0309 07:58:07.160279  1118 solver.cpp:229] Iteration 22750, loss = 0.0308003
I0309 07:58:07.160485  1118 solver.cpp:245]     Train net output #0: loss = 0.0308002 (* 1 = 0.0308002 loss)
I0309 07:58:07.160518  1118 sgd_solver.cpp:106] Iteration 22750, lr = 1e-06
I0309 07:58:46.013139  1118 solver.cpp:338] Iteration 22800, Testing net (#0)
I0309 07:58:47.345100  1118 solver.cpp:406]     Test net output #0: accuracy = 0.96
I0309 07:58:47.345144  1118 solver.cpp:406]     Test net output #1: loss = 0.126847 (* 1 = 0.126847 loss)
I0309 07:58:47.957713  1118 solver.cpp:229] Iteration 22800, loss = 0.0615186
I0309 07:58:47.957758  1118 solver.cpp:245]     Train net output #0: loss = 0.0615184 (* 1 = 0.0615184 loss)
I0309 07:58:47.957784  1118 sgd_solver.cpp:106] Iteration 22800, lr = 1e-06
I0309 07:59:27.600545  1118 solver.cpp:229] Iteration 22850, loss = 0.070733
I0309 07:59:27.600823  1118 solver.cpp:245]     Train net output #0: loss = 0.0707328 (* 1 = 0.0707328 loss)
I0309 07:59:27.600857  1118 sgd_solver.cpp:106] Iteration 22850, lr = 1e-06
I0309 08:00:07.243100  1118 solver.cpp:229] Iteration 22900, loss = 0.0567801
I0309 08:00:07.243336  1118 solver.cpp:245]     Train net output #0: loss = 0.0567799 (* 1 = 0.0567799 loss)
I0309 08:00:07.243369  1118 sgd_solver.cpp:106] Iteration 22900, lr = 1e-06
I0309 08:00:46.878144  1118 solver.cpp:229] Iteration 22950, loss = 0.0849179
I0309 08:00:46.878337  1118 solver.cpp:245]     Train net output #0: loss = 0.0849178 (* 1 = 0.0849178 loss)
I0309 08:00:46.878371  1118 sgd_solver.cpp:106] Iteration 22950, lr = 1e-06
I0309 08:01:25.736773  1118 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_23000.caffemodel
I0309 08:01:27.384896  1118 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_23000.solverstate
I0309 08:01:28.926846  1118 solver.cpp:229] Iteration 23000, loss = 0.0772075
I0309 08:01:28.926931  1118 solver.cpp:245]     Train net output #0: loss = 0.0772074 (* 1 = 0.0772074 loss)
I0309 08:01:28.926964  1118 sgd_solver.cpp:106] Iteration 23000, lr = 1e-06
I0309 08:02:08.571174  1118 solver.cpp:229] Iteration 23050, loss = 0.0305684
I0309 08:02:08.571385  1118 solver.cpp:245]     Train net output #0: loss = 0.0305682 (* 1 = 0.0305682 loss)
I0309 08:02:08.571419  1118 sgd_solver.cpp:106] Iteration 23050, lr = 1e-06
I0309 08:02:47.416822  1118 solver.cpp:338] Iteration 23100, Testing net (#0)
I0309 08:02:48.750229  1118 solver.cpp:406]     Test net output #0: accuracy = 0.96
I0309 08:02:48.750274  1118 solver.cpp:406]     Test net output #1: loss = 0.126901 (* 1 = 0.126901 loss)
I0309 08:02:49.362488  1118 solver.cpp:229] Iteration 23100, loss = 0.094071
I0309 08:02:49.362532  1118 solver.cpp:245]     Train net output #0: loss = 0.0940709 (* 1 = 0.0940709 loss)
I0309 08:02:49.362563  1118 sgd_solver.cpp:106] Iteration 23100, lr = 1e-06
I0309 08:03:29.008719  1118 solver.cpp:229] Iteration 23150, loss = 0.0945366
I0309 08:03:29.008924  1118 solver.cpp:245]     Train net output #0: loss = 0.0945365 (* 1 = 0.0945365 loss)
I0309 08:03:29.008957  1118 sgd_solver.cpp:106] Iteration 23150, lr = 1e-06
I0309 08:04:08.648068  1118 solver.cpp:229] Iteration 23200, loss = 0.0649685
I0309 08:04:08.648267  1118 solver.cpp:245]     Train net output #0: loss = 0.0649683 (* 1 = 0.0649683 loss)
I0309 08:04:08.648299  1118 sgd_solver.cpp:106] Iteration 23200, lr = 1e-06
I0309 08:04:48.290199  1118 solver.cpp:229] Iteration 23250, loss = 0.0313912
I0309 08:04:48.290397  1118 solver.cpp:245]     Train net output #0: loss = 0.031391 (* 1 = 0.031391 loss)
I0309 08:04:48.290431  1118 sgd_solver.cpp:106] Iteration 23250, lr = 1e-06
I0309 08:05:27.935118  1118 solver.cpp:229] Iteration 23300, loss = 0.118046
I0309 08:05:27.935312  1118 solver.cpp:245]     Train net output #0: loss = 0.118046 (* 1 = 0.118046 loss)
I0309 08:05:27.935345  1118 sgd_solver.cpp:106] Iteration 23300, lr = 1e-06
I0309 08:06:07.571535  1118 solver.cpp:229] Iteration 23350, loss = 0.0332319
I0309 08:06:07.571820  1118 solver.cpp:245]     Train net output #0: loss = 0.0332317 (* 1 = 0.0332317 loss)
I0309 08:06:07.571853  1118 sgd_solver.cpp:106] Iteration 23350, lr = 1e-06
I0309 08:06:46.426785  1118 solver.cpp:338] Iteration 23400, Testing net (#0)
I0309 08:06:47.759351  1118 solver.cpp:406]     Test net output #0: accuracy = 0.96
I0309 08:06:47.759397  1118 solver.cpp:406]     Test net output #1: loss = 0.127004 (* 1 = 0.127004 loss)
I0309 08:06:48.371589  1118 solver.cpp:229] Iteration 23400, loss = 0.0779437
I0309 08:06:48.371634  1118 solver.cpp:245]     Train net output #0: loss = 0.0779435 (* 1 = 0.0779435 loss)
I0309 08:06:48.371659  1118 sgd_solver.cpp:106] Iteration 23400, lr = 1e-06
I0309 08:07:28.013695  1118 solver.cpp:229] Iteration 23450, loss = 0.103118
I0309 08:07:28.013896  1118 solver.cpp:245]     Train net output #0: loss = 0.103118 (* 1 = 0.103118 loss)
I0309 08:07:28.013929  1118 sgd_solver.cpp:106] Iteration 23450, lr = 1e-06
I0309 08:08:06.866284  1118 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_23500.caffemodel
I0309 08:08:08.523406  1118 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_23500.solverstate
I0309 08:08:10.072422  1118 solver.cpp:229] Iteration 23500, loss = 0.0400166
I0309 08:08:10.072509  1118 solver.cpp:245]     Train net output #0: loss = 0.0400164 (* 1 = 0.0400164 loss)
I0309 08:08:10.072540  1118 sgd_solver.cpp:106] Iteration 23500, lr = 1e-06
I0309 08:08:49.720988  1118 solver.cpp:229] Iteration 23550, loss = 0.033373
I0309 08:08:49.721222  1118 solver.cpp:245]     Train net output #0: loss = 0.0333728 (* 1 = 0.0333728 loss)
I0309 08:08:49.721256  1118 sgd_solver.cpp:106] Iteration 23550, lr = 1e-06
I0309 08:09:29.376804  1118 solver.cpp:229] Iteration 23600, loss = 0.0537612
I0309 08:09:29.377001  1118 solver.cpp:245]     Train net output #0: loss = 0.053761 (* 1 = 0.053761 loss)
I0309 08:09:29.377033  1118 sgd_solver.cpp:106] Iteration 23600, lr = 1e-06
I0309 08:10:09.020391  1118 solver.cpp:229] Iteration 23650, loss = 0.0293519
I0309 08:10:09.020606  1118 solver.cpp:245]     Train net output #0: loss = 0.0293517 (* 1 = 0.0293517 loss)
I0309 08:10:09.020638  1118 sgd_solver.cpp:106] Iteration 23650, lr = 1e-06
I0309 08:10:47.885304  1118 solver.cpp:338] Iteration 23700, Testing net (#0)
I0309 08:10:49.218637  1118 solver.cpp:406]     Test net output #0: accuracy = 0.962
I0309 08:10:49.218682  1118 solver.cpp:406]     Test net output #1: loss = 0.127089 (* 1 = 0.127089 loss)
I0309 08:10:49.831084  1118 solver.cpp:229] Iteration 23700, loss = 0.051146
I0309 08:10:49.831128  1118 solver.cpp:245]     Train net output #0: loss = 0.0511459 (* 1 = 0.0511459 loss)
I0309 08:10:49.831153  1118 sgd_solver.cpp:106] Iteration 23700, lr = 1e-06
I0309 08:11:29.476238  1118 solver.cpp:229] Iteration 23750, loss = 0.0223383
I0309 08:11:29.476441  1118 solver.cpp:245]     Train net output #0: loss = 0.0223381 (* 1 = 0.0223381 loss)
I0309 08:11:29.476475  1118 sgd_solver.cpp:106] Iteration 23750, lr = 1e-06
I0309 08:12:09.130816  1118 solver.cpp:229] Iteration 23800, loss = 0.0512545
I0309 08:12:09.131014  1118 solver.cpp:245]     Train net output #0: loss = 0.0512543 (* 1 = 0.0512543 loss)
I0309 08:12:09.131047  1118 sgd_solver.cpp:106] Iteration 23800, lr = 1e-06
I0309 08:12:48.780978  1118 solver.cpp:229] Iteration 23850, loss = 0.0554383
I0309 08:12:48.781185  1118 solver.cpp:245]     Train net output #0: loss = 0.0554381 (* 1 = 0.0554381 loss)
I0309 08:12:48.781219  1118 sgd_solver.cpp:106] Iteration 23850, lr = 1e-06
I0309 08:13:28.435847  1118 solver.cpp:229] Iteration 23900, loss = 0.0328993
I0309 08:13:28.436192  1118 solver.cpp:245]     Train net output #0: loss = 0.0328992 (* 1 = 0.0328992 loss)
I0309 08:13:28.436228  1118 sgd_solver.cpp:106] Iteration 23900, lr = 1e-06
I0309 08:14:08.090900  1118 solver.cpp:229] Iteration 23950, loss = 0.0240569
I0309 08:14:08.091250  1118 solver.cpp:245]     Train net output #0: loss = 0.0240568 (* 1 = 0.0240568 loss)
I0309 08:14:08.091287  1118 sgd_solver.cpp:106] Iteration 23950, lr = 1e-06
I0309 08:14:46.960515  1118 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_24000.caffemodel
I0309 08:14:48.614307  1118 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_24000.solverstate
I0309 08:14:49.547035  1118 solver.cpp:338] Iteration 24000, Testing net (#0)
I0309 08:14:50.707310  1118 solver.cpp:406]     Test net output #0: accuracy = 0.96
I0309 08:14:50.707366  1118 solver.cpp:406]     Test net output #1: loss = 0.127074 (* 1 = 0.127074 loss)
I0309 08:14:51.319641  1118 solver.cpp:229] Iteration 24000, loss = 0.113025
I0309 08:14:51.319798  1118 solver.cpp:245]     Train net output #0: loss = 0.113025 (* 1 = 0.113025 loss)
I0309 08:14:51.319829  1118 sgd_solver.cpp:106] Iteration 24000, lr = 1e-06
I0309 08:15:30.966930  1118 solver.cpp:229] Iteration 24050, loss = 0.0600935
I0309 08:15:30.967324  1118 solver.cpp:245]     Train net output #0: loss = 0.0600933 (* 1 = 0.0600933 loss)
I0309 08:15:30.967376  1118 sgd_solver.cpp:106] Iteration 24050, lr = 1e-06
I0309 08:16:10.620420  1118 solver.cpp:229] Iteration 24100, loss = 0.0446449
I0309 08:16:10.620775  1118 solver.cpp:245]     Train net output #0: loss = 0.0446447 (* 1 = 0.0446447 loss)
I0309 08:16:10.620812  1118 sgd_solver.cpp:106] Iteration 24100, lr = 1e-06
I0309 08:16:50.272445  1118 solver.cpp:229] Iteration 24150, loss = 0.0564277
I0309 08:16:50.272781  1118 solver.cpp:245]     Train net output #0: loss = 0.0564276 (* 1 = 0.0564276 loss)
I0309 08:16:50.272819  1118 sgd_solver.cpp:106] Iteration 24150, lr = 1e-06
I0309 08:17:29.915637  1118 solver.cpp:229] Iteration 24200, loss = 0.117397
I0309 08:17:29.915992  1118 solver.cpp:245]     Train net output #0: loss = 0.117397 (* 1 = 0.117397 loss)
I0309 08:17:29.916028  1118 sgd_solver.cpp:106] Iteration 24200, lr = 1e-06
I0309 08:18:09.562069  1118 solver.cpp:229] Iteration 24250, loss = 0.0419522
I0309 08:18:09.562414  1118 solver.cpp:245]     Train net output #0: loss = 0.041952 (* 1 = 0.041952 loss)
I0309 08:18:09.562451  1118 sgd_solver.cpp:106] Iteration 24250, lr = 1e-06
I0309 08:18:48.423173  1118 solver.cpp:338] Iteration 24300, Testing net (#0)
I0309 08:18:49.756827  1118 solver.cpp:406]     Test net output #0: accuracy = 0.96
I0309 08:18:49.756885  1118 solver.cpp:406]     Test net output #1: loss = 0.127174 (* 1 = 0.127174 loss)
I0309 08:18:50.370194  1118 solver.cpp:229] Iteration 24300, loss = 0.0188966
I0309 08:18:50.370339  1118 solver.cpp:245]     Train net output #0: loss = 0.0188964 (* 1 = 0.0188964 loss)
I0309 08:18:50.370370  1118 sgd_solver.cpp:106] Iteration 24300, lr = 1e-06
I0309 08:19:30.032217  1118 solver.cpp:229] Iteration 24350, loss = 0.108045
I0309 08:19:30.032577  1118 solver.cpp:245]     Train net output #0: loss = 0.108045 (* 1 = 0.108045 loss)
I0309 08:19:30.032614  1118 sgd_solver.cpp:106] Iteration 24350, lr = 1e-06
I0309 08:20:09.682235  1118 solver.cpp:229] Iteration 24400, loss = 0.017818
I0309 08:20:09.682592  1118 solver.cpp:245]     Train net output #0: loss = 0.0178178 (* 1 = 0.0178178 loss)
I0309 08:20:09.682629  1118 sgd_solver.cpp:106] Iteration 24400, lr = 1e-06
I0309 08:20:49.327828  1118 solver.cpp:229] Iteration 24450, loss = 0.0688692
I0309 08:20:49.328173  1118 solver.cpp:245]     Train net output #0: loss = 0.068869 (* 1 = 0.068869 loss)
I0309 08:20:49.328209  1118 sgd_solver.cpp:106] Iteration 24450, lr = 1e-06
I0309 08:21:28.198598  1118 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_24500.caffemodel
I0309 08:21:29.849124  1118 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_24500.solverstate
I0309 08:21:31.407459  1118 solver.cpp:229] Iteration 24500, loss = 0.0548494
I0309 08:21:31.407541  1118 solver.cpp:245]     Train net output #0: loss = 0.0548492 (* 1 = 0.0548492 loss)
I0309 08:21:31.407575  1118 sgd_solver.cpp:106] Iteration 24500, lr = 1e-06
I0309 08:22:11.056061  1118 solver.cpp:229] Iteration 24550, loss = 0.0383943
I0309 08:22:11.056305  1118 solver.cpp:245]     Train net output #0: loss = 0.0383942 (* 1 = 0.0383942 loss)
I0309 08:22:11.056339  1118 sgd_solver.cpp:106] Iteration 24550, lr = 1e-06
I0309 08:22:49.917315  1118 solver.cpp:338] Iteration 24600, Testing net (#0)
I0309 08:22:51.250851  1118 solver.cpp:406]     Test net output #0: accuracy = 0.962
I0309 08:22:51.250896  1118 solver.cpp:406]     Test net output #1: loss = 0.127032 (* 1 = 0.127032 loss)
I0309 08:22:51.863064  1118 solver.cpp:229] Iteration 24600, loss = 0.115785
I0309 08:22:51.863108  1118 solver.cpp:245]     Train net output #0: loss = 0.115785 (* 1 = 0.115785 loss)
I0309 08:22:51.863134  1118 sgd_solver.cpp:106] Iteration 24600, lr = 1e-06
I0309 08:23:31.507143  1118 solver.cpp:229] Iteration 24650, loss = 0.0737707
I0309 08:23:31.507349  1118 solver.cpp:245]     Train net output #0: loss = 0.0737705 (* 1 = 0.0737705 loss)
I0309 08:23:31.507382  1118 sgd_solver.cpp:106] Iteration 24650, lr = 1e-06
I0309 08:24:11.150485  1118 solver.cpp:229] Iteration 24700, loss = 0.0761104
I0309 08:24:11.150684  1118 solver.cpp:245]     Train net output #0: loss = 0.0761103 (* 1 = 0.0761103 loss)
I0309 08:24:11.150718  1118 sgd_solver.cpp:106] Iteration 24700, lr = 1e-06
I0309 08:24:50.801797  1118 solver.cpp:229] Iteration 24750, loss = 0.0279839
I0309 08:24:50.801996  1118 solver.cpp:245]     Train net output #0: loss = 0.0279838 (* 1 = 0.0279838 loss)
I0309 08:24:50.802029  1118 sgd_solver.cpp:106] Iteration 24750, lr = 1e-06
I0309 08:25:30.448333  1118 solver.cpp:229] Iteration 24800, loss = 0.012078
I0309 08:25:30.448524  1118 solver.cpp:245]     Train net output #0: loss = 0.0120778 (* 1 = 0.0120778 loss)
I0309 08:25:30.448564  1118 sgd_solver.cpp:106] Iteration 24800, lr = 1e-06
I0309 08:26:10.089295  1118 solver.cpp:229] Iteration 24850, loss = 0.0403498
I0309 08:26:10.089503  1118 solver.cpp:245]     Train net output #0: loss = 0.0403497 (* 1 = 0.0403497 loss)
I0309 08:26:10.089536  1118 sgd_solver.cpp:106] Iteration 24850, lr = 1e-06
I0309 08:26:48.954663  1118 solver.cpp:338] Iteration 24900, Testing net (#0)
I0309 08:26:50.288655  1118 solver.cpp:406]     Test net output #0: accuracy = 0.962
I0309 08:26:50.288699  1118 solver.cpp:406]     Test net output #1: loss = 0.127 (* 1 = 0.127 loss)
I0309 08:26:50.901901  1118 solver.cpp:229] Iteration 24900, loss = 0.0527017
I0309 08:26:50.901947  1118 solver.cpp:245]     Train net output #0: loss = 0.0527015 (* 1 = 0.0527015 loss)
I0309 08:26:50.901973  1118 sgd_solver.cpp:106] Iteration 24900, lr = 1e-06
I0309 08:27:30.545685  1118 solver.cpp:229] Iteration 24950, loss = 0.0548009
I0309 08:27:30.545869  1118 solver.cpp:245]     Train net output #0: loss = 0.0548008 (* 1 = 0.0548008 loss)
I0309 08:27:30.545902  1118 sgd_solver.cpp:106] Iteration 24950, lr = 1e-06
I0309 08:28:09.418380  1118 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_25000.caffemodel
I0309 08:28:11.069103  1118 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_25000.solverstate
I0309 08:28:12.615525  1118 solver.cpp:229] Iteration 25000, loss = 0.063252
I0309 08:28:12.615609  1118 solver.cpp:245]     Train net output #0: loss = 0.0632518 (* 1 = 0.0632518 loss)
I0309 08:28:12.615640  1118 sgd_solver.cpp:106] Iteration 25000, lr = 1e-06
I0309 08:28:52.270038  1118 solver.cpp:229] Iteration 25050, loss = 0.0365214
I0309 08:28:52.270251  1118 solver.cpp:245]     Train net output #0: loss = 0.0365213 (* 1 = 0.0365213 loss)
I0309 08:28:52.270284  1118 sgd_solver.cpp:106] Iteration 25050, lr = 1e-06
I0309 08:29:31.916420  1118 solver.cpp:229] Iteration 25100, loss = 0.0317986
I0309 08:29:31.916625  1118 solver.cpp:245]     Train net output #0: loss = 0.0317985 (* 1 = 0.0317985 loss)
I0309 08:29:31.916658  1118 sgd_solver.cpp:106] Iteration 25100, lr = 1e-06
I0309 08:30:11.566886  1118 solver.cpp:229] Iteration 25150, loss = 0.0762391
I0309 08:30:11.567142  1118 solver.cpp:245]     Train net output #0: loss = 0.076239 (* 1 = 0.076239 loss)
I0309 08:30:11.567175  1118 sgd_solver.cpp:106] Iteration 25150, lr = 1e-06
I0309 08:30:50.428448  1118 solver.cpp:338] Iteration 25200, Testing net (#0)
I0309 08:30:51.762171  1118 solver.cpp:406]     Test net output #0: accuracy = 0.962
I0309 08:30:51.762217  1118 solver.cpp:406]     Test net output #1: loss = 0.126856 (* 1 = 0.126856 loss)
I0309 08:30:52.375324  1118 solver.cpp:229] Iteration 25200, loss = 0.0745581
I0309 08:30:52.375368  1118 solver.cpp:245]     Train net output #0: loss = 0.074558 (* 1 = 0.074558 loss)
I0309 08:30:52.375396  1118 sgd_solver.cpp:106] Iteration 25200, lr = 1e-06
I0309 08:31:32.031646  1118 solver.cpp:229] Iteration 25250, loss = 0.0559951
I0309 08:31:32.031852  1118 solver.cpp:245]     Train net output #0: loss = 0.0559949 (* 1 = 0.0559949 loss)
I0309 08:31:32.031885  1118 sgd_solver.cpp:106] Iteration 25250, lr = 1e-06
I0309 08:32:11.686849  1118 solver.cpp:229] Iteration 25300, loss = 0.0649882
I0309 08:32:11.687132  1118 solver.cpp:245]     Train net output #0: loss = 0.0649881 (* 1 = 0.0649881 loss)
I0309 08:32:11.687166  1118 sgd_solver.cpp:106] Iteration 25300, lr = 1e-06
I0309 08:32:51.352969  1118 solver.cpp:229] Iteration 25350, loss = 0.02782
I0309 08:32:51.353186  1118 solver.cpp:245]     Train net output #0: loss = 0.0278199 (* 1 = 0.0278199 loss)
I0309 08:32:51.353219  1118 sgd_solver.cpp:106] Iteration 25350, lr = 1e-06
I0309 08:33:31.003392  1118 solver.cpp:229] Iteration 25400, loss = 0.0377585
I0309 08:33:31.003607  1118 solver.cpp:245]     Train net output #0: loss = 0.0377584 (* 1 = 0.0377584 loss)
I0309 08:33:31.003640  1118 sgd_solver.cpp:106] Iteration 25400, lr = 1e-06
I0309 08:34:10.655408  1118 solver.cpp:229] Iteration 25450, loss = 0.0351115
I0309 08:34:10.655603  1118 solver.cpp:245]     Train net output #0: loss = 0.0351114 (* 1 = 0.0351114 loss)
I0309 08:34:10.655637  1118 sgd_solver.cpp:106] Iteration 25450, lr = 1e-06
I0309 08:34:49.522264  1118 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_25500.caffemodel
I0309 08:34:51.176417  1118 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_25500.solverstate
I0309 08:34:52.113993  1118 solver.cpp:338] Iteration 25500, Testing net (#0)
I0309 08:34:53.275022  1118 solver.cpp:406]     Test net output #0: accuracy = 0.962
I0309 08:34:53.275077  1118 solver.cpp:406]     Test net output #1: loss = 0.126842 (* 1 = 0.126842 loss)
I0309 08:34:53.887972  1118 solver.cpp:229] Iteration 25500, loss = 0.0735441
I0309 08:34:53.888016  1118 solver.cpp:245]     Train net output #0: loss = 0.073544 (* 1 = 0.073544 loss)
I0309 08:34:53.888046  1118 sgd_solver.cpp:106] Iteration 25500, lr = 1e-06
I0309 08:35:33.546720  1118 solver.cpp:229] Iteration 25550, loss = 0.0509128
I0309 08:35:33.546932  1118 solver.cpp:245]     Train net output #0: loss = 0.0509126 (* 1 = 0.0509126 loss)
I0309 08:35:33.546965  1118 sgd_solver.cpp:106] Iteration 25550, lr = 1e-06
I0309 08:36:13.182005  1118 solver.cpp:229] Iteration 25600, loss = 0.0285005
I0309 08:36:13.182209  1118 solver.cpp:245]     Train net output #0: loss = 0.0285003 (* 1 = 0.0285003 loss)
I0309 08:36:13.182242  1118 sgd_solver.cpp:106] Iteration 25600, lr = 1e-06
I0309 08:36:52.823045  1118 solver.cpp:229] Iteration 25650, loss = 0.107674
I0309 08:36:52.823251  1118 solver.cpp:245]     Train net output #0: loss = 0.107674 (* 1 = 0.107674 loss)
I0309 08:36:52.823285  1118 sgd_solver.cpp:106] Iteration 25650, lr = 1e-06
I0309 08:37:32.469828  1118 solver.cpp:229] Iteration 25700, loss = 0.0204071
I0309 08:37:32.477633  1118 solver.cpp:245]     Train net output #0: loss = 0.020407 (* 1 = 0.020407 loss)
I0309 08:37:32.477669  1118 sgd_solver.cpp:106] Iteration 25700, lr = 1e-06
I0309 08:38:12.121767  1118 solver.cpp:229] Iteration 25750, loss = 0.0393737
I0309 08:38:12.121976  1118 solver.cpp:245]     Train net output #0: loss = 0.0393735 (* 1 = 0.0393735 loss)
I0309 08:38:12.122009  1118 sgd_solver.cpp:106] Iteration 25750, lr = 1e-06
I0309 08:38:50.985709  1118 solver.cpp:338] Iteration 25800, Testing net (#0)
I0309 08:38:52.319259  1118 solver.cpp:406]     Test net output #0: accuracy = 0.962
I0309 08:38:52.319314  1118 solver.cpp:406]     Test net output #1: loss = 0.126788 (* 1 = 0.126788 loss)
I0309 08:38:52.931490  1118 solver.cpp:229] Iteration 25800, loss = 0.0408682
I0309 08:38:52.931538  1118 solver.cpp:245]     Train net output #0: loss = 0.040868 (* 1 = 0.040868 loss)
I0309 08:38:52.931565  1118 sgd_solver.cpp:106] Iteration 25800, lr = 1e-06
I0309 08:39:32.575562  1118 solver.cpp:229] Iteration 25850, loss = 0.0448392
I0309 08:39:32.575765  1118 solver.cpp:245]     Train net output #0: loss = 0.0448391 (* 1 = 0.0448391 loss)
I0309 08:39:32.575798  1118 sgd_solver.cpp:106] Iteration 25850, lr = 1e-06
I0309 08:40:12.226364  1118 solver.cpp:229] Iteration 25900, loss = 0.0470281
I0309 08:40:12.226593  1118 solver.cpp:245]     Train net output #0: loss = 0.047028 (* 1 = 0.047028 loss)
I0309 08:40:12.226627  1118 sgd_solver.cpp:106] Iteration 25900, lr = 1e-06
I0309 08:40:51.876169  1118 solver.cpp:229] Iteration 25950, loss = 0.0677657
I0309 08:40:51.876379  1118 solver.cpp:245]     Train net output #0: loss = 0.0677655 (* 1 = 0.0677655 loss)
I0309 08:40:51.876411  1118 sgd_solver.cpp:106] Iteration 25950, lr = 1e-06
I0309 08:41:30.730515  1118 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_26000.caffemodel
I0309 08:41:32.381431  1118 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_26000.solverstate
I0309 08:41:33.929733  1118 solver.cpp:229] Iteration 26000, loss = 0.0362858
I0309 08:41:33.929821  1118 solver.cpp:245]     Train net output #0: loss = 0.0362857 (* 1 = 0.0362857 loss)
I0309 08:41:33.929852  1118 sgd_solver.cpp:106] Iteration 26000, lr = 1e-06
I0309 08:42:13.573426  1118 solver.cpp:229] Iteration 26050, loss = 0.0249721
I0309 08:42:13.573668  1118 solver.cpp:245]     Train net output #0: loss = 0.0249719 (* 1 = 0.0249719 loss)
I0309 08:42:13.573703  1118 sgd_solver.cpp:106] Iteration 26050, lr = 1e-06
I0309 08:42:52.438582  1118 solver.cpp:338] Iteration 26100, Testing net (#0)
I0309 08:42:53.771561  1118 solver.cpp:406]     Test net output #0: accuracy = 0.96
I0309 08:42:53.771620  1118 solver.cpp:406]     Test net output #1: loss = 0.126761 (* 1 = 0.126761 loss)
I0309 08:42:54.383926  1118 solver.cpp:229] Iteration 26100, loss = 0.0482481
I0309 08:42:54.384078  1118 solver.cpp:245]     Train net output #0: loss = 0.048248 (* 1 = 0.048248 loss)
I0309 08:42:54.384109  1118 sgd_solver.cpp:106] Iteration 26100, lr = 1e-06
I0309 08:43:34.031733  1118 solver.cpp:229] Iteration 26150, loss = 0.0470823
I0309 08:43:34.032097  1118 solver.cpp:245]     Train net output #0: loss = 0.0470822 (* 1 = 0.0470822 loss)
I0309 08:43:34.032135  1118 sgd_solver.cpp:106] Iteration 26150, lr = 1e-06
I0309 08:44:13.675719  1118 solver.cpp:229] Iteration 26200, loss = 0.0965699
I0309 08:44:13.676030  1118 solver.cpp:245]     Train net output #0: loss = 0.0965698 (* 1 = 0.0965698 loss)
I0309 08:44:13.676064  1118 sgd_solver.cpp:106] Iteration 26200, lr = 1e-06
I0309 08:44:53.318101  1118 solver.cpp:229] Iteration 26250, loss = 0.0398292
I0309 08:44:53.318298  1118 solver.cpp:245]     Train net output #0: loss = 0.039829 (* 1 = 0.039829 loss)
I0309 08:44:53.318331  1118 sgd_solver.cpp:106] Iteration 26250, lr = 1e-06
I0309 08:45:32.975706  1118 solver.cpp:229] Iteration 26300, loss = 0.0594
I0309 08:45:32.976006  1118 solver.cpp:245]     Train net output #0: loss = 0.0593999 (* 1 = 0.0593999 loss)
I0309 08:45:32.976039  1118 sgd_solver.cpp:106] Iteration 26300, lr = 1e-06
I0309 08:46:12.630115  1118 solver.cpp:229] Iteration 26350, loss = 0.0388668
I0309 08:46:12.630321  1118 solver.cpp:245]     Train net output #0: loss = 0.0388666 (* 1 = 0.0388666 loss)
I0309 08:46:12.630355  1118 sgd_solver.cpp:106] Iteration 26350, lr = 1e-06
I0309 08:46:51.493170  1118 solver.cpp:338] Iteration 26400, Testing net (#0)
I0309 08:46:52.826509  1118 solver.cpp:406]     Test net output #0: accuracy = 0.96
I0309 08:46:52.826555  1118 solver.cpp:406]     Test net output #1: loss = 0.126514 (* 1 = 0.126514 loss)
I0309 08:46:53.438438  1118 solver.cpp:229] Iteration 26400, loss = 0.080202
I0309 08:46:53.438482  1118 solver.cpp:245]     Train net output #0: loss = 0.0802018 (* 1 = 0.0802018 loss)
I0309 08:46:53.438513  1118 sgd_solver.cpp:106] Iteration 26400, lr = 1e-06
I0309 08:47:33.084205  1118 solver.cpp:229] Iteration 26450, loss = 0.0309731
I0309 08:47:33.084410  1118 solver.cpp:245]     Train net output #0: loss = 0.0309729 (* 1 = 0.0309729 loss)
I0309 08:47:33.084444  1118 sgd_solver.cpp:106] Iteration 26450, lr = 1e-06
I0309 08:48:11.940940  1118 solver.cpp:456] Snapshotting to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_26500.caffemodel
I0309 08:48:13.595335  1118 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /work/04018/wxie/maverick/visual_recognition/states/large_fast/finetune_lmdb_iter_26500.solverstate
I0309 08:48:15.140893  1118 solver.cpp:229] Iteration 26500, loss = 0.0225945
I0309 08:48:15.140981  1118 solver.cpp:245]     Train net output #0: loss = 0.0225944 (* 1 = 0.0225944 loss)
I0309 08:48:15.141012  1118 sgd_solver.cpp:106] Iteration 26500, lr = 1e-06
I0309 08:48:54.797440  1118 solver.cpp:229] Iteration 26550, loss = 0.047665
I0309 08:48:54.797662  1118 solver.cpp:245]     Train net output #0: loss = 0.0476649 (* 1 = 0.0476649 loss)
I0309 08:48:54.797695  1118 sgd_solver.cpp:106] Iteration 26550, lr = 1e-06
I0309 08:49:34.456770  1118 solver.cpp:229] Iteration 26600, loss = 0.0451643
I0309 08:49:34.456979  1118 solver.cpp:245]     Train net output #0: loss = 0.0451642 (* 1 = 0.0451642 loss)
I0309 08:49:34.457011  1118 sgd_solver.cpp:106] Iteration 26600, lr = 1e-06
I0309 08:50:14.104710  1118 solver.cpp:229] Iteration 26650, loss = 0.0520135
I0309 08:50:14.104918  1118 solver.cpp:245]     Train net output #0: loss = 0.0520133 (* 1 = 0.0520133 loss)
I0309 08:50:14.104950  1118 sgd_solver.cpp:106] Iteration 26650, lr = 1e-06
I0309 08:50:52.969825  1118 solver.cpp:338] Iteration 26700, Testing net (#0)
I0309 08:50:54.303166  1118 solver.cpp:406]     Test net output #0: accuracy = 0.96
I0309 08:50:54.303212  1118 solver.cpp:406]     Test net output #1: loss = 0.12645 (* 1 = 0.12645 loss)
I0309 08:50:54.915302  1118 solver.cpp:229] Iteration 26700, loss = 0.0351475
I0309 08:50:54.915349  1118 solver.cpp:245]     Train net output #0: loss = 0.0351473 (* 1 = 0.0351473 loss)
I0309 08:50:54.915375  1118 sgd_solver.cpp:106] Iteration 26700, lr = 1e-06
I0309 08:51:34.567822  1118 solver.cpp:229] Iteration 26750, loss = 0.0264958
I0309 08:51:34.568027  1118 solver.cpp:245]     Train net output #0: loss = 0.0264956 (* 1 = 0.0264956 loss)
I0309 08:51:34.568060  1118 sgd_solver.cpp:106] Iteration 26750, lr = 1e-06
I0309 08:52:14.208631  1118 solver.cpp:229] Iteration 26800, loss = 0.0390269
I0309 08:52:14.208817  1118 solver.cpp:245]     Train net output #0: loss = 0.0390267 (* 1 = 0.0390267 loss)
I0309 08:52:14.208852  1118 sgd_solver.cpp:106] Iteration 26800, lr = 1e-06
I0309 08:52:53.861120  1118 solver.cpp:229] Iteration 26850, loss = 0.0527096
I0309 08:52:53.861322  1118 solver.cpp:245]     Train net output #0: loss = 0.0527095 (* 1 = 0.0527095 loss)
I0309 08:52:53.861356  1118 sgd_solver.cpp:106] Iteration 26850, lr = 1e-06
I0309 08:53:33.519938  1118 solver.cpp:229] Iteration 26900, loss = 0.0258563
I0309 08:53:33.520140  1118 solver.cpp:245]     Train net output #0: loss = 0.0258561 (* 1 = 0.0258561 loss)
I0309 08:53:33.520174  1118 sgd_solver.cpp:106] Iteration 26900, lr = 1e-06
I0309 08:54:13.165627  1118 solver.cpp:229] Iteration 26950, loss = 0.0326242
I0309 08:54:13.165834  1118 solver.cpp:245]     Train net output #0: loss = 0.032624 (* 1 = 0.032624 loss)
I0309 08:54:13.165866  1118 sgd_solver.cpp:106] Iteration 26950, lr = 1e-06
slurmstepd: *** JOB 447268 CANCELLED AT 2016-03-09T08:54:26 DUE TO TIME LIMIT on c221-501 ***
*** Aborted at 1457535266 (unix time) try "date -d @1457535266" if you are using GNU date ***
PC: @       0x3be020a859 (unknown)
